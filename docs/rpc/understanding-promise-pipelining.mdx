---
title: Understanding Promise Pipelining
description: The mental model behind dotdo's core innovation - why unawaited promises eliminate network round trips
---

import { Callout, Steps } from 'fumadocs-ui/components/callout'

# Understanding Promise Pipelining

This is the guide for understanding dotdo's core performance innovation. If you only read one page about RPC, read this one.

## The Problem: Network Round Trips

Every distributed system faces the same fundamental challenge: **network latency compounds**.

When your code runs across a network boundary, every `await` forces a round trip:

```typescript title="Traditional async - 3 round trips"
const spec = await priya`define the MVP`     // Round trip 1: 200ms
const app = await ralph`build ${spec}`        // Round trip 2: 200ms
const deployed = await tom`ship ${app}`       // Round trip 3: 200ms
// Total: 600ms of network latency
```

The problem isn't the server work. It's the **waiting**. Each `await` sends a request, waits for the response, then sends the next request. Three operations take three times the network latency.

```
Client                            Server
  |                                  |
  |-------- priya request ---------> |
  |                                  | (work)
  | <------- spec response --------- |
  |                                  |
  |-------- ralph request ---------> |
  |                                  | (work)
  | <-------- app response --------- |
  |                                  |
  |--------- tom request ----------> |
  |                                  | (work)
  | <------ deployed response ------ |
  |                                  |
```

At 200ms round-trip latency (common for edge-to-origin), three calls take 600ms before any work even happens.

## The Insight: Promises as Graph Edges

Here's the key realization: **a promise is just a reference to a future value**.

When you write:

```typescript
const spec = priya`define the MVP`
```

You don't have the spec yet. You have a **promise of a spec**. A reference to something that will exist.

Now, what happens when you pass that promise to another call?

```typescript
const spec = priya`define the MVP`
const app = ralph`build ${spec}`
```

You're not passing the spec itself. You're passing a reference to something that doesn't exist yet. But you're telling the system: "when you have the spec, use it to build the app."

This creates a **dependency edge**:

```
priya() -----> ralph()
         spec
```

The unawaited promise is literally an edge in a dependency graph. The client isn't saying "give me the spec, then I'll tell you what to do." It's saying "here's what to do with the spec when you have it."

<Callout type="info" title="The Core Insight">
An unawaited promise passed to another call is a **graph edge**, not a request for a value. The client is building a computation graph, not orchestrating a sequence.
</Callout>

## The Solution: Send the Graph

Instead of executing calls one by one, **send the entire dependency graph in one request**:

```typescript title="Promise pipelining - 1 round trip"
const spec = priya`define the MVP`           // RpcPromise (not awaited)
const app = ralph`build ${spec}`              // Passes spec as graph edge
const deployed = tom`ship ${app}`             // Passes app as graph edge
// ONE round trip when we finally await
```

The client builds this graph:

```
┌─────────────────────┐
│   priya("define")   │
└──────────┬──────────┘
           │ spec
           v
┌─────────────────────┐
│   ralph("build")    │
└──────────┬──────────┘
           │ app
           v
┌─────────────────────┐
│    tom("ship")      │
└──────────┬──────────┘
           │ deployed
           v
        [return]
```

This entire graph goes to the server in **one request**:

```
Client                            Server
  |                                  |
  |------- entire pipeline --------> |
  |                                  | priya (work)
  |                                  | ralph (work)
  |                                  | tom (work)
  | <------ deployed response ------ |
  |                                  |
```

200ms total, not 600ms. The server has everything it needs to execute the full pipeline. Intermediate values never cross the network.

## Before and After: Visual Comparison

### Without Pipelining

```
┌─────────────────────────────────────────────────────────────┐
│                        CLIENT                               │
│                                                             │
│  t=0ms    send(priya)                                       │
│           wait...                                           │
│  t=200ms  receive(spec)                                     │
│           send(ralph, spec)                                 │
│           wait...                                           │
│  t=400ms  receive(app)                                      │
│           send(tom, app)                                    │
│           wait...                                           │
│  t=600ms  receive(deployed)                                 │
│                                                             │
└─────────────────────────────────────────────────────────────┘

Total time: 600ms (3 round trips)
Network utilization: 3 requests, 3 responses
```

### With Pipelining

```
┌─────────────────────────────────────────────────────────────┐
│                        CLIENT                               │
│                                                             │
│  t=0ms    send(pipeline: priya -> ralph -> tom)             │
│           wait...                                           │
│  t=200ms  receive(deployed)                                 │
│                                                             │
└─────────────────────────────────────────────────────────────┘

Total time: 200ms (1 round trip)
Network utilization: 1 request, 1 response
```

**3x faster with the same amount of work.**

## Building the Mental Model

Think of it this way:

<Steps>
### Unawaited Promises Are References

When you don't await, you're not getting a value. You're getting a **reference** to a future value. An RpcPromise is a stub, a placeholder, a capability.

### Passing References Builds a Graph

When you pass an unawaited promise to another call, you're creating a **dependency edge**. You're saying "this operation depends on that result."

### Await Flushes the Graph

When you finally `await`, the entire accumulated graph is sent to the server. All the edges, all the dependencies, all the operations - in one network request.

### The Server Walks the Graph

The server receives the graph and executes it. It follows the edges, passing results from one operation to the next, without any client involvement.

</Steps>

## The Graph in Action

Let's trace through a real example:

```typescript
const spec = priya`define the MVP for ${hypothesis}`
const app = ralph`build ${spec}`
const reviewed = tom`review ${app}`
const shipped = tom`ship ${reviewed}`
```

Step by step:

1. **Line 1**: Creates node 0. Returns RpcPromise pointing to node 0.
2. **Line 2**: Creates node 1. Records edge: node 1 depends on node 0. Returns RpcPromise pointing to node 1.
3. **Line 3**: Creates node 2. Records edge: node 2 depends on node 1. Returns RpcPromise pointing to node 2.
4. **Line 4**: Creates node 3. Records edge: node 3 depends on node 2. Returns RpcPromise pointing to node 3.

The graph:

```
    0: priya(hypothesis)
         │
         └──> 1: ralph($0)
                   │
                   └──> 2: tom.review($1)
                             │
                             └──> 3: tom.ship($2)
```

When you `await shipped`, this entire structure serializes to:

```json
{
  "nodes": [
    { "id": 0, "call": ["priya", "define the MVP for ..."] },
    { "id": 1, "call": ["ralph", "build", { "$ref": 0 }] },
    { "id": 2, "call": ["tom", "review", { "$ref": 1 }] },
    { "id": 3, "call": ["tom", "ship", { "$ref": 2 }] }
  ],
  "return": 3
}
```

The `$ref` markers are the graph edges. The server knows node 1 needs the result of node 0 before it can execute.

## Parallel Branches

Pipelines aren't just linear. Independent operations run in parallel:

```typescript
const spec = priya`define the MVP`
const marketing = mark`draft launch plan`
const sales = sally`identify prospects`
const app = ralph`build ${spec}`
const launch = tom`coordinate ${app} with ${marketing} and ${sales}`
```

Graph structure:

```
    0: priya()          1: mark()          2: sally()
         │                  │                  │
         v                  │                  │
    3: ralph($0)            │                  │
         │                  │                  │
         └──────────────────┼──────────────────┘
                            │
                            v
                    4: tom($3, $1, $2)
```

The server sees that nodes 0, 1, and 2 have no dependencies - they can run in parallel. Node 3 depends on 0. Node 4 depends on 3, 1, and 2. The execution is automatically parallelized:

```
Server execution:
├── Parallel: priya(), mark(), sally()
├── Sequential: ralph() (waits for priya)
└── Sequential: tom() (waits for ralph, mark, sally)
```

One round trip. Maximum parallelism. No client coordination needed.

## When to Await

The rule is simple: **await when you need the value locally**.

| Scenario | Await? | Why |
|----------|--------|-----|
| Pass to another call | No | It's a graph edge |
| Branch on the value | Yes | Client needs to decide |
| Loop over the value | Yes | Client needs to iterate |
| Display/log the value | Yes | Client needs the bytes |
| Return to caller | Maybe | Depends if caller continues |

```typescript
// Branch: must await to decide
const analysis = await priya`analyze market`
if (analysis.opportunity === 'high') {
  // Different path based on analysis
}

// Loop: must await to iterate
const tasks = await priya`list tasks`
for (const task of tasks) {
  // Need actual array to loop
}

// Chain: don't await, pass the promise
const spec = priya`define MVP`
const app = ralph`build ${spec}`  // spec is RpcPromise, not value
```

<Callout type="warn" title="Every Await Is a Potential Batch Boundary">
When you `await`, you flush the current pipeline. New calls after the await start a new batch. Unnecessary awaits fragment your pipelines.
</Callout>

## Magic Map: Transforms Without Awaiting

What about array operations? Normally you'd await to use `.map()`:

```typescript
// Breaks the pipeline
const users = await sally`find customers`  // Round trip 1
const emails = users.map(u => u.email)
await mark`send to ${emails}`              // Round trip 2
```

Magic Map records the transform and executes it on the server:

```typescript
// Single pipeline
const users = sally`find customers`
const emails = users.map(u => u.email)    // Recorded, not executed
await mark`send to ${emails}`             // ONE round trip
```

The `.map()` callback is serialized and sent to the server. The transform happens where the data is.

See [Magic Map](/docs/rpc/magic-map) for the complete API.

## Cap'n Web: The Protocol

Under the hood, dotdo uses **Cap'n Web** - a promise pipelining RPC protocol inspired by Cap'n Proto.

Key concepts:

1. **Push**: Send an expression to evaluate. Gets assigned an ID.
2. **Pipeline**: Reference a previous result by ID in new expressions.
3. **Pull**: Request the actual result when you need it.
4. **Resolve**: Server sends back the value.

The protocol is designed for **batching** - multiple expressions can reference each other by ID without waiting for resolution.

See [Protocol Reference](/docs/transport/handlers) for the wire format.

## RpcPromise: The Dual Nature

An `RpcPromise` is both:

- **A Promise**: Can be awaited, has `.then()`, `.catch()`, `.finally()`
- **A Proxy**: Can access properties, call methods, use in template literals

```typescript
const user = $.Customer('cus_123')

// As a promise
const resolved = await user

// As a proxy (returns new RpcPromise)
const email = user.profile.email
const greeting = user.greet('Hello')
```

Every property access or method call returns a new RpcPromise. The chain is recorded and sent to the server together.

See [Proxy Chaining](/docs/rpc/proxy-chaining) for details.

## Performance Impact

| Pattern | Round Trips | With 200ms RTT |
|---------|-------------|----------------|
| 5 sequential awaits | 5 | 1000ms |
| 5 pipelined calls | 1 | 200ms |
| 5 parallel calls | 1 | 200ms |
| 3 await + 2 pipeline | 3 | 600ms |

For agent orchestration with multiple AI calls, this is transformative. A workflow that would take 10 seconds of network latency drops to 200ms.

## Summary

Promise pipelining is about **describing computation graphs, not orchestrating sequences**.

1. **Don't await** unless you need the value locally
2. **Pass RpcPromises** as arguments to build dependency edges
3. **Let the server** figure out execution order and parallelism
4. **Await once** at the end to flush the pipeline

The canonical dotdo startup launch:

```typescript
const spec = priya`define the MVP for ${hypothesis}`
const app = ralph`build ${spec}`
const deployed = tom`ship ${app}`
const announced = mark`announce ${deployed}`
const selling = sally`start selling ${announced}`
return await selling  // ONE round trip
```

Five agent calls. Five AI invocations. One network round trip.

## Deep Dive

<Cards>
  <Card title="When to Await" href="/docs/rpc/when-to-await">
    The definitive decision tree and quick reference for all await decisions.
  </Card>
  <Card title="Await Patterns" href="/docs/rpc/await-patterns">
    Pattern-focused examples for common await scenarios.
  </Card>
  <Card title="Magic Map" href="/docs/rpc/magic-map">
    Transform arrays on the server without breaking the pipeline.
  </Card>
  <Card title="Proxy Chaining" href="/docs/rpc/proxy-chaining">
    Access properties and call methods on values that don't exist yet.
  </Card>
  <Card title="Request Batching" href="/docs/rpc/batching">
    Automatic and manual batching for independent operations.
  </Card>
  <Card title="Protocol Reference" href="/docs/transport/handlers">
    The Cap'n Web wire format and message types.
  </Card>
</Cards>
