---
title: Use Cases
description: Common use cases for EdgeVec including RAG, semantic search, recommendations, and hybrid search patterns.
---

import { Callout } from 'fumadocs-ui/components/callout'

<Callout type="info" title="Part of EdgeVec">
This page is part of the [EdgeVec](/docs/database/edgevec) vector database documentation, which is part of [Database](/docs/database).
</Callout>

# Use Cases

EdgeVec enables powerful AI-powered search and retrieval patterns. This guide covers common use cases with implementation examples.

## Retrieval-Augmented Generation (RAG)

RAG combines vector search with LLM generation for grounded responses.

### Basic RAG Pipeline

```typescript
import { createFilteredIndex } from 'db/edgevec/filtered-search'

// 1. Create index for your knowledge base
const knowledgeBase = createFilteredIndex({
  dimensions: 1536,  // OpenAI ada-002
  metric: 'cosine',
  M: 16,
  efConstruction: 200
})

// 2. Index your documents
async function indexDocuments(documents: Document[]) {
  for (const doc of documents) {
    const embedding = await embedText(doc.content)
    knowledgeBase.insert(doc.id, embedding, {
      title: doc.title,
      source: doc.source,
      updatedAt: doc.updatedAt
    })
  }
}

// 3. RAG query function
async function ragQuery(question: string): Promise<string> {
  // Embed the question
  const queryEmbedding = await embedText(question)

  // Retrieve relevant documents
  const results = knowledgeBase.search(queryEmbedding, {
    k: 5,
    ef: 100
  })

  // Build context from retrieved documents
  const context = results
    .map(r => documents.get(r.id).content)
    .join('\n\n---\n\n')

  // Generate response with LLM
  const response = await llm.complete({
    prompt: `Answer based on the following context:

${context}

Question: ${question}

Answer:`,
    temperature: 0.7
  })

  return response
}
```

### Multi-Turn Conversation RAG

Track conversation history for context-aware retrieval:

```typescript
interface ConversationContext {
  messages: Array<{ role: 'user' | 'assistant'; content: string }>
  retrievedDocs: Set<string>
}

async function conversationalRag(
  question: string,
  context: ConversationContext
): Promise<string> {
  // Combine question with recent conversation for better retrieval
  const searchQuery = context.messages.length > 0
    ? `${context.messages.slice(-2).map(m => m.content).join(' ')} ${question}`
    : question

  const queryEmbedding = await embedText(searchQuery)

  // Retrieve, excluding already-seen documents
  const results = knowledgeBase.search(queryEmbedding, {
    k: 5,
    ef: 100,
    filter: {
      id: { $nin: Array.from(context.retrievedDocs) }
    }
  })

  // Track retrieved docs
  results.forEach(r => context.retrievedDocs.add(r.id))

  // Build augmented prompt
  const newContext = results
    .map(r => documents.get(r.id).content)
    .join('\n\n---\n\n')

  const conversationHistory = context.messages
    .map(m => `${m.role}: ${m.content}`)
    .join('\n')

  const response = await llm.complete({
    prompt: `Previous conversation:
${conversationHistory}

Additional context from knowledge base:
${newContext}

User: ${question}
Assistant:`,
    temperature: 0.7
  })

  // Update context
  context.messages.push(
    { role: 'user', content: question },
    { role: 'assistant', content: response }
  )

  return response
}
```

### RAG with Source Citations

Return sources with answers:

```typescript
interface RagResponse {
  answer: string
  sources: Array<{
    id: string
    title: string
    score: number
    excerpt: string
  }>
}

async function ragWithCitations(question: string): Promise<RagResponse> {
  const queryEmbedding = await embedText(question)

  const results = knowledgeBase.search(queryEmbedding, { k: 5 })

  const sources = results.map(r => {
    const doc = documents.get(r.id)
    return {
      id: r.id,
      title: doc.title,
      score: r.score,
      excerpt: doc.content.slice(0, 200) + '...'
    }
  })

  const context = sources
    .map((s, i) => `[${i + 1}] ${s.title}\n${documents.get(s.id).content}`)
    .join('\n\n')

  const answer = await llm.complete({
    prompt: `Answer the question using the numbered sources. Cite sources as [1], [2], etc.

Sources:
${context}

Question: ${question}

Answer with citations:`,
    temperature: 0.3
  })

  return { answer, sources }
}
```

## Semantic Search

Search by meaning rather than keywords.

### Document Search

```typescript
// Index documents with rich metadata
async function indexDocument(doc: Document) {
  const embedding = await embedText(doc.content)

  knowledgeBase.insert(doc.id, embedding, {
    title: doc.title,
    author: doc.author,
    category: doc.category,
    tags: doc.tags,
    publishedAt: doc.publishedAt,
    wordCount: doc.content.split(' ').length
  })
}

// Search with filters
async function searchDocuments(query: string, options: SearchOptions) {
  const embedding = await embedText(query)

  return knowledgeBase.search(embedding, {
    k: options.limit ?? 10,
    ef: 100,
    filter: {
      $and: [
        options.category ? { category: options.category } : {},
        options.author ? { author: options.author } : {},
        options.tags ? { tags: { $contains: options.tags } } : {},
        options.dateRange ? {
          publishedAt: {
            $gte: options.dateRange.start,
            $lte: options.dateRange.end
          }
        } : {}
      ].filter(f => Object.keys(f).length > 0)
    }
  })
}
```

### Code Search

Search code by description:

```typescript
// Index code snippets
async function indexCodebase(files: CodeFile[]) {
  for (const file of files) {
    // Generate embedding from code + docstrings
    const searchableText = extractSearchableContent(file)
    const embedding = await embedText(searchableText)

    codeIndex.insert(file.path, embedding, {
      language: file.language,
      type: file.type, // 'function', 'class', 'module'
      name: file.name,
      signature: file.signature,
      dependencies: file.dependencies
    })
  }
}

// Search code by natural language
async function searchCode(query: string, language?: string) {
  const embedding = await embedText(query)

  return codeIndex.search(embedding, {
    k: 10,
    filter: language ? { language } : undefined
  })
}

// Example: "function that parses JSON from a file"
const results = await searchCode('function that parses JSON from a file', 'typescript')
```

### Image Search

Search images by text description (with CLIP embeddings):

```typescript
// Index images with CLIP embeddings
async function indexImages(images: Image[]) {
  for (const img of images) {
    // Use CLIP model for image embedding
    const embedding = await embedImage(img.data)

    imageIndex.insert(img.id, embedding, {
      filename: img.filename,
      width: img.width,
      height: img.height,
      format: img.format,
      tags: img.tags
    })
  }
}

// Text-to-image search
async function searchImages(textQuery: string) {
  // Use CLIP text encoder
  const embedding = await embedText(textQuery, { model: 'clip' })

  return imageIndex.search(embedding, { k: 20 })
}

// Example: "sunset over mountains"
const results = await searchImages('sunset over mountains')
```

## Recommendation Systems

Use vector similarity for personalized recommendations.

### Content-Based Recommendations

```typescript
// Index products with embeddings
async function indexProducts(products: Product[]) {
  for (const product of products) {
    // Embed product description + attributes
    const text = `${product.name} ${product.description} ${product.tags.join(' ')}`
    const embedding = await embedText(text)

    productIndex.insert(product.id, embedding, {
      category: product.category,
      price: product.price,
      brand: product.brand,
      inStock: product.inStock,
      rating: product.rating
    })
  }
}

// Find similar products
async function getSimilarProducts(productId: string, limit = 10) {
  const product = await getProduct(productId)
  const productVector = productIndex.getVector(productId)

  if (!productVector) return []

  return productIndex.search(productVector, {
    k: limit + 1, // +1 to exclude self
    filter: {
      id: { $ne: productId },
      category: product.category,
      inStock: true
    }
  }).slice(0, limit)
}
```

### User-Based Recommendations

Track user preferences as vectors:

```typescript
interface UserProfile {
  id: string
  // Average embedding of liked items
  preferenceVector: Float32Array
  // Interaction history
  liked: string[]
  viewed: string[]
}

async function updateUserProfile(userId: string, interaction: Interaction) {
  const user = await getUserProfile(userId)
  const itemVector = productIndex.getVector(interaction.itemId)

  if (!itemVector) return

  if (interaction.type === 'like') {
    user.liked.push(interaction.itemId)

    // Update preference vector (weighted average)
    const weight = 1 / user.liked.length
    for (let i = 0; i < user.preferenceVector.length; i++) {
      user.preferenceVector[i] =
        user.preferenceVector[i] * (1 - weight) +
        itemVector[i] * weight
    }
  }

  await saveUserProfile(user)
}

// Get personalized recommendations
async function getRecommendations(userId: string, limit = 20) {
  const user = await getUserProfile(userId)

  if (!user.preferenceVector) {
    // Cold start: return popular items
    return getPopularProducts(limit)
  }

  // Search using user's preference vector
  const excludeIds = [...user.liked, ...user.viewed.slice(-100)]

  return productIndex.search(user.preferenceVector, {
    k: limit,
    filter: {
      id: { $nin: excludeIds },
      inStock: true
    }
  })
}
```

### Collaborative Filtering Hybrid

Combine content and collaborative signals:

```typescript
async function hybridRecommendations(userId: string, limit = 20) {
  const user = await getUserProfile(userId)

  // 1. Content-based candidates
  const contentCandidates = user.preferenceVector
    ? await productIndex.search(user.preferenceVector, { k: 50 })
    : []

  // 2. Collaborative candidates (items liked by similar users)
  const similarUsers = await userIndex.search(user.preferenceVector, { k: 10 })
  const collaborativeCandidates = new Set<string>()

  for (const simUser of similarUsers) {
    const theirLikes = await getUserLikes(simUser.id)
    theirLikes.forEach(id => collaborativeCandidates.add(id))
  }

  // 3. Merge and score
  const scores = new Map<string, number>()

  // Content score
  for (const c of contentCandidates) {
    scores.set(c.id, c.score * 0.6)
  }

  // Collaborative boost
  for (const id of collaborativeCandidates) {
    const existing = scores.get(id) ?? 0
    scores.set(id, existing + 0.4)
  }

  // Sort and return
  return Array.from(scores.entries())
    .sort((a, b) => b[1] - a[1])
    .slice(0, limit)
    .map(([id, score]) => ({ id, score }))
}
```

## Hybrid Search

Combine vector and keyword search for best results.

### Vector + Full-Text Fusion

```typescript
interface HybridResult {
  id: string
  vectorScore: number
  textScore: number
  fusedScore: number
}

async function hybridSearch(
  query: string,
  options: { vectorWeight?: number; k?: number } = {}
): Promise<HybridResult[]> {
  const vectorWeight = options.vectorWeight ?? 0.7
  const textWeight = 1 - vectorWeight
  const k = options.k ?? 10

  // Vector search
  const queryEmbedding = await embedText(query)
  const vectorResults = await knowledgeBase.search(queryEmbedding, { k: k * 2 })

  // Full-text search (using DO SQLite FTS5)
  const textResults = await fullTextSearch(query, k * 2)

  // Merge results with RRF (Reciprocal Rank Fusion)
  const scores = new Map<string, HybridResult>()

  vectorResults.forEach((r, rank) => {
    const score = 1 / (rank + 60) // RRF constant = 60
    scores.set(r.id, {
      id: r.id,
      vectorScore: r.score,
      textScore: 0,
      fusedScore: score * vectorWeight
    })
  })

  textResults.forEach((r, rank) => {
    const score = 1 / (rank + 60)
    const existing = scores.get(r.id)
    if (existing) {
      existing.textScore = r.score
      existing.fusedScore += score * textWeight
    } else {
      scores.set(r.id, {
        id: r.id,
        vectorScore: 0,
        textScore: r.score,
        fusedScore: score * textWeight
      })
    }
  })

  return Array.from(scores.values())
    .sort((a, b) => b.fusedScore - a.fusedScore)
    .slice(0, k)
}
```

### Query Classification

Route queries to appropriate search method:

```typescript
type QueryType = 'semantic' | 'exact' | 'hybrid'

function classifyQuery(query: string): QueryType {
  // Exact match indicators
  if (query.startsWith('"') && query.endsWith('"')) return 'exact'
  if (query.includes('exact:')) return 'exact'

  // Semantic indicators
  const semanticPatterns = [
    /what is/i, /how to/i, /explain/i, /similar to/i,
    /like/i, /about/i, /related to/i
  ]
  if (semanticPatterns.some(p => p.test(query))) return 'semantic'

  // Default to hybrid
  return 'hybrid'
}

async function smartSearch(query: string, options = {}) {
  const queryType = classifyQuery(query)

  switch (queryType) {
    case 'exact':
      return fullTextSearch(query.replace(/^"|"$/g, ''), options)
    case 'semantic':
      return vectorSearch(query, options)
    case 'hybrid':
    default:
      return hybridSearch(query, options)
  }
}
```

## Multi-Tenant Vector Search

Isolate data between tenants.

### Namespace Isolation

```typescript
// Each tenant gets their own namespace
async function createTenantIndex(tenantId: string) {
  return env.EDGEVEC.createIndex(tenantId, 'documents', {
    dimensions: 1536,
    metric: 'cosine'
  })
}

async function tenantSearch(tenantId: string, query: string, k = 10) {
  const embedding = await embedText(query)

  return env.EDGEVEC.search(tenantId, 'documents', embedding, { k })
}
```

### Filter-Based Isolation

Single index with tenant filter:

```typescript
// Insert with tenant ID
await env.EDGEVEC.insert('shared', 'documents', [
  {
    id: 'doc-1',
    values: embedding,
    metadata: {
      tenantId: 'tenant-a',
      // ... other metadata
    }
  }
])

// Search with tenant filter (always applied)
async function tenantSearch(tenantId: string, query: string, additionalFilters = {}) {
  const embedding = await embedText(query)

  return env.EDGEVEC.search('shared', 'documents', embedding, {
    k: 10,
    filter: {
      $and: [
        { tenantId }, // Always filter by tenant
        additionalFilters
      ]
    }
  })
}
```

## Anomaly Detection

Use vector distance for outlier detection.

```typescript
async function detectAnomalies(
  dataPoints: DataPoint[],
  threshold: number
): Promise<DataPoint[]> {
  // Build index of normal data
  const normalIndex = createFilteredIndex({
    dimensions: dataPoints[0].features.length,
    metric: 'l2', // L2 distance for anomaly detection
    M: 16,
    efConstruction: 100
  })

  for (const point of dataPoints) {
    normalIndex.insert(point.id, new Float32Array(point.features), {
      timestamp: point.timestamp
    })
  }

  // Find anomalies (points far from their nearest neighbors)
  const anomalies: DataPoint[] = []

  for (const point of dataPoints) {
    const vector = new Float32Array(point.features)
    const neighbors = normalIndex.search(vector, { k: 6 }) // k=6 to exclude self

    // Average distance to 5 nearest neighbors (excluding self)
    const avgDistance = neighbors
      .filter(n => n.id !== point.id)
      .slice(0, 5)
      .reduce((sum, n) => sum + Math.abs(n.score), 0) / 5

    if (avgDistance > threshold) {
      anomalies.push(point)
    }
  }

  return anomalies
}
```

## Performance Patterns

### Batch Operations

Process vectors in batches for efficiency:

```typescript
import { BatchInserter } from 'db/edgevec/batch-insert'

async function bulkIndex(documents: Document[]) {
  const inserter = new BatchInserter(knowledgeBase, {
    chunkSize: 100,
    onProgress: (p) => console.log(`${Math.round(p * 100)}% complete`)
  })

  const vectors = await Promise.all(
    documents.map(async doc => ({
      id: doc.id,
      vector: await embedText(doc.content),
      metadata: { title: doc.title, source: doc.source }
    }))
  )

  const result = await inserter.insertBatch(vectors)
  console.log(`Inserted: ${result.inserted}, Failed: ${result.failed}`)
}
```

### Caching Embeddings

Cache embeddings for repeated queries:

```typescript
import { EmbeddingCache } from 'db/edgevec/embedding-cache'

const cache = new EmbeddingCache({
  dimensions: 1536,
  maxEntries: 10000,
  maxMemoryBytes: 50 * 1024 * 1024 // 50MB
})

async function getEmbedding(text: string): Promise<Float32Array> {
  const cacheKey = hashText(text)
  const cached = cache.get(cacheKey)

  if (cached) {
    return cached.vector
  }

  const embedding = await embedText(text)
  cache.set(cacheKey, embedding)

  return embedding
}
```

## Related

- [EdgeVec Overview](/docs/database/edgevec) - Full system documentation
- [HNSW Indexing](/docs/database/edgevec/hnsw) - Graph-based search algorithm
- [Filtering](/docs/database/edgevec/filtering) - Metadata filtering
- [Embeddings](/docs/database/edgevec/embeddings) - Embedding provider integrations
- [RAG Guide](/docs/guides/rag) - Comprehensive RAG implementation guide
