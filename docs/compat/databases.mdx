---
title: Databases
description: API-compatible database SDKs for Postgres, MySQL, MongoDB, Supabase, Firebase, and more.
---

# Database Compat SDKs

Twelve database APIs, rebuilt on Durable Objects. Your existing code works. It just scales to millions of agents.

## The Problem

When you spin up 10,000 AI agents:

- **Postgres** exhausts connection pools (max ~200 connections per instance)
- **MongoDB** hits write lock contention (single writer per collection)
- **Supabase** rate limits kick in (connection pooling capped)
- **Firebase** throttles concurrent operations

The solution: per-tenant isolation in Durable Objects. Each tenant gets their own single-threaded isolate. No connection pools. No locks. No coordination overhead.

## Quick Start

```typescript
// One-line migration
import { createClient } from '@dotdo/supabase'

const supabase = createClient(url, key)
const { data } = await supabase.from('users').select('*')
```

The compat layer automatically:
- Routes queries to the correct shard
- Handles connection lifecycle
- Tiers data between hot (SQLite) and cold (R2)

## Available SDKs

### @dotdo/postgres

PostgreSQL wire protocol compatible. Use your existing postgres driver.

```typescript
import { Pool } from '@dotdo/postgres'

const pool = new Pool({
  connectionString: process.env.DATABASE_URL,
  shardKey: 'tenant_id',
})

const result = await pool.query(
  'SELECT * FROM orders WHERE tenant_id = $1',
  [tenantId]
)
```

Under the hood:
- Queries with `tenant_id` route to specific shards
- Queries without shard key fan out to all shards
- Connection pooling replaced by DO isolation

### @dotdo/mysql

MySQL wire protocol compatible.

```typescript
import { createConnection } from '@dotdo/mysql'

const connection = await createConnection({
  host: 'localhost',
  user: 'root',
  database: 'myapp',
  shardKey: 'organization_id',
})

const [rows] = await connection.execute(
  'SELECT * FROM users WHERE organization_id = ?',
  [orgId]
)
```

### @dotdo/mongodb

MongoDB driver compatible. Supports the full CRUD API.

```typescript
import { DocumentStore } from '@dotdo/mongodb'

const store = new DocumentStore({
  shardKey: 'workspace_id',
})

const db = store.db('myapp')
const users = db.collection('users')

// Sharded by workspace_id
const user = await users.findOne({
  workspace_id: 'ws-123',
  email: 'user@example.com.ai'
})

// Insert automatically routes to correct shard
await users.insertOne({
  workspace_id: 'ws-123',
  email: 'new@example.com.ai',
  name: 'New User',
})
```

Key differences from hosted MongoDB:
- No replica sets (DOs handle durability)
- No sharding configuration (automatic)
- No connection pool tuning (single-threaded per shard)

### @dotdo/supabase

Full Supabase client SDK compatibility.

```typescript
import { createClient } from '@dotdo/supabase'

const supabase = createClient(url, key)

// Standard queries work
const { data, error } = await supabase
  .from('profiles')
  .select('*')
  .eq('tenant_id', tenantId)

// Real-time subscriptions backed by DO WebSockets
const channel = supabase
  .channel('room1')
  .on('postgres_changes',
    { event: 'INSERT', schema: 'public', table: 'messages' },
    (payload) => console.log(payload)
  )
  .subscribe()

// Auth works (backed by org.ai identity)
const { data: { user } } = await supabase.auth.getUser()
```

### @dotdo/firebase

Firebase Admin SDK compatible.

```typescript
import { initializeApp, getFirestore } from '@dotdo/firebase'

const app = initializeApp({
  projectId: 'my-project',
  shardKey: 'userId',
})

const db = getFirestore(app)

// Document operations
const docRef = db.collection('users').doc('user-123')
await docRef.set({ name: 'Alice', age: 30 })
const doc = await docRef.get()

// Queries with automatic sharding
const snapshot = await db
  .collection('orders')
  .where('userId', '==', 'user-123')
  .orderBy('createdAt', 'desc')
  .limit(10)
  .get()
```

### @dotdo/neon

Neon serverless Postgres driver compatible.

```typescript
import { neon } from '@dotdo/neon'

const sql = neon(process.env.DATABASE_URL)

const users = await sql`
  SELECT * FROM users
  WHERE tenant_id = ${tenantId}
`
```

### @dotdo/planetscale

PlanetScale serverless driver compatible.

```typescript
import { connect } from '@dotdo/planetscale'

const conn = connect({
  host: process.env.DATABASE_HOST,
  username: process.env.DATABASE_USERNAME,
  password: process.env.DATABASE_PASSWORD,
})

const results = await conn.execute(
  'SELECT * FROM products WHERE store_id = ?',
  [storeId]
)
```

### @dotdo/turso

Turso/libsql compatible. Actually uses libsql under the hood.

```typescript
import { createClient } from '@dotdo/turso'

const client = createClient({
  url: 'libsql://your-database.turso.io',
  authToken: process.env.TURSO_AUTH_TOKEN,
})

const result = await client.execute({
  sql: 'SELECT * FROM events WHERE org_id = ?',
  args: [orgId],
})
```

### @dotdo/duckdb

DuckDB for analytics queries. Runs directly in the Worker.

```typescript
import { createDuckDB } from '@dotdo/duckdb'

const db = await createDuckDB()

// Query Parquet files directly from R2
// Use parameterized queries to prevent SQL injection
const result = await db.query(`
  SELECT
    date_trunc('day', created_at) as day,
    count(*) as signups
  FROM read_parquet('r2://analytics/users/*.parquet')
  WHERE tenant_id = $1
  GROUP BY 1
  ORDER BY 1
`, [tenantId])
```

### @dotdo/cockroach

CockroachDB compatible. Uses the Postgres wire protocol.

```typescript
import { Pool } from '@dotdo/cockroach'

const pool = new Pool({
  connectionString: process.env.COCKROACH_URL,
})

// Supports CockroachDB-specific features
const result = await pool.query(`
  SELECT * FROM orders
  AS OF SYSTEM TIME '-10s'
  WHERE region = $1
`, [region])
```

### @dotdo/tidb

TiDB compatible. MySQL wire protocol.

```typescript
import { createConnection } from '@dotdo/tidb'

const conn = await createConnection({
  host: process.env.TIDB_HOST,
  port: 4000,
  user: 'root',
  database: 'test',
})
```

### @dotdo/couchdb

CouchDB document store compatible.

```typescript
import { CouchDB } from '@dotdo/couchdb'

const couch = new CouchDB({
  url: 'http://localhost:5984',
  shardKey: 'type',
})

const db = couch.use('mydb')

// Document operations
await db.insert({ _id: 'doc-1', type: 'user', name: 'Alice' })
const doc = await db.get('doc-1')

// Views and queries
const result = await db.view('users', 'by_name', { key: 'Alice' })
```

## Sharding Deep Dive

All database compat SDKs use the ShardRouter for automatic data distribution.

### Shard Key Selection

Choose a shard key that:
- Is present in most queries
- Distributes data evenly
- Groups related data together

```typescript
// Good: tenant_id groups all tenant data
const pool = new Pool({
  shardKey: 'tenant_id', // All queries for a tenant hit same shard
})

// Bad: created_at would spread related data across shards
const pool = new Pool({
  shardKey: 'created_at', // Related records on different shards
})
```

### Query Routing

```typescript
// Routed to single shard (fast)
await pool.query(
  'SELECT * FROM orders WHERE tenant_id = $1',
  [tenantId]
)

// Fan-out to all shards (slower, but supported)
await pool.query(
  'SELECT count(*) FROM orders WHERE status = $1',
  ['pending']
)

// Aggregation happens in the Worker
const results = await router.queryAll('/aggregate')
const total = results.reduce((sum, r) => sum + r.data.count, 0)
```

### Shard Count

Default is 16 shards. Adjust based on data volume:

```typescript
const router = new ShardRouter(env.DO, {
  key: 'tenant_id',
  count: 64, // More shards for higher volume
  algorithm: 'consistent', // Minimal redistribution on resize
})
```

## Storage Tiers

Data automatically tiers between hot and cold storage:

```
Hot  → SQLite in DO (< 10ms latency)
Warm → Cloudflare R2 (< 100ms latency)
Cold → Iceberg Parquet (analytics queries)
```

### Configuring Tiers

```typescript
const pool = new Pool({
  tiers: {
    hot: {
      maxSize: '100MB',
      ttl: '7d',
    },
    warm: {
      storage: 'r2',
      compression: 'zstd',
    },
    cold: {
      format: 'parquet',
      partitionBy: ['year', 'month'],
    },
  },
})
```

### Querying Cold Data

```typescript
// Hot queries go to SQLite
const recent = await pool.query(
  'SELECT * FROM orders WHERE created_at > now() - interval \'7 days\''
)

// Cold queries go to DuckDB + Parquet
// Use parameterized queries to prevent SQL injection
const historical = await pool.queryAnalytics(`
  SELECT
    date_trunc('month', created_at) as month,
    sum(amount) as revenue
  FROM orders
  WHERE tenant_id = $1
  GROUP BY 1
`, [tenantId])
```

## Migration Patterns

### From Supabase Cloud

```typescript
// Before
import { createClient } from '@supabase/supabase-js'
const supabase = createClient(
  'https://xyz.supabase.co',
  'public-anon-key'
)

// After
import { createClient } from '@dotdo/supabase'
const supabase = createClient(
  process.env.DOTDO_URL,
  process.env.DOTDO_KEY
)

// Code stays the same
const { data } = await supabase.from('users').select('*')
```

### From MongoDB Atlas

```typescript
// Before
import { MongoClient } from 'mongodb'
const client = new MongoClient('mongodb+srv://...')

// After
import { DocumentStore } from '@dotdo/mongodb'
const store = new DocumentStore({
  shardKey: 'workspace_id', // Add shard key
})

// Code stays the same
const db = store.db('myapp')
const users = await db.collection('users').findOne({ email })
```

### From Firebase

```typescript
// Before
import { initializeApp } from 'firebase-admin/app'
import { getFirestore } from 'firebase-admin/firestore'

// After
import { initializeApp, getFirestore } from '@dotdo/firebase'

// Code stays the same
const db = getFirestore()
const doc = await db.collection('users').doc(userId).get()
```

## Performance Characteristics

| Operation | Latency | Notes |
|-----------|---------|-------|
| Single-shard read | < 10ms | SQLite in DO |
| Single-shard write | < 20ms | SQLite + DO persistence |
| Fan-out query | 50-200ms | Parallel to all shards |
| Cold storage read | 100-500ms | R2 + decompression |
| Analytics query | 1-10s | DuckDB on Parquet |

## Limitations

What's different from hosted services:

- **No cross-shard transactions** - Use saga patterns instead
- **No full-text search** - Use search compat SDKs instead
- **No stored procedures** - Logic lives in Workers
- **Eventual consistency** - Reads may lag writes by ~50ms

## Related

- [Messaging SDKs](/docs/compat/messaging) - Kafka, Redis, NATS, SQS
- [Search SDKs](/docs/compat/search) - Elasticsearch, Algolia, Meilisearch
- [Vector SDKs](/docs/compat/vector) - Pinecone, Qdrant, Weaviate
