---
title: Custom Agents
description: Build domain-specific AI agents for your industry
---

import { Callout } from 'fumadocs-ui/components/callout'

# Custom Agents

Build domain-specific agents for your industry. Legal reviewers. Healthcare coordinators. Financial analysts. Your domain, your agents.

<Callout type="info">
The declarative class property syntax shown below is the planned API. For production use with the current implementation, see the [Named Agents](/docs/agents/named-agents) documentation for working patterns, or use the `objects/Agent` base class with `registerTool()` method.
</Callout>

## Basic Agent

```typescript
import { Agent } from 'dotdo'

export class LegalReviewer extends Agent {
  name = 'Lexi'
  role = 'Legal'

  instructions = `You review contracts and legal documents.
    Flag risks. Suggest revisions. Never give legal advice.`
}

// Use it
const lexi = new LegalReviewer()
const reviewed = await lexi`review ${contract}`
```

That's it. A custom agent is a class with a name, role, and instructions.

## Agent Configuration

```typescript
import { Agent } from 'dotdo'

// Stop conditions (planned API - not yet exported from dotdo)
const stepCountIs = (n: number) => (step: number) => step >= n

export class FinancialAnalyst extends Agent {
  name = 'Finn'
  role = 'Financial Analyst'

  instructions = `You analyze financial data and reports.
    Focus on trends, anomalies, and actionable insights.
    Present numbers in context, not isolation.`

  // Model selection
  model = 'claude-opus-4-5-20251101'

  // Tool access
  tools = [
    this.spreadsheetAnalysis,
    this.marketDataLookup,
    this.chartGeneration,
  ]

  // Stop conditions
  stopWhen = stepCountIs(10)

  // Memory configuration
  memory = {
    type: 'persistent',
    maxTokens: 100000,
  }
}
```

## Agent with Tools

Agents become powerful when they have tools:

```typescript
import { Agent } from 'dotdo'
import { tool } from 'agents.do' // Tool definition helper
import { z } from 'zod'

const searchDatabase = tool({
  name: 'searchDatabase',
  description: 'Search the customer database',
  inputSchema: z.object({
    query: z.string(),
    limit: z.number().optional().default(10),
  }),
  execute: async ({ query, limit }) => {
    const results = await db.customers.search(query, limit)
    return results
  },
})

const sendEmail = tool({
  name: 'sendEmail',
  description: 'Send an email to a customer',
  inputSchema: z.object({
    to: z.string().email(),
    subject: z.string(),
    body: z.string(),
  }),
  execute: async ({ to, subject, body }) => {
    await email.send({ to, subject, body })
    return { sent: true }
  },
  permission: 'confirm', // Require human approval
})

export class CustomerSuccess extends Agent {
  name = 'Casey'
  role = 'Customer Success'

  instructions = `You help customers succeed with our product.
    Search for customer context before responding.
    Be helpful, never pushy.`

  tools = [searchDatabase, sendEmail]
}
```

## Permission Levels

Control what agents can do autonomously:

```typescript
const riskyTool = tool({
  name: 'deleteAccount',
  description: 'Delete a customer account',
  inputSchema: z.object({
    accountId: z.string(),
    reason: z.string(),
  }),
  execute: async ({ accountId, reason }) => {
    await accounts.delete(accountId, reason)
    return { deleted: true }
  },
  permission: 'deny', // Never allow automatically
})

const safeTool = tool({
  name: 'lookupAccount',
  description: 'Look up account details',
  inputSchema: z.object({
    accountId: z.string(),
  }),
  execute: async ({ accountId }) => {
    return accounts.get(accountId)
  },
  permission: 'auto', // Always allow
})

const sensitiveTool = tool({
  name: 'updateBilling',
  description: 'Update billing information',
  inputSchema: z.object({
    accountId: z.string(),
    billingInfo: z.object({
      address: z.string(),
      paymentMethod: z.string(),
    }),
  }),
  execute: async ({ accountId, billingInfo }) => {
    await billing.update(accountId, billingInfo)
    return { updated: true }
  },
  permission: 'confirm', // Ask human first
})
```

Permission levels:

| Level | Behavior |
|-------|----------|
| `auto` | Execute without confirmation |
| `confirm` | Ask human before executing |
| `deny` | Never execute, even if requested |

## Agent Hooks

Customize agent behavior at runtime:

```typescript
import { Agent } from 'dotdo'

export class AuditedAgent extends Agent {
  name = 'Audrey'
  role = 'Compliance'

  instructions = `You ensure compliance with regulations.`

  hooks = {
    onPreToolUse: async (toolCall) => {
      // Log every tool use
      await audit.log('tool_use', {
        tool: toolCall.name,
        arguments: toolCall.arguments,
        timestamp: new Date(),
      })

      // Block sensitive tools after hours
      if (isAfterHours() && toolCall.name === 'updateRecords') {
        return {
          action: 'deny',
          reason: 'Record updates not allowed after business hours',
        }
      }

      return { action: 'allow' }
    },

    onPostToolUse: async (toolCall, result) => {
      // Log results
      await audit.log('tool_result', {
        tool: toolCall.name,
        result,
        timestamp: new Date(),
      })
    },

    onStepFinish: async (step, stepNumber) => {
      // Monitor for concerning patterns
      if (step.text?.includes('delete') && step.text?.includes('all')) {
        await alerts.send('Potentially dangerous operation detected')
      }
    },
  }
}
```

## Multi-Agent Handoffs

Agents can hand off to specialists:

```typescript
import { Agent } from 'dotdo'

export class Receptionist extends Agent {
  name = 'Riley'
  role = 'Receptionist'

  instructions = `You're the first point of contact.
    Route requests to the right specialist.`

  handoffs = [technicalSupport, billing, sales]
}

export class TechnicalSupport extends Agent {
  name = 'Terry'
  role = 'Technical Support'

  instructions = `You solve technical problems.
    Escalate to engineering if you can't resolve.`

  handoffs = [engineering]
}

// Usage: Riley routes to Terry, Terry might escalate to engineering
const result = await riley`I can't log in and my billing is wrong`
```

## Spawning Subagents

Complex tasks can spawn specialized subagents:

```typescript
import { Agent } from 'dotdo'

export class ProjectManager extends Agent {
  name = 'Pat'
  role = 'Project Manager'

  instructions = `You coordinate complex projects.
    Break work into tasks and delegate.`

  canSpawnSubagents = true

  async planAndExecute(project: string) {
    // Plan the work
    const tasks = await this`break ${project} into tasks`

    // Spawn subagents for parallel work
    const results = await Promise.all(
      tasks.map(task =>
        this.spawnSubagent({
          prompt: `Complete: ${task}`,
          timeout: 300000, // 5 minutes
        })
      )
    )

    // Summarize results
    return this`summarize the results: ${results}`
  }
}
```

## Agent with Memory

Persistent memory across conversations:

```typescript
import { Agent } from 'dotdo'

export class PersonalAssistant extends Agent {
  name = 'Alex'
  role = 'Personal Assistant'

  instructions = `You're a personal assistant.
    Remember user preferences and past interactions.`

  memory = {
    type: 'persistent',
    connection: process.env.DATABASE_URL,
    maxTokens: 100000,
  }
}

// Alex remembers previous conversations
const alex = new PersonalAssistant({ userId: 'user_123' })

await alex`I prefer morning meetings`
// ... days later ...
await alex`schedule a meeting with the team`
// Alex schedules it in the morning because it remembers
```

## Voice Agents

Build voice-enabled agents:

```typescript
import { Agent } from 'dotdo'

export class PhoneSupport extends Agent {
  name = 'Phoebe'
  role = 'Phone Support'

  instructions = `You handle phone support calls.
    Be conversational and helpful.
    Keep responses brief for voice.`

  voice = {
    transcriber: {
      provider: 'deepgram',
      model: 'nova-2',
      language: 'en-US',
    },
    voice: {
      provider: 'elevenlabs',
      voiceId: 'rachel',
      speed: 1.0,
    },
    bargeIn: true, // Allow interruptions
    silenceTimeoutMs: 2000,
  }
}
```

## Registering Custom Agents (Planned)

<Callout type="info">
The `registerAgent` function is part of the planned API. Currently, use the factory pattern shown in `agents/named/factory.ts` to create named agent functions.
</Callout>

Make your agents available like named agents:

```typescript
// Planned API
import { registerAgent } from 'dotdo'

// Register your custom agents
registerAgent('lexi', new LegalReviewer())
registerAgent('finn', new FinancialAnalyst())
registerAgent('casey', new CustomerSuccess())

// Now use them with template literal syntax
import { lexi, finn, casey } from 'your-agents'

await lexi`review ${contract}`
await finn`analyze ${quarterlyReport}`
await casey`help ${customer} with ${issue}`
```

## Industry Examples

### Healthcare

```typescript
export class CareCoordinator extends Agent {
  name = 'Clara'
  role = 'Care Coordinator'

  instructions = `You coordinate patient care.
    Never provide medical advice.
    Always recommend consulting healthcare providers.
    HIPAA compliance is mandatory.`

  tools = [
    scheduleAppointment,
    sendReminder,
    lookupProvider,
  ]
}
```

### Legal

```typescript
export class ContractReviewer extends Agent {
  name = 'Lexi'
  role = 'Contract Reviewer'

  instructions = `You review contracts for risks.
    Flag unusual clauses.
    Never provide legal advice.
    Always recommend consulting an attorney.`

  tools = [
    searchPrecedents,
    flagClause,
    suggestRevision,
  ]
}
```

### Finance

```typescript
export class FraudDetector extends Agent {
  name = 'Frank'
  role = 'Fraud Analyst'

  instructions = `You analyze transactions for fraud patterns.
    Flag suspicious activity.
    Document your reasoning.
    Escalate high-risk cases immediately.`

  tools = [
    analyzeTransaction,
    flagForReview,
    escalateToSecurity,
  ]

  hooks = {
    onPreToolUse: async (toolCall) => {
      if (toolCall.name === 'escalateToSecurity') {
        // Always require human approval for escalation
        return {
          action: 'confirm',
          message: 'Confirm escalation to security team?',
        }
      }
      return { action: 'allow' }
    },
  }
}
```

## Best Practices

### Clear Instructions

```typescript
// Bad: vague
instructions = `Help users with stuff.`

// Good: specific
instructions = `You help users troubleshoot login issues.
  First, verify their email address.
  Then, check account status.
  If locked, explain the unlock process.
  If technical issue, gather error details and escalate.`
```

### Appropriate Tool Access

```typescript
// Bad: too many permissions
tools = [readDatabase, writeDatabase, deleteDatabase, sendEmail, makePayment]

// Good: minimal necessary permissions
tools = [readDatabase, sendNotification]
```

### Guardrails

```typescript
// Always add guardrails for sensitive operations
hooks = {
  onPreToolUse: async (toolCall) => {
    // Rate limit
    if (await rateLimiter.isExceeded(toolCall.name)) {
      return { action: 'deny', reason: 'Rate limit exceeded' }
    }

    // Audit
    await audit.log(toolCall)

    return { action: 'allow' }
  },
}
```

### Testing Agents

Testing AI agents requires a multi-layered approach: deterministic unit tests with mocks, integration tests with real LLMs, and CI/CD pipeline configuration for automated testing.

#### Unit Testing with Mock Providers

Use mock providers for fast, deterministic tests that don't require API calls:

```typescript
import { createMockProvider, mockResponses, fixtures } from 'agents/testing'
import { describe, it, expect } from 'vitest'

describe('LegalReviewer', () => {
  it('flags risky clauses', async () => {
    const provider = createMockProvider({
      responses: [
        mockResponses.text('Found 3 risky clauses: unlimited liability, auto-renewal, non-compete...')
      ]
    })

    const lexi = provider.createAgent({
      id: 'lexi',
      name: 'Lexi',
      instructions: 'You review contracts and flag risks.',
      model: 'mock',
    })

    const result = await lexi.run({ prompt: `review ${testContract}` })

    expect(result.text).toContain('risky clauses')
  })

  it('handles tool calls in sequence', async () => {
    const provider = createMockProvider({
      responses: [
        mockResponses.toolCall('searchPrecedents', { clause: 'non-compete' }),
        mockResponses.text('Based on precedent search, this clause is enforceable in 40 states.')
      ]
    })

    const lexi = provider.createAgent({
      id: 'lexi',
      name: 'Lexi',
      instructions: 'Search precedents before providing analysis.',
      model: 'mock',
      tools: [searchPrecedentsTool],
    })

    const result = await lexi.run({ prompt: 'Analyze non-compete clause' })

    expect(result.toolCalls).toHaveLength(1)
    expect(result.toolCalls[0].name).toBe('searchPrecedents')
    expect(result.steps).toBe(2)
  })
})
```

#### Real Integration Testing

For verifying agent behavior with actual LLM providers, use conditional tests that run only when API keys are available:

```typescript
import { describe, it, expect } from 'vitest'
import { createClaudeProvider } from 'agents/providers/claude'
import { createOpenAIProvider } from 'agents/providers/openai'

describe('LegalReviewer Integration', () => {
  const hasClaudeKey = !!process.env.ANTHROPIC_API_KEY
  const hasOpenAIKey = !!process.env.OPENAI_API_KEY

  it.skipIf(!hasClaudeKey)('reviews contracts with Claude', async () => {
    const provider = createClaudeProvider({
      apiKey: process.env.ANTHROPIC_API_KEY,
    })

    const agent = provider.createAgent({
      id: 'lexi-integration',
      name: 'Lexi',
      instructions: 'You review contracts. Flag any unlimited liability clauses.',
      model: 'claude-sonnet-4-20250514',
    })

    const result = await agent.run({
      prompt: 'Review this contract clause: "Client agrees to unlimited liability for all damages."'
    })

    // Verify the agent identified the risk
    expect(result.text.toLowerCase()).toMatch(/unlimited|liability|risk|concern/)
  }, { timeout: 30000 })

  it.skipIf(!hasOpenAIKey)('reviews contracts with OpenAI', async () => {
    const provider = createOpenAIProvider({
      apiKey: process.env.OPENAI_API_KEY,
    })

    const agent = provider.createAgent({
      id: 'lexi-openai',
      name: 'Lexi',
      instructions: 'You review contracts. Flag any unlimited liability clauses.',
      model: 'gpt-4o',
    })

    const result = await agent.run({
      prompt: 'Review this contract clause: "Client agrees to unlimited liability for all damages."'
    })

    expect(result.text.toLowerCase()).toMatch(/unlimited|liability|risk|concern/)
  }, { timeout: 30000 })
})
```

<Callout type="warning" title="Cost Considerations">
Integration tests with real LLMs incur API costs. Estimate costs before running:
- Claude Sonnet: ~$3/1M input tokens, ~$15/1M output tokens
- GPT-4o: ~$2.50/1M input tokens, ~$10/1M output tokens
- Use `maxSteps: 3` to limit runaway loops
- Consider using cheaper models (Claude Haiku, GPT-4o-mini) for CI tests
</Callout>

#### Environment Setup for Testing

Configure environment variables for different testing scenarios:

```bash
# .env.test - Local test environment
ANTHROPIC_API_KEY=sk-ant-test-...
OPENAI_API_KEY=sk-test-...
AGENT_TEST_MODE=integration  # or 'mock' for unit tests only

# Cost limits (optional)
MAX_TOKENS_PER_TEST=1000
MAX_API_CALLS_PER_RUN=5
```

```typescript
// vitest.setup.ts
import { beforeAll, afterAll } from 'vitest'
import { enableMockMode, disableMockMode } from 'agents/named'

beforeAll(() => {
  // Use mock mode by default unless explicitly testing integration
  if (process.env.AGENT_TEST_MODE !== 'integration') {
    enableMockMode()
  }
})

afterAll(() => {
  disableMockMode()
})
```

#### Snapshot Testing for Agent Responses

While LLM outputs are non-deterministic, you can snapshot test structured outputs:

```typescript
import { describe, it, expect } from 'vitest'
import { createMockProvider, mockResponses } from 'agents/testing'

describe('Structured Output Snapshots', () => {
  it('produces consistent review format', async () => {
    const provider = createMockProvider({
      responses: [
        mockResponses.text(JSON.stringify({
          riskLevel: 'high',
          issues: ['unlimited liability', 'no termination clause'],
          recommendations: ['Add liability cap', 'Include 30-day notice period']
        }))
      ]
    })

    const agent = provider.createAgent({
      id: 'structured-reviewer',
      name: 'Lexi',
      instructions: 'Return JSON with riskLevel, issues, and recommendations.',
      model: 'mock',
    })

    const result = await agent.run({ prompt: 'Review contract' })
    const parsed = JSON.parse(result.text)

    // Snapshot the structure, not exact values
    expect(parsed).toMatchObject({
      riskLevel: expect.any(String),
      issues: expect.any(Array),
      recommendations: expect.any(Array),
    })
  })
})
```

#### Golden File Testing Pattern

For testing against expected baseline responses:

```typescript
import { readFileSync, writeFileSync, existsSync } from 'fs'
import { describe, it, expect } from 'vitest'

const GOLDEN_DIR = '__goldens__'

function assertMatchesGolden(name: string, actual: string, update = false) {
  const goldenPath = `${GOLDEN_DIR}/${name}.txt`

  if (update || !existsSync(goldenPath)) {
    writeFileSync(goldenPath, actual)
    return
  }

  const expected = readFileSync(goldenPath, 'utf-8')

  // For LLM outputs, compare semantic similarity rather than exact match
  const actualWords = new Set(actual.toLowerCase().split(/\s+/))
  const expectedWords = new Set(expected.toLowerCase().split(/\s+/))
  const intersection = [...actualWords].filter(w => expectedWords.has(w))
  const similarity = intersection.length / Math.max(actualWords.size, expectedWords.size)

  expect(similarity).toBeGreaterThan(0.6) // 60% word overlap threshold
}

describe('Golden File Tests', () => {
  it('matches baseline contract review', async () => {
    const result = await agent.run({ prompt: 'Review standard NDA template' })
    assertMatchesGolden('nda-review', result.text, process.env.UPDATE_GOLDENS === 'true')
  })
})
```

#### Handling Flaky Tests

LLM responses vary between runs. Use these patterns to reduce flakiness:

```typescript
import { describe, it, expect, retry } from 'vitest'

describe('Agent Flaky Test Handling', () => {
  // Retry flaky integration tests
  it('identifies contract risks (with retry)', async () => {
    await retry(async () => {
      const result = await agent.run({ prompt: 'Identify risks in this contract' })

      // Use flexible assertions
      expect(result.text.length).toBeGreaterThan(50)
      expect(result.text.toLowerCase()).toMatch(/risk|issue|concern|flag/)
    }, { retries: 3, delay: 1000 })
  })

  // Test for semantic correctness, not exact output
  it('provides relevant analysis', async () => {
    const result = await agent.run({
      prompt: 'Summarize the key terms of an employment contract'
    })

    // Check for expected topics rather than exact text
    const topics = ['salary', 'benefits', 'termination', 'duties', 'confidential']
    const foundTopics = topics.filter(t =>
      result.text.toLowerCase().includes(t)
    )

    expect(foundTopics.length).toBeGreaterThanOrEqual(3)
  })

  // Use temperature 0 for more deterministic outputs
  it('produces consistent output with temperature 0', async () => {
    const provider = createClaudeProvider({
      apiKey: process.env.ANTHROPIC_API_KEY,
    })

    const agent = provider.createAgent({
      id: 'deterministic-agent',
      name: 'Lexi',
      instructions: 'List exactly 3 contract risks.',
      model: 'claude-sonnet-4-20250514',
      providerOptions: { temperature: 0 },
    })

    const result = await agent.run({ prompt: 'Analyze contract' })
    expect(result.text).toMatch(/1\.|2\.|3\./) // Numbered list
  })
})
```

#### CI/CD Integration

Configure GitHub Actions to run agent tests safely:

```yaml
# .github/workflows/agent-tests.yml
name: Agent Tests

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

jobs:
  unit-tests:
    name: Unit Tests (Mocked)
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: pnpm/action-setup@v4
        with:
          version: 10
      - uses: actions/setup-node@v4
        with:
          node-version: '22'
          cache: 'pnpm'
      - run: pnpm install --frozen-lockfile
      - run: pnpm vitest run --project=agents
        env:
          AGENT_TEST_MODE: mock

  integration-tests:
    name: Integration Tests (Real LLM)
    runs-on: ubuntu-latest
    # Only run on main branch to control costs
    if: github.ref == 'refs/heads/main'
    steps:
      - uses: actions/checkout@v4
      - uses: pnpm/action-setup@v4
        with:
          version: 10
      - uses: actions/setup-node@v4
        with:
          node-version: '22'
          cache: 'pnpm'
      - run: pnpm install --frozen-lockfile
      - run: pnpm vitest run agents/tests/ai-integration.test.ts
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          AGENT_TEST_MODE: integration
        timeout-minutes: 10
```

<Callout type="info" title="API Key Security">
Store API keys in GitHub Secrets, never in code. Use separate test keys with:
- Spending limits configured in provider dashboards
- Restricted permissions (no fine-tuning, limited models)
- Regular rotation schedule
</Callout>

#### Test Mode Configuration

Configure different provider behaviors for test vs production:

```typescript
// agents/config.ts
export function getTestProvider() {
  const mode = process.env.AGENT_TEST_MODE || 'mock'

  switch (mode) {
    case 'mock':
      return createMockProvider({
        responses: [mockResponses.text('Mock response')]
      })

    case 'integration':
      if (process.env.ANTHROPIC_API_KEY) {
        return createClaudeProvider({
          apiKey: process.env.ANTHROPIC_API_KEY,
          // Use cheaper model for tests
          defaultModel: 'claude-haiku-3-20240307',
        })
      }
      if (process.env.OPENAI_API_KEY) {
        return createOpenAIProvider({
          apiKey: process.env.OPENAI_API_KEY,
          defaultModel: 'gpt-4o-mini',
        })
      }
      throw new Error('No API key configured for integration tests')

    case 'production':
      return createClaudeProvider({
        apiKey: process.env.ANTHROPIC_API_KEY,
        defaultModel: 'claude-sonnet-4-20250514',
      })

    default:
      throw new Error(`Unknown test mode: ${mode}`)
  }
}

// Usage in tests
describe('Agent with configurable provider', () => {
  const provider = getTestProvider()

  it('works in any mode', async () => {
    const agent = provider.createAgent(fixtures.minimalAgent)
    const result = await agent.run({ prompt: 'Hello' })
    expect(result.text).toBeDefined()
  })
})
```

For comprehensive testing utilities and patterns, see the [Agent Testing Guide](/docs/guides/testing/agent-tests).
