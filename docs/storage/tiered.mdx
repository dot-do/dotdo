---
title: Tiered Storage
description: Automatic hot/warm/cold data management with zero egress costs
---

# Tiered Storage

dotdo uses a three-tier storage architecture that automatically moves data based on access patterns. Your data flows from hot working sets to cold analytics without manual intervention.

```
┌─────────────────────────────────────────────────────────────────────┐
│                    HOT: DO SQLite                                   │
│  Active working set. 50ms reads. 10GB per shard.                   │
└────────────────────────────┬────────────────────────────────────────┘
                             │ Cloudflare Pipelines (streaming)
                             ▼
┌─────────────────────────────────────────────────────────────────────┐
│                  WARM: R2 + Iceberg/Parquet                         │
│  Cross-DO queries. 100-150ms. Partitioned by (ns, type, visibility) │
└────────────────────────────┬────────────────────────────────────────┘
                             │ R2 SQL / ClickHouse
                             ▼
┌─────────────────────────────────────────────────────────────────────┐
│                  COLD: ClickHouse + R2 Archive                      │
│  Analytics, aggregations, time-series. Pennies per TB.              │
└─────────────────────────────────────────────────────────────────────┘
```

## Tier Comparison

| Tier | Storage | Latency | Capacity | Cost | Use Case |
|------|---------|---------|----------|------|----------|
| **Hot** | DO SQLite | ~50ms | 10GB/shard | $$ | Active working set, real-time state |
| **Warm** | R2 + Iceberg | 100-150ms | Unlimited | $ | Cross-DO queries, historical data |
| **Cold** | ClickHouse + R2 | Variable | Unlimited | $$$ | Analytics, aggregations, time-series |

## Quick Start

```typescript
import { TierConfig } from 'dotdo/db/core'

const config: TierConfig = {
  hot: 'sqlite',       // DO SQLite
  warm: 'r2',          // R2 object storage
  cold: 'archive',     // R2 Archive tier
  hotThreshold: '1GB', // Move to warm when > 1GB
  coldAfter: '90d',    // Archive after 90 days
}
```

## Automatic Data Flow

Data moves through tiers automatically based on:

1. **Size thresholds** - When hot tier exceeds limit
2. **Age** - Old data moves to colder tiers
3. **Access patterns** - Frequently accessed data stays hot

```typescript
// Hot tier: Real-time state in DO SQLite
const customer = await $.Customer('cust_abc').get()

// Warm tier: Cross-DO query via Iceberg
const orders = await $.query(`
  SELECT * FROM orders
  WHERE customer_id = 'cust_abc'
  AND created_at > NOW() - INTERVAL '30 days'
`)

// Cold tier: Analytics aggregation
const metrics = await $.analytics(`
  SELECT
    date_trunc('day', created_at) as day,
    count(*) as orders,
    sum(total) as revenue
  FROM orders
  WHERE created_at > NOW() - INTERVAL '1 year'
  GROUP BY 1
`)
```

## Zero Egress Architecture

The entire architecture runs on Cloudflare R2, which has **$0 egress fees**:

| Service | Egress | Storage |
|---------|--------|---------|
| **Cloudflare R2** | **$0** | $0.015/GB-mo |
| AWS S3 | $0.09/GB | $0.023/GB-mo |
| Snowflake | $0.05-0.12/GB | Credit-based |

A typical data warehouse that costs $10,000/month on AWS runs for under $1,000 on this stack.

## Hot Tier: DO SQLite

Fast, transactional storage for active data:

```typescript
// Direct DO access - ~50ms
const thing = await do.things.create({
  $type: 'Order',
  customer_id: 'cust_123',
  amount: 99.99,
})

// Query within DO - indexed, fast
const orders = await do.things.list({
  $type: 'Order',
  customer_id: 'cust_123',
})
```

**Characteristics:**
- 50ms typical latency
- 10GB per DO (shardable to 10TB)
- ACID transactions
- Full SQL via SQLite

### Columnar Optimization

dotdo uses columnar storage to minimize DO billing:

```
Traditional: 1000 records = 1000 row writes = $$$
Columnar:    1000 records = 6 row writes    = 99.4% savings
```

Each column is stored as a separate SQLite row, dramatically reducing read/write costs.

## Warm Tier: R2 + Iceberg

Cross-DO queries and historical data:

```typescript
// Iceberg table query - 100-150ms
const results = await $.query(`
  SELECT customer_id, count(*) as order_count
  FROM things
  WHERE $type = 'Order'
  AND created_at > '2024-01-01'
  GROUP BY customer_id
`)
```

**Characteristics:**
- 100-150ms latency
- Unlimited capacity
- Partitioned by namespace, type, visibility
- Direct Iceberg navigation for point lookups

### Iceberg Partitioning

Data is automatically partitioned for efficient queries:

```
R2 bucket structure:
└── things/
    ├── type=Order/
    │   ├── ns=tenant-a/
    │   │   └── 2024-01-15.parquet
    │   └── ns=tenant-b/
    │       └── 2024-01-15.parquet
    └── type=Customer/
        └── ...
```

## Cold Tier: ClickHouse + R2 Archive

Analytics and long-term retention:

```typescript
// ClickHouse aggregation
const analytics = await $.analytics(`
  SELECT
    toStartOfMonth(created_at) as month,
    countMerge(order_count) as orders,
    sumMerge(revenue) as total_revenue,
    avgMerge(order_value) as avg_order
  FROM orders_monthly_mv
  WHERE month >= '2023-01-01'
  GROUP BY month
  ORDER BY month
`)
```

**Characteristics:**
- Variable latency (depends on query complexity)
- Pennies per TB storage
- Materialized views for fast aggregations
- Time-series optimized

## Query Accelerator

The hot tier maintains indexes for fast Iceberg navigation:

```typescript
// DO SQLite stores lightweight indexes:
// - _ids: All thing IDs
// - _types: All type values
// - bloom:data.email: Bloom filter for email lookups
// - minmax:createdAt: Min/max for range pruning
```

| Query | Traditional | With Accelerator |
|-------|-------------|------------------|
| `SELECT COUNT(*)` | Scan all partitions | 1 DO row read |
| `WHERE type = 'User'` | Scan all | Partition pruning |
| `WHERE data.email = 'x'` | Scan all | Bloom filter check |
| `WHERE createdAt > date` | Scan all | Min/max pruning |

## Configuration

### TierConfig

```typescript
interface TierConfig {
  // Storage tier for each level
  hot?: 'sqlite' | 'r2' | 'archive'
  warm?: 'sqlite' | 'r2' | 'archive'
  cold?: 'sqlite' | 'r2' | 'archive'

  // Size threshold to move from hot to warm
  hotThreshold?: string  // e.g., '1GB', '500MB'

  // Time after which data moves to cold
  coldAfter?: string  // e.g., '90d', '24h', '60m'
}
```

### Default Configuration

```typescript
const DEFAULT_TIER_CONFIG: TierConfig = {
  hot: 'sqlite',
  warm: 'r2',
  cold: 'archive',
  hotThreshold: '1GB',
  coldAfter: '90d',
}
```

## Streaming Pipeline

Data flows between tiers via Cloudflare Pipelines:

```typescript
interface StreamConfig {
  // Pipeline binding name
  pipeline?: string

  // Output format
  sink: 'iceberg' | 'parquet' | 'json'

  // Transform before sending
  transform?: (event: unknown) => unknown

  // Batching options
  batchSize?: number      // Default: 1000
  flushInterval?: number  // Default: 60000ms
}
```

### Example Pipeline

```typescript
const streamConfig: StreamConfig = {
  pipeline: 'ANALYTICS_PIPELINE',
  sink: 'iceberg',
  transform: (event) => ({
    ...event,
    ingested_at: Date.now(),
  }),
  batchSize: 1000,
  flushInterval: 60000,
}
```

## Promotion and Demotion

Data can move between tiers based on access patterns:

```typescript
// Automatic demotion (based on age/size)
// After 90 days, data moves hot -> warm -> cold

// Manual promotion (bring cold data to hot)
await $.promote('thing_123', { from: 'cold', to: 'hot' })

// Access-based promotion (automatic)
// Frequently accessed cold data auto-promotes to warm
```

## Cost Optimization

### Storage Costs

| Tier | Cost/GB/month | 1TB/month |
|------|---------------|-----------|
| Hot (DO SQLite) | ~$0.50 | $500 |
| Warm (R2) | $0.015 | $15 |
| Cold (R2 Archive) | $0.010 | $10 |

### Query Costs

| Tier | Cost/query | Notes |
|------|------------|-------|
| Hot | ~$0.0001 | Per row read/write |
| Warm | ~$0 | R2 GET requests only |
| Cold | ~$0 | R2 Archive retrieval |

### Optimization Strategies

1. **Keep hot tier small** - Only active working set
2. **Aggressive demotion** - Move old data quickly
3. **Use materialized views** - Pre-aggregate in cold tier
4. **Query routing** - Direct queries to cheapest viable tier

## Best Practices

### 1. Size Your Hot Tier Appropriately

```typescript
// Good: Small, focused hot tier
const config: TierConfig = {
  hotThreshold: '500MB',  // Aggressive demotion
  coldAfter: '30d',
}

// Avoid: Keeping everything hot
const config: TierConfig = {
  hotThreshold: '10GB',   // Too large
  coldAfter: '365d',      // Too long
}
```

### 2. Use Appropriate Query Patterns

```typescript
// Good: Query matches tier
// Real-time lookup -> hot tier
const order = await $.Order('ord_123').get()

// Historical analysis -> warm tier
const monthlyOrders = await $.query('SELECT ... FROM orders WHERE created_at > ...')

// Aggregations -> cold tier
const yearlyRevenue = await $.analytics('SELECT SUM(amount) FROM orders WHERE ...')
```

### 3. Monitor Tier Usage

```typescript
// Check tier distribution
const stats = await $.tierStats()
console.log(`Hot: ${stats.hot.size}, Warm: ${stats.warm.size}, Cold: ${stats.cold.size}`)

// Monitor promotion/demotion rates
console.log(`Demotions/day: ${stats.demotionRate}`)
console.log(`Promotions/day: ${stats.promotionRate}`)
```

### 4. Configure Retention Policies

```typescript
// Time-based retention
const config: TierConfig = {
  coldAfter: '90d',       // Archive after 90 days
  deleteAfter: '7y',      // Delete after 7 years (compliance)
}

// Size-based retention
const config: TierConfig = {
  hotThreshold: '1GB',
  warmThreshold: '100GB',
}
```

## Technical Details

For implementation details and architecture documentation:

| Component | Location | Description |
|-----------|----------|-------------|
| **db/core/types.ts** | TierConfig | Type definitions |
| **db/iceberg/** | Iceberg integration | Direct Iceberg navigation |
| **db/edge-postgres/** | Edge Postgres | PGLite + FSX + Iceberg |

## Related

- [Replication Patterns](/docs/storage/replication) - Geo-distributed replicas
- [Sharding Strategies](/docs/storage/sharding) - Horizontal scaling
- [Vector Operations](/docs/storage/vector) - Vector search across tiers
- [Storage Architecture](/docs/storage) - Overall storage overview
