---
title: R2 Object Storage
description: Cloudflare R2 for large objects, multipart uploads, and presigned URLs with zero egress fees
---

# R2 Object Storage

Cloudflare R2 provides S3-compatible object storage with zero egress fees. Store files, backups, and large objects without paying to read your own data.

## Overview

R2 is ideal for:

- **Large files** - Images, videos, documents
- **Backups** - DO snapshots, database exports
- **Cold storage** - Historical data, archives
- **Static assets** - CDN-backed file serving
- **Multipart uploads** - Large file handling

## R2Store Integration

dotdo provides a typed R2 wrapper with multi-tenant support:

```typescript
import { createR2Store } from 'dotdo/cloudflare'

export class FileDO extends DO {
  private r2: R2Store

  constructor(ctx: DurableObjectState, env: Env) {
    super(ctx, env)
    this.r2 = createR2Store(env.R2, {
      tenant: this.ns,
      publicUrl: 'https://files.example.com',
    })
  }
}
```

## Basic Operations

### Storing Objects

```typescript
export class DocumentDO extends DO {
  async uploadDocument(name: string, content: string) {
    // Simple put operation
    const result = await this.r2.put(`documents/${name}`, content, {
      contentType: 'text/plain',
      customMetadata: {
        uploadedBy: this.getCurrentUser(),
        uploadedAt: new Date().toISOString(),
      },
    })

    return {
      key: result.key,
      size: result.size,
      etag: result.etag,
    }
  }

  async uploadBinary(name: string, data: ArrayBuffer) {
    // Binary data with auto content-type detection
    return await this.r2.put(`files/${name}`, data)
  }
}
```

### Retrieving Objects

```typescript
export class AssetDO extends DO {
  async getFile(key: string): Promise<Response> {
    const object = await this.r2.get(key)

    if (!object) {
      return new Response('Not Found', { status: 404 })
    }

    // Stream the body directly
    const headers = new Headers()
    object.writeHttpMetadata(headers)
    headers.set('etag', object.etag)

    return new Response(object.body, { headers })
  }

  async getFileAsText(key: string): Promise<string | null> {
    const object = await this.r2.get(key)
    return object ? await object.text() : null
  }

  async getFileAsJson<T>(key: string): Promise<T | null> {
    const object = await this.r2.get(key)
    return object ? await object.json<T>() : null
  }
}
```

### Range Requests

Fetch partial content for large files:

```typescript
export class VideoDO extends DO {
  async streamVideo(key: string, request: Request): Promise<Response> {
    const range = request.headers.get('range')

    if (!range) {
      // Full file request
      const object = await this.r2.get(key)
      if (!object) return new Response('Not Found', { status: 404 })

      return new Response(object.body, {
        headers: {
          'content-type': 'video/mp4',
          'content-length': object.size.toString(),
          'accept-ranges': 'bytes',
        },
      })
    }

    // Parse range header: "bytes=0-1023"
    const [start, end] = range.replace('bytes=', '').split('-').map(Number)

    const object = await this.r2.get(key, {
      range: {
        offset: start,
        length: end ? end - start + 1 : undefined,
      },
    })

    if (!object) return new Response('Not Found', { status: 404 })

    return new Response(object.body, {
      status: 206,
      headers: {
        'content-type': 'video/mp4',
        'content-range': `bytes ${start}-${end || object.size - 1}/${object.size}`,
        'accept-ranges': 'bytes',
      },
    })
  }
}
```

## Multipart Uploads

Handle large files by uploading in parts:

```typescript
export class UploadDO extends DO {
  async initiateUpload(filename: string, contentType: string) {
    // Start multipart upload
    const upload = await this.env.R2.createMultipartUpload(
      `uploads/${this.ns}/${filename}`,
      {
        httpMetadata: { contentType },
        customMetadata: {
          originalName: filename,
          initiatedAt: new Date().toISOString(),
        },
      }
    )

    // Store upload state
    await this.ctx.storage.put(`upload:${upload.uploadId}`, {
      key: upload.key,
      uploadId: upload.uploadId,
      parts: [],
      createdAt: Date.now(),
    })

    return {
      uploadId: upload.uploadId,
      key: upload.key,
    }
  }

  async uploadPart(uploadId: string, partNumber: number, data: ArrayBuffer) {
    const state = await this.ctx.storage.get<UploadState>(`upload:${uploadId}`)
    if (!state) throw new Error('Upload not found')

    // Get multipart upload handle
    const upload = this.env.R2.resumeMultipartUpload(state.key, uploadId)

    // Upload the part
    const part = await upload.uploadPart(partNumber, data)

    // Track uploaded parts
    state.parts.push({
      partNumber: part.partNumber,
      etag: part.etag,
    })
    await this.ctx.storage.put(`upload:${uploadId}`, state)

    return { partNumber: part.partNumber, etag: part.etag }
  }

  async completeUpload(uploadId: string) {
    const state = await this.ctx.storage.get<UploadState>(`upload:${uploadId}`)
    if (!state) throw new Error('Upload not found')

    const upload = this.env.R2.resumeMultipartUpload(state.key, uploadId)

    // Complete the upload
    const object = await upload.complete(state.parts)

    // Cleanup state
    await this.ctx.storage.delete(`upload:${uploadId}`)

    return {
      key: object.key,
      size: object.size,
      etag: object.etag,
    }
  }

  async abortUpload(uploadId: string) {
    const state = await this.ctx.storage.get<UploadState>(`upload:${uploadId}`)
    if (!state) throw new Error('Upload not found')

    const upload = this.env.R2.resumeMultipartUpload(state.key, uploadId)
    await upload.abort()

    await this.ctx.storage.delete(`upload:${uploadId}`)
  }
}

interface UploadState {
  key: string
  uploadId: string
  parts: Array<{ partNumber: number; etag: string }>
  createdAt: number
}
```

## Presigned URLs

Generate signed URLs for direct client uploads/downloads:

```typescript
export class MediaDO extends DO {
  async getDownloadUrl(key: string, expiresIn: number = 3600) {
    // Generate signed URL for download
    return await this.r2.getSignedUrl(key, {
      expiresIn,
      action: 'get',
      contentDisposition: 'attachment',
    })
  }

  async getUploadUrl(filename: string, contentType: string) {
    const key = `uploads/${this.ns}/${Date.now()}-${filename}`

    // Generate signed URL for upload
    const url = await this.r2.getSignedUrl(key, {
      expiresIn: 3600,
      action: 'put',
      contentType,
      maxSize: 100 * 1024 * 1024, // 100 MB max
    })

    return { url, key }
  }
}
```

### Implementing Signed URL Verification

For production, implement proper HMAC signing:

```typescript
export class SignedUrlDO extends DO {
  private signingKey: string

  constructor(ctx: DurableObjectState, env: Env) {
    super(ctx, env)
    this.signingKey = env.SIGNING_KEY
  }

  async createSignedUrl(key: string, expiresIn: number): Promise<string> {
    const expires = Math.floor(Date.now() / 1000) + expiresIn
    const data = `${key}:${expires}`

    // Create HMAC signature
    const encoder = new TextEncoder()
    const keyData = encoder.encode(this.signingKey)
    const cryptoKey = await crypto.subtle.importKey(
      'raw',
      keyData,
      { name: 'HMAC', hash: 'SHA-256' },
      false,
      ['sign']
    )

    const signature = await crypto.subtle.sign(
      'HMAC',
      cryptoKey,
      encoder.encode(data)
    )

    const sig = btoa(String.fromCharCode(...new Uint8Array(signature)))

    return `https://files.example.com/${key}?expires=${expires}&sig=${encodeURIComponent(sig)}`
  }

  async verifySignedUrl(key: string, expires: string, signature: string): Promise<boolean> {
    const now = Math.floor(Date.now() / 1000)
    if (parseInt(expires) < now) {
      return false // Expired
    }

    const data = `${key}:${expires}`
    const expectedSig = await this.sign(data)

    return signature === expectedSig
  }
}
```

## Tenant-Scoped Operations

Use the tenant path convention for multi-tenant apps:

```typescript
export class TenantFileDO extends DO {
  private r2: R2Store

  constructor(ctx: DurableObjectState, env: Env) {
    super(ctx, env)
    this.r2 = createR2Store(env.R2, { tenant: this.ns })
  }

  async uploadFile(type: string, id: string, data: ArrayBuffer) {
    // Automatically prefixes with tenant: {tenant}/{type}/{id}
    return await this.r2.putForTenant({
      type,
      id,
      data,
      timestamp: new Date().toISOString(),
      contentType: 'application/octet-stream',
    })
  }

  async getFile(type: string, id: string) {
    return await this.r2.getForTenant({ type, id })
  }

  async listFiles(type: string, limit: number = 100) {
    return await this.r2.listForTenant({
      type,
      limit,
    })
  }

  async deleteFile(type: string, id: string) {
    return await this.r2.deleteForTenant({ type, id })
  }
}
```

## Listing and Iteration

### Basic Listing

```typescript
export class BucketDO extends DO {
  async listObjects(prefix: string, limit: number = 1000) {
    const result = await this.r2.list({
      prefix,
      limit,
      include: ['httpMetadata', 'customMetadata'],
    })

    return {
      objects: result.objects.map(obj => ({
        key: obj.key,
        size: obj.size,
        uploaded: obj.uploaded,
        metadata: obj.customMetadata,
      })),
      truncated: result.truncated,
      cursor: result.cursor,
    }
  }

  async listAllObjects(prefix: string) {
    const objects: R2Object[] = []

    // Iterate through all pages
    for await (const obj of this.r2.listAll({ prefix })) {
      objects.push(obj)
    }

    return objects
  }

  async listDirectories(prefix: string) {
    // Use delimiter for directory-like listing
    const result = await this.r2.list({
      prefix,
      delimiter: '/',
    })

    return {
      files: result.objects,
      directories: result.delimitedPrefixes,
    }
  }
}
```

## Object Lifecycle

### Copying Objects

```typescript
export class ArchiveDO extends DO {
  async archiveFile(sourceKey: string, archivePrefix: string) {
    const destKey = `${archivePrefix}/${Date.now()}-${sourceKey.split('/').pop()}`

    // Copy preserves metadata
    await this.r2.copy(sourceKey, destKey)

    return destKey
  }
}
```

### Conditional Operations

```typescript
export class CacheDO extends DO {
  async conditionalGet(key: string, cachedEtag?: string) {
    const object = await this.r2.get(key, {
      onlyIf: cachedEtag ? { etagDoesNotMatch: cachedEtag } : undefined,
    })

    if (!object) {
      // Either not found or etag matched (cached version is fresh)
      return { status: 'not-modified' as const }
    }

    return {
      status: 'ok' as const,
      data: await object.text(),
      etag: object.etag,
    }
  }
}
```

## Cost Comparison

R2 has zero egress fees:

| Operation | R2 | AWS S3 |
|-----------|-----|--------|
| Storage | $0.015/GB-mo | $0.023/GB-mo |
| Egress | **$0** | $0.09/GB |
| PUT (Class A) | $4.50/million | $5.00/million |
| GET (Class B) | $0.36/million | $0.40/million |

### Example: Video Streaming Platform

| Metric | AWS S3 Cost | R2 Cost |
|--------|-------------|---------|
| 10 TB stored | $230/mo | $150/mo |
| 100 TB egress | $9,000/mo | **$0** |
| **Monthly Total** | $9,230/mo | **$150/mo** |
| **Annual Savings** | - | **$109,000** |

## Related Documentation

- [Storage Architecture](/docs/storage) - Tiered storage overview
- [Warm Tier](/docs/storage/warm-tier) - R2 + Iceberg for analytics
- [Durable Object Storage](/docs/storage/durable-objects) - Hot tier with SQLite
