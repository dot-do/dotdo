---
title: Primitives Storage Architecture
description: How fsx, gitx, bashx, npmx, and pyx use R2 and SQLite for persistent storage
---

# Primitives Storage Architecture

The extended primitives (fsx, gitx, bashx, npmx, pyx) use a tiered storage architecture that combines SQLite in Durable Objects with R2 object storage. This document explains how data flows between tiers, when migrations happen, and the operational characteristics of each primitive.

## Storage Tiers Overview

All primitives share a common three-tier architecture:

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                           Tiered Storage Architecture                        │
├─────────────────────┬─────────────────────────┬─────────────────────────────┤
│     Hot Tier        │       Warm Tier         │        Cold Tier            │
│     (SQLite)        │       (R2)              │        (R2 Archive)         │
├─────────────────────┼─────────────────────────┼─────────────────────────────┤
│ • < 1ms latency     │ • 5-50ms latency        │ • 50-200ms latency          │
│ • Per-DO isolation  │ • Shared across DOs     │ • Compressed/packed         │
│ • Size limits apply │ • Up to 5GB per object  │ • Optimized for cost        │
│ • ACID transactions │ • Eventual consistency  │ • Infrequent access class   │
└─────────────────────┴─────────────────────────┴─────────────────────────────┘
```

### Tier Characteristics

| Tier | Storage Backend | Max Object Size | Latency | Use Case |
|------|-----------------|-----------------|---------|----------|
| **Hot** | SQLite in DO | 1 MB (default) | < 1ms | Frequently accessed, small files |
| **Warm** | R2 Bucket | 5 GB | 5-50ms | Large files, moderate access |
| **Cold** | R2 (Archive) | 5 GB | 50-200ms | Historical data, packfiles |

## fsx - Filesystem Storage

### How fsx Uses Storage

fsx stores filesystem metadata and small files in SQLite, with large files automatically offloaded to R2:

```typescript
// Configuration determines tier thresholds
const tiered = new TieredFS({
  hot: env.FSX_DO,
  warm: env.FSX_WARM_BUCKET,
  cold: env.FSX_COLD_BUCKET,
  thresholds: {
    hotMaxSize: 1024 * 1024,     // 1MB - files smaller go to SQLite
    warmMaxSize: 100 * 1024 * 1024, // 100MB - larger files go to R2
  }
})
```

### SQLite Schema (Hot Tier)

Filesystem metadata is always stored in SQLite regardless of where the file content lives:

```sql
-- files table: stores all filesystem entries
CREATE TABLE files (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  path TEXT UNIQUE NOT NULL,
  name TEXT NOT NULL,
  parent_id INTEGER,
  type TEXT CHECK(type IN ('file', 'directory', 'symlink')),
  mode INTEGER DEFAULT 420,
  size INTEGER DEFAULT 0,
  blob_id TEXT,        -- Reference to blob storage
  tier TEXT DEFAULT 'hot' CHECK(tier IN ('hot', 'warm', 'cold')),
  atime INTEGER,       -- Access time (Unix ms)
  mtime INTEGER,       -- Modification time (Unix ms)
  ctime INTEGER,       -- Status change time (Unix ms)
  birthtime INTEGER,   -- Creation time (Unix ms)
  FOREIGN KEY (parent_id) REFERENCES files(id) ON DELETE CASCADE
);

-- Small file content stored inline in SQLite
-- content BLOB (for files < 64KB in hot tier)
```

### Tier Selection Logic

When you write a file, fsx automatically selects the appropriate tier:

```typescript
// Tier selection based on file size
private selectTier(size: number): StorageTier {
  if (size <= hotMaxSize) return 'hot'        // SQLite
  if (size <= warmMaxSize) return 'warm'      // R2
  return 'cold'                                // R2 Archive
}
```

**Automatic tier selection:**
- Files **<= 1MB**: Stored directly in SQLite (hot tier)
- Files **<= 100MB**: Stored in R2 warm bucket
- Files **> 100MB**: Stored in R2 cold/archive bucket

### When Files Move Between Tiers

**Automatic promotion** (cold/warm to hot):
- Triggered when `accessCount >= promotionThreshold` (default: 3)
- Only promotes if file fits in hot tier capacity

**Manual demotion** (hot to warm/cold):
```typescript
// Move old data to cold storage
await $.fs.demote('/data/archive-2023.json', 'cold')
```

**Automatic demotion** (via maintenance):
```typescript
// Run periodically to demote unused files
await tieredFs.runMaintenance()
```

### Consistency Model

fsx provides **strong consistency** for metadata and **eventual consistency** for large file content:

| Operation | Consistency | Notes |
|-----------|-------------|-------|
| Metadata reads | Strong | SQLite in single DO |
| Hot tier reads | Strong | SQLite SERIALIZABLE isolation |
| Warm/cold reads | Eventual | R2 read-after-write consistency |
| Directory listings | Strong | Metadata always in SQLite |
| Atomic writes | Supported | Via `atomic: true` option |
| Transactions | Full ACID | SQLite transactions |

**On DO restart:**
- Metadata is persisted in SQLite and survives restarts
- Hot tier file content is persisted
- Warm/cold content is in R2 (persistent)
- In-memory tier tracking cache is rebuilt from metadata

## gitx - Git Storage

### How gitx Uses Storage

gitx stores Git objects (blobs, trees, commits, tags) using a three-tier system optimized for Git access patterns:

```
┌────────────────────────────────────────────────────────────┐
│                      gitx Storage                           │
├────────────────────┬───────────────────────────────────────┤
│   Hot Tier         │           Warm/Cold Tier              │
│   (SQLite)         │           (R2)                        │
├────────────────────┼───────────────────────────────────────┤
│ • Recent commits   │ • Pack files (delta compressed)       │
│ • Active branches  │ • Full commit history                 │
│ • Loose objects    │ • Large blobs (LFS)                   │
│ • References/HEAD  │ • Old/rarely accessed objects         │
│ • Object metadata  │                                       │
└────────────────────┴───────────────────────────────────────┘
```

### R2 Object Layout

Git objects are stored in R2 using the standard Git two-character prefix:

```
git/objects/
  ab/
    cdef1234567890abcdef1234567890abcdef12  (blob)
  12/
    34567890abcdef1234567890abcdef12345678  (tree)
  fe/
    dcba9876543210fedcba9876543210fedcba98  (commit)
git/objects/packs/
  pack-<id>.pack   (delta-compressed objects)
  pack-<id>.idx    (pack index)
```

### Object Metadata Schema

```sql
-- Object metadata stored in SQLite
CREATE TABLE git_objects_meta (
  sha TEXT PRIMARY KEY,
  type TEXT NOT NULL,           -- blob, tree, commit, tag
  size INTEGER NOT NULL,
  tier TEXT DEFAULT 'warm',     -- hot, warm, cold
  access_count INTEGER DEFAULT 0,
  last_accessed INTEGER,
  created_at INTEGER,
  pack_id TEXT,                 -- For cold tier: which packfile
  pack_offset INTEGER           -- For cold tier: offset in packfile
);

-- Hot tier: actual object data
CREATE TABLE git_objects_hot (
  sha TEXT PRIMARY KEY,
  type TEXT NOT NULL,
  data BLOB NOT NULL,
  size INTEGER NOT NULL,
  created_at INTEGER
);
```

### Tier Configuration

```typescript
const storage = new TieredStorage({
  r2: env.GIT_OBJECTS,
  sql: ctx.storage.sql,
  hotTierMaxBytes: 50 * 1024 * 1024,  // 50MB in SQLite
  hotTierMaxObjectSize: 1 * 1024 * 1024, // 1MB max per object
  promotionThreshold: 3,               // Promote after 3 accesses
  demotionAgeDays: 7                   // Demote after 7 days
})
```

### Git Remote Integration

gitx uses R2 as its primary "remote" storage, but can sync with external Git hosts:

```typescript
// Configure GitHub sync
$.git.configure({
  repo: 'org/repo',
  branch: 'main',
  r2: env.R2_BUCKET,
  github: {
    token: env.GITHUB_TOKEN,
    syncOnPush: true  // Auto-sync to GitHub
  }
})

// Push syncs to both R2 and GitHub
await $.git.push()

// Sync pulls from R2 (or GitHub if configured)
await $.git.sync()
```

**Multi-agent collaboration** works via R2's consistency:
- All agents write to the same R2 bucket
- R2 provides read-after-write consistency
- Refs (branch pointers) are stored in DO metadata for strong consistency

### Size Limits and Constraints

| Item | Limit | Notes |
|------|-------|-------|
| Hot tier total | 50 MB default | Configurable |
| Hot tier object | 1 MB default | Larger objects go to warm |
| R2 object | 5 GB | Per Cloudflare R2 limits |
| Pack file | Unlimited | Stored in R2 |
| References | Unlimited | Stored in DO metadata |

## bashx - Execution Tiers

bashx doesn't store data but routes commands to different executors based on analysis:

### Tier Selection

```
┌─────────────────────────────────────────────────────────────┐
│                    Command Input                             │
│              $.bash`cat config.json`                         │
└─────────────────────┬───────────────────────────────────────┘
                      │
                      ▼
┌─────────────────────────────────────────────────────────────┐
│                 AST Parser (tree-sitter)                     │
│            Parse → Classify → Route                          │
└─────────────────────┬───────────────────────────────────────┘
                      │
          ┌───────────┴───────────┬───────────────────────────┐
          ▼                       ▼                           ▼
┌─────────────────┐   ┌─────────────────┐   ┌─────────────────┐
│   Tier 1        │   │   Tier 2        │   │   Tier 3        │
│   Native JS     │   │   WASM          │   │   Containers    │
├─────────────────┤   ├─────────────────┤   ├─────────────────┤
│ cat, head, tail │   │ jq, sed, awk    │   │ npm, python     │
│ ls, find, grep  │   │ curl, wget      │   │ ffmpeg, gcc     │
│ echo, printf    │   │ base64, sha256  │   │ docker, git     │
├─────────────────┤   ├─────────────────┤   ├─────────────────┤
│ Uses fsx        │   │ WASM modules    │   │ Container exec  │
│ Sub-ms latency  │   │ 10-50ms         │   │ 100ms+ startup  │
└─────────────────┘   └─────────────────┘   └─────────────────┘
```

### Tier Selection Logic

bashx analyzes each command and routes to the appropriate executor:

1. **Tier 1 (Native)**: File operations that can be implemented via fsx
   ```typescript
   // These use $.fs internally - no subprocess!
   await $.bash`cat config.json`        // → $.fs.read('config.json')
   await $.bash`ls -la src/`            // → $.fs.list('src/')
   await $.bash`mkdir -p uploads/2024`  // → $.fs.mkdir({ recursive: true })
   ```

2. **Tier 2 (WASM)**: Tools compiled to WebAssembly
   ```typescript
   await $.bash`jq '.name' package.json`  // → jq WASM module
   await $.bash`echo "hello" | base64`    // → base64 WASM
   ```

3. **Tier 3 (Container)**: Full process execution
   ```typescript
   await $.bash`npm install`              // → Container execution
   await $.bash`python train.py`          // → Container execution
   ```

### Classification Rules

The tier is determined by command analysis:

| Command Type | Classification | Tier |
|-------------|----------------|------|
| File read (`cat`, `head`, `tail`) | safe | Native |
| Directory (`ls`, `find`) | safe | Native |
| File write (`mkdir`, `cp`) | write | Native |
| Text processing (`jq`, `sed`) | safe | WASM |
| Network (`curl`, `wget`) | network | WASM |
| Package managers (`npm`, `pip`) | write | Container |
| Compilers (`gcc`, `rustc`) | write | Container |
| Dangerous (`rm -rf /`) | destructive | Blocked |

## npmx - Package Storage

npmx uses fsx for all storage, inheriting its tiered architecture:

```
┌─────────────────────────────────────────────────────────────┐
│                    npmx Architecture                         │
├─────────────────────────────────────────────────────────────┤
│  /node_modules/lodash/...  → fsx (SQLite hot tier)          │
│  /cache/lodash-4.17.21.tgz → fsx (R2 cold tier)             │
└─────────────────────────────────────────────────────────────┘
```

### Storage Layout

```
/node_modules/          ← Hot tier (frequently accessed)
  lodash/
    index.js
    package.json
/cache/                 ← Cold tier (tarballs)
  lodash-4.17.21.tgz
  react-18.2.0.tgz
```

## pyx - Python Execution

pyx uses Pyodide (WebAssembly Python) and stores session data via fsx:

### Session Snapshots

```typescript
// Create session with packages
const session = await py.session()
await session.install(['numpy', 'pandas'])

// Snapshot the state (stored via fsx)
const snapshot = await session.snapshot()
// Snapshot is stored in R2 (warm tier) due to size

// Later, restore from snapshot (instant cold start)
const restored = await snapshot.restore()
```

### Storage for Python Files

```
/py/sessions/           ← Session state
  session-abc123.snap   → R2 (large snapshots)
/py/packages/           ← Installed packages
  numpy/...             → SQLite (hot tier)
```

## Configuration Reference

### fsx Configuration

```typescript
interface TieredFSConfig {
  hot: DurableObjectNamespace    // Required: DO for SQLite
  warm?: R2Bucket                 // Optional: R2 for large files
  cold?: R2Bucket                 // Optional: R2 archive
  thresholds?: {
    hotMaxSize?: number           // Default: 1MB
    warmMaxSize?: number          // Default: 100MB
  }
  promotionPolicy?: 'none' | 'on-access' | 'aggressive'
}
```

### gitx Configuration

```typescript
interface TieredStorageOptions {
  r2: R2Bucket                    // Required: R2 bucket for objects
  sql: SqlStorage                 // Required: SQLite for hot tier
  prefix?: string                 // Default: 'git/objects'
  hotTierMaxBytes?: number        // Default: 50MB
  hotTierMaxObjectSize?: number   // Default: 1MB
  promotionThreshold?: number     // Default: 3 accesses
  demotionAgeDays?: number        // Default: 7 days
  autoPromote?: boolean           // Default: true
  autoDemote?: boolean            // Default: true
}
```

## Performance Characteristics

| Primitive | Hot Tier | Warm Tier | Cold Tier |
|-----------|----------|-----------|-----------|
| **fsx read** | < 1ms | 5-15ms | N/A |
| **fsx write** | < 1ms | 10-50ms | N/A |
| **gitx get** | < 5ms | 50-100ms | 100-500ms (pack parse) |
| **gitx put** | 10-50ms | 100-300ms | N/A |
| **bashx native** | < 1ms | N/A | N/A |
| **bashx WASM** | 10-50ms | N/A | N/A |
| **bashx container** | 100ms+ | N/A | N/A |

## Limitations and Tradeoffs

### SQLite (Hot Tier)

- **Limit**: ~50MB practical limit for hot tier (configurable)
- **Tradeoff**: Fast access but limited capacity
- **Single writer**: Only one DO instance writes at a time

### R2 (Warm/Cold Tier)

- **Limit**: 5GB per object
- **Tradeoff**: Higher latency but unlimited capacity
- **Eventual consistency**: Read-after-write consistency, not linearizable
- **No transactions**: Operations are not atomic across objects

### Tier Migration

- **Automatic**: Based on access patterns and configured thresholds
- **Not instant**: Migration happens asynchronously
- **Cost**: R2 has no egress fees, so reading is cheap

## Troubleshooting

### File Not Found After Write

If a file was written to warm tier and immediately read:
- Wait for R2 read-after-write consistency (typically immediate)
- Check tier metadata: `await $.fs.stat(path)` shows tier

### Slow File Access

Check which tier the file is in:
```typescript
const stat = await $.fs.stat('/large-file.bin')
console.log(`Tier: ${stat.tier}`) // 'hot', 'warm', or 'cold'
```

### Out of Hot Tier Capacity

If hot tier is full, files automatically go to warm tier. To force demotion:
```typescript
// Manually demote old files
await tieredFs.runMaintenance()
```

## Next Steps

- [fsx](/docs/primitives/fsx) - Full filesystem API reference
- [gitx](/docs/primitives/gitx) - Git operations and remote sync
- [bashx](/docs/primitives/bashx) - Shell execution details
- [Storage Overview](/docs/storage) - General storage architecture
