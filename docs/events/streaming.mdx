---
title: Event Streaming
description: Real-time event streaming with WebSocket connections and pipeline integration
---

import { Callout } from 'fumadocs-ui/components/callout'

# Event Streaming

dotdo provides real-time event streaming through WebSocket connections and Cloudflare Pipelines integration. Stream events to analytics sinks, enable live subscriptions, and build reactive interfaces.

## Overview

The streaming system provides:

- **WebSocket Connections**: Real-time push to connected clients
- **Pipeline Integration**: Stream to Iceberg, Parquet, or JSON sinks
- **Topic-based Subscriptions**: Filter by topic patterns with wildcards
- **Hot Tier Storage**: 5-minute in-memory cache for replay
- **Backpressure Handling**: Rate limiting and message coalescing
- **Fan-out Optimization**: Efficient broadcast to large subscriber counts

## WebSocket Streaming

### Connecting to Events

Connect via WebSocket with topic subscriptions:

```typescript
// Client-side: Subscribe to order events
const ws = new WebSocket('wss://stream.example.com/events?topic=orders')

ws.onopen = () => {
  console.log('Connected to event stream')
}

ws.onmessage = (event) => {
  const data = JSON.parse(event.data)
  console.log('Event received:', data)
}

ws.onerror = (error) => {
  console.error('WebSocket error:', error)
}
```

### Multiple Topics

Subscribe to multiple topics:

```typescript
// Subscribe to multiple topics
const ws = new WebSocket(
  'wss://stream.example.com/events?topic=orders&topic=inventory&topic=payments'
)

// Or use wildcard patterns
const ws = new WebSocket('wss://stream.example.com/events?topic=orders.*')
```

### Dynamic Subscriptions

Subscribe and unsubscribe after connection:

```typescript
// Subscribe to additional topics
ws.send(JSON.stringify({
  type: 'subscribe',
  topics: ['shipping', 'returns']
}))

// Unsubscribe from topics
ws.send(JSON.stringify({
  type: 'unsubscribe',
  topics: ['returns']
}))
```

## EventStreamDO

The `EventStreamDO` Durable Object handles WebSocket connections and event broadcasting:

```typescript
import { EventStreamDO, EventStreamConfig } from 'dotdo/streaming'

// Configure the stream
const config: EventStreamConfig = {
  hotTierRetentionMs: 5 * 60 * 1000,  // 5 minutes
  maxConnections: 10_000,
  maxTopics: 10_000,
  rateLimit: {
    messagesPerSecond: 1000,
    burstSize: 100
  },
  coalescing: {
    enabled: true,
    maxDelayMs: 50,
    maxBatchSize: 100
  },
  fanOut: {
    batchSize: 1000,
    yieldIntervalMs: 1
  }
}

export class MyEventStream extends EventStreamDO {
  constructor(state: DurableObjectState, env: Env) {
    super(state, env, config)
  }
}
```

### Broadcasting Events

```typescript
// Broadcast to all subscribers of a topic
await stream.broadcastToTopic('orders', {
  id: 'evt-123',
  type: 'order.created',
  topic: 'orders',
  payload: { orderId: 'ord-456', total: 99.99 },
  timestamp: Date.now()
})

// Broadcast batch of events
await stream.broadcastBatch([
  { id: 'evt-1', type: 'inventory.updated', topic: 'inventory', payload: {...}, timestamp: Date.now() },
  { id: 'evt-2', type: 'inventory.updated', topic: 'inventory', payload: {...}, timestamp: Date.now() },
])
```

## Pipeline Integration

Stream events to analytics sinks using the `StreamBridge`:

```typescript
import { StreamBridge } from 'dotdo/streaming'

// Configure pipeline integration
const stream = new StreamBridge(env.EVENTS_PIPELINE, {
  sink: 'iceberg',      // or 'parquet', 'json'
  batchSize: 1000,
  flushInterval: 60000, // 1 minute
  transform: (event) => {
    // Filter or enrich events
    if (event.type === 'debug') return null
    return { ...event, processedAt: Date.now() }
  }
})

// Emit changes
stream.emit('insert', 'orders', { id: 'ord-123', total: 99.99 })
stream.emit('update', 'orders', { id: 'ord-123', status: 'shipped' })
stream.emit('delete', 'orders', { id: 'ord-123' })

// Flush at end of transaction
await stream.flush()
```

### Supported Sinks

| Sink | Format | Use Case |
|------|--------|----------|
| `iceberg` | Apache Iceberg tables | Data warehouse, time-travel queries |
| `parquet` | Parquet files | Columnar analytics, S3/R2 storage |
| `json` | JSON lines | Debugging, simple storage |

## Topic Patterns

Wildcard patterns for flexible subscriptions:

```typescript
// Single level wildcard - matches orders.created, orders.updated
'orders.*'

// Multi-level wildcard (NATS-style) - matches orders.us.west, orders.eu.east.london
'orders.>'

// Exact match
'orders.created'

// Complex patterns
'orders.*.shipped'  // matches orders.us.shipped, orders.eu.shipped
```

## Message Coalescing

For high-frequency events, enable coalescing to batch messages:

```typescript
const config = {
  coalescing: {
    enabled: true,
    maxDelayMs: 50,      // Max wait before flush
    maxBatchSize: 100    // Max events per batch
  }
}

// Events are automatically batched
await stream.broadcastToTopic('ticks', tick1)
await stream.broadcastToTopic('ticks', tick2)
// Both sent as single batch: { type: 'batch', payload: { events: [tick1, tick2] } }
```

## Replay and Recovery

Clients can replay missed events:

```typescript
// Replay from last known event
const ws = new WebSocket(
  'wss://stream.example.com/events?topic=orders&lastEventId=evt-456'
)

// Replay from timestamp
const ws = new WebSocket(
  'wss://stream.example.com/events?topic=orders&fromTimestamp=1705312200000'
)
```

<Callout type="info">
Replay is limited to the hot tier retention window (default 5 minutes). Events older than the retention window cannot be replayed from the stream - use the cold storage query API instead.
</Callout>

## Live Queries

Subscribe to SQL queries that update in real-time:

```typescript
const subscription = await stream.subscribeToQuery(
  `SELECT type, COUNT(*) as count
   FROM events
   WHERE topic = 'orders'
   GROUP BY type`,
  (result) => {
    console.log('Query updated:', result.rows)
  }
)

// Later, unsubscribe
await subscription.unsubscribe()
```

## Backpressure Handling

The stream automatically handles slow consumers:

```typescript
// Client receives backpressure warning
ws.onmessage = (event) => {
  const data = JSON.parse(event.data)

  if (data.type === 'backpressure') {
    console.warn('Messages being dropped due to backpressure')
    // Slow down processing or buffer locally
  }
}
```

Configure backpressure limits:

```typescript
const config = {
  maxPendingMessages: 100,  // Messages per connection before backpressure
  rateLimit: {
    messagesPerSecond: 1000,
    burstSize: 100
  }
}
```

## Fan-out Optimization

For topics with many subscribers, configure batched fan-out:

```typescript
const config = {
  fanOut: {
    batchSize: 1000,      // Subscribers per batch
    yieldIntervalMs: 1    // Yield between batches to prevent blocking
  }
}
```

## Metrics

Monitor stream health with built-in metrics:

```typescript
// GET /metrics (JSON)
const metrics = await stream.getMetrics()
// {
//   activeConnections: 5000,
//   totalConnections: 15000,
//   messagesSent: 1000000,
//   messagesPerSecond: 1666,
//   errorCount: 5,
//   latencyP50: 2,
//   latencyP95: 10,
//   latencyP99: 25,
//   topicStats: { orders: { subscribers: 500 }, ... }
// }

// GET /metrics (Prometheus format)
// eventstream_connections_active 5000
// eventstream_messages_total 1000000
// eventstream_errors_total 5
```

## Authentication

Require authentication for connections:

```typescript
const config = {
  requireAuth: true,
  tokenTTL: 3600  // 1 hour
}

// Set custom validator
stream.setTokenValidator(async (token) => {
  const user = await validateToken(token)
  if (!user) return false

  return {
    valid: true,
    allowedTopics: user.permissions.topics  // Restrict topic access
  }
})
```

Client authentication:

```typescript
// Via query parameter
const ws = new WebSocket('wss://stream.example.com/events?topic=orders&token=jwt...')

// Via header (in browser, use protocols)
const ws = new WebSocket('wss://stream.example.com/events?topic=orders', ['Bearer', 'jwt...'])
```

## Graceful Shutdown

Handle server shutdown gracefully:

```typescript
// Notify clients and drain connections
await stream.gracefulShutdown({ drainTimeout: 5000 })

// Clients receive:
// { type: 'shutdown', reason: 'Server is shutting down' }
```

## Related

- [Events Overview](/docs/events) - Event handlers with $.on.Noun.verb
- [Event Emission](/docs/events/emission) - Fire-and-forget emission patterns
- [Event Sourcing](/docs/events/sourcing) - Event-sourced architecture patterns
- [Concepts: Events](/docs/concepts/events) - 5W+H event model
