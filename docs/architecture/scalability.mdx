---
title: Scalability Patterns
description: Horizontal scaling with Durable Objects, sharding strategies, and load balancing techniques
---

import { Callout } from 'fumadocs-ui/components/callout'

# Scalability Patterns

dotdo is designed to scale from zero to millions of concurrent users. This guide covers horizontal scaling strategies using Durable Objects, sharding techniques, and load balancing patterns.

## Scaling Model

### Durable Objects: Natural Horizontal Scaling

Each Durable Object is an isolated unit that can run independently:

```
┌─────────────────────────────────────────────────────────────────┐
│                    Cloudflare Edge Network                       │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│   ┌─────┐  ┌─────┐  ┌─────┐  ┌─────┐  ┌─────┐  ┌─────┐        │
│   │ DO1 │  │ DO2 │  │ DO3 │  │ DO4 │  │ DO5 │  │ ... │        │
│   └─────┘  └─────┘  └─────┘  └─────┘  └─────┘  └─────┘        │
│                                                                  │
│   • Each DO is independent                                      │
│   • Millions can run simultaneously                             │
│   • No shared state between DOs                                 │
│   • Each has its own 10GB SQLite                                │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘
```

### Scaling Dimensions

| Dimension | Strategy | Limit |
|-----------|----------|-------|
| Users | One DO per user/tenant | Millions of DOs |
| Data | Sharding across DOs | 10GB per DO, 10TB sharded |
| Throughput | Request distribution | 1000+ RPS per DO |
| Geography | Regional DOs | 300+ edge locations |

## Horizontal Scaling Strategies

### 1. Entity-per-DO Pattern

The simplest scaling pattern: one Durable Object per entity:

```typescript
import { DO } from 'dotdo'

// Each user gets their own DO
class UserDO extends DO {
  async fetch(request: Request): Promise<Response> {
    // this.ns contains the user ID
    const userId = this.ns  // e.g., 'user_abc123'

    const url = new URL(request.url)

    if (url.pathname === '/profile') {
      return this.getProfile()
    }

    if (url.pathname === '/settings') {
      return this.getSettings()
    }

    return new Response('Not found', { status: 404 })
  }
}

// Worker routes to user's DO
export default {
  async fetch(request: Request, env: Env): Promise<Response> {
    const userId = await getUserId(request)
    const id = env.USER_DO.idFromName(userId)
    return env.USER_DO.get(id).fetch(request)
  }
}
```

**Advantages:**
- Natural isolation between users
- Linear scaling with user count
- No contention between users
- Simple mental model

**Best for:** User profiles, settings, personal data, multi-tenant SaaS

### 2. Aggregator Pattern

Use a hierarchy of DOs for aggregation:

```
                    ┌─────────────────┐
                    │   Global DO     │
                    │  (Aggregation)  │
                    └────────┬────────┘
                             │
            ┌────────────────┼────────────────┐
            │                │                │
            ▼                ▼                ▼
    ┌──────────────┐ ┌──────────────┐ ┌──────────────┐
    │  Region DO   │ │  Region DO   │ │  Region DO   │
    │   (US-East)  │ │   (EU-West)  │ │   (APAC)     │
    └──────┬───────┘ └──────┬───────┘ └──────┬───────┘
           │                │                │
     ┌─────┴─────┐    ┌─────┴─────┐    ┌─────┴─────┐
     │           │    │           │    │           │
     ▼           ▼    ▼           ▼    ▼           ▼
  ┌─────┐     ┌─────┐ ...      ┌─────┐ ...      ┌─────┐
  │ User│     │ User│          │ User│          │ User│
  │ DO  │     │ DO  │          │ DO  │          │ DO  │
  └─────┘     └─────┘          └─────┘          └─────┘
```

```typescript
import { DO } from 'dotdo'

class GlobalAggregatorDO extends DO {
  private readonly regions = ['us-east', 'eu-west', 'apac']

  async getGlobalStats(): Promise<GlobalStats> {
    // Fan out to all region DOs
    const regionStats = await Promise.all(
      this.regions.map(async (region) => {
        const id = this.env.REGION_DO.idFromName(region)
        const stub = this.env.REGION_DO.get(id)
        const response = await stub.fetch('/stats')
        return response.json() as Promise<RegionStats>
      })
    )

    // Aggregate results
    return {
      totalUsers: regionStats.reduce((sum, r) => sum + r.userCount, 0),
      totalRevenue: regionStats.reduce((sum, r) => sum + r.revenue, 0),
      activeNow: regionStats.reduce((sum, r) => sum + r.activeUsers, 0),
      regions: regionStats,
    }
  }
}

class RegionAggregatorDO extends DO {
  async getStats(): Promise<RegionStats> {
    // Query local SQLite for aggregated metrics
    const [stats] = await this.db
      .select({
        userCount: sql<number>`COUNT(DISTINCT user_id)`,
        revenue: sql<number>`SUM(amount)`,
        activeUsers: sql<number>`COUNT(DISTINCT CASE WHEN last_active > datetime('now', '-5 minutes') THEN user_id END)`,
      })
      .from(metrics)

    return stats
  }
}
```

### 3. Coordinator Pattern

For operations requiring coordination across DOs:

```typescript
import { DO } from 'dotdo'

class TransferCoordinatorDO extends DO {
  async transfer(from: string, to: string, amount: number): Promise<TransferResult> {
    const transferId = crypto.randomUUID()

    // Phase 1: Prepare
    const fromDO = this.env.ACCOUNT_DO.get(this.env.ACCOUNT_DO.idFromName(from))
    const toDO = this.env.ACCOUNT_DO.get(this.env.ACCOUNT_DO.idFromName(to))

    const [fromPrepare, toPrepare] = await Promise.all([
      fromDO.fetch('/prepare-debit', {
        method: 'POST',
        body: JSON.stringify({ transferId, amount }),
      }),
      toDO.fetch('/prepare-credit', {
        method: 'POST',
        body: JSON.stringify({ transferId, amount }),
      }),
    ])

    if (!fromPrepare.ok || !toPrepare.ok) {
      // Rollback
      await Promise.all([
        fromDO.fetch('/rollback', { method: 'POST', body: JSON.stringify({ transferId }) }),
        toDO.fetch('/rollback', { method: 'POST', body: JSON.stringify({ transferId }) }),
      ])
      return { success: false, error: 'Preparation failed' }
    }

    // Phase 2: Commit
    await Promise.all([
      fromDO.fetch('/commit', { method: 'POST', body: JSON.stringify({ transferId }) }),
      toDO.fetch('/commit', { method: 'POST', body: JSON.stringify({ transferId }) }),
    ])

    return { success: true, transferId }
  }
}

class AccountDO extends DO {
  async prepareDebit(transferId: string, amount: number): Promise<Response> {
    // Check balance and reserve funds
    const balance = await this.getBalance()

    if (balance < amount) {
      return new Response('Insufficient funds', { status: 400 })
    }

    // Create pending transaction
    await this.db.insert(pendingTransactions).values({
      id: transferId,
      type: 'debit',
      amount,
      status: 'prepared',
    })

    return new Response('OK')
  }

  async commit(transferId: string): Promise<Response> {
    const [pending] = await this.db
      .select()
      .from(pendingTransactions)
      .where(eq(pendingTransactions.id, transferId))

    if (!pending) {
      return new Response('Transaction not found', { status: 404 })
    }

    // Apply the transaction
    await this.db.transaction(async (tx) => {
      if (pending.type === 'debit') {
        await tx.update(accounts).set({
          balance: sql`balance - ${pending.amount}`,
        })
      } else {
        await tx.update(accounts).set({
          balance: sql`balance + ${pending.amount}`,
        })
      }

      await tx.delete(pendingTransactions).where(eq(pendingTransactions.id, transferId))
    })

    return new Response('OK')
  }
}
```

## Sharding Strategies

### When to Shard

| Indicator | Threshold | Action |
|-----------|-----------|--------|
| SQLite size | > 5GB | Consider sharding |
| Row count | > 10M rows | Consider sharding |
| Query latency | > 100ms | Consider sharding or indexing |
| Write throughput | > 100 writes/s | Consider sharding |

### Consistent Hashing

Distributes data evenly with minimal redistribution when scaling:

```typescript
import { DO } from 'dotdo/full'

class ShardedDO extends DO {
  async shard(): Promise<ShardResult> {
    const result = await this.$.shard({
      key: 'tenantId',
      count: 16,
      strategy: 'consistent',
      options: {
        virtualNodes: 150,  // More vnodes = better distribution
        replicationFactor: 1,
      },
    })

    return result
  }
}

// Using the shard router
class ShardRouterDO extends DO {
  private router: ShardRouter

  async setup(): Promise<void> {
    this.router = new ShardRouter(this.env.DO, {
      key: 'tenantId',
      count: 16,
      algorithm: 'consistent',
    })
  }

  async query(tenantId: string, sql: string): Promise<unknown> {
    // Route to correct shard
    const stub = await this.router.getShardStub(tenantId)
    const response = await stub.fetch('/query', {
      method: 'POST',
      body: JSON.stringify({ sql }),
    })
    return response.json()
  }

  async queryAll(sql: string): Promise<unknown[]> {
    // Fan out to all shards
    return this.router.queryAll('/query', {
      method: 'POST',
      body: JSON.stringify({ sql }),
    })
  }
}
```

### Range Sharding

Best for time-series or ordered data:

```typescript
class TimeSeriesShardedDO extends DO {
  async shard(): Promise<ShardResult> {
    return this.$.shard({
      key: 'timestamp',
      count: 12,  // One shard per month
      strategy: 'range',
      options: {
        boundaries: this.generateMonthlyBoundaries(),
      },
    })
  }

  private generateMonthlyBoundaries(): number[] {
    const boundaries: number[] = []
    const now = new Date()

    for (let i = 0; i < 12; i++) {
      const date = new Date(now.getFullYear(), now.getMonth() - i, 1)
      boundaries.push(date.getTime())
    }

    return boundaries.reverse()
  }
}
```

### Shard Rebalancing

```typescript
class RebalancingDO extends DO {
  async rebalance(): Promise<RebalanceResult> {
    const stats = await this.$.getShardStats()

    // Check for skew
    const skewRatio = stats.maxPerShard / stats.minPerShard

    if (skewRatio > 2.0) {
      console.log(`High skew detected: ${skewRatio}. Rebalancing...`)

      return this.$.rebalanceShards({
        targetCount: stats.shardCount * 2,  // Double shards
        strategy: 'incremental',
        maxMigrationBatchSize: 1000,
      })
    }

    return { rebalanced: false, reason: 'Skew within acceptable range' }
  }
}
```

## Load Balancing

### Request Distribution

```
┌─────────────────────────────────────────────────────────────────┐
│                     Incoming Requests                            │
└─────────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────────┐
│                    Load Balancer Worker                          │
│                                                                  │
│  1. Extract routing key (tenant, user, etc.)                    │
│  2. Hash key to determine target                                │
│  3. Route to appropriate DO                                     │
│  4. Handle failover if needed                                   │
└─────────────────────────────────────────────────────────────────┘
                              │
            ┌─────────────────┼─────────────────┐
            │                 │                 │
            ▼                 ▼                 ▼
        ┌───────┐         ┌───────┐         ┌───────┐
        │  DO1  │         │  DO2  │         │  DO3  │
        └───────┘         └───────┘         └───────┘
```

```typescript
// Load balancer worker
export default {
  async fetch(request: Request, env: Env): Promise<Response> {
    const url = new URL(request.url)
    const tenantId = url.hostname.split('.')[0]

    // Consistent hash to select DO
    const hash = await hashString(tenantId)
    const doIndex = hash % env.DO_COUNT

    // Get the target DO
    const id = env.DO.idFromName(`shard-${doIndex}`)
    const stub = env.DO.get(id)

    try {
      return await stub.fetch(request)
    } catch (error) {
      // Failover to next shard
      const failoverId = env.DO.idFromName(`shard-${(doIndex + 1) % env.DO_COUNT}`)
      return env.DO.get(failoverId).fetch(request)
    }
  }
}

async function hashString(str: string): Promise<number> {
  const encoder = new TextEncoder()
  const data = encoder.encode(str)
  const hashBuffer = await crypto.subtle.digest('SHA-256', data)
  const hashArray = new Uint8Array(hashBuffer)
  return hashArray[0] | (hashArray[1] << 8) | (hashArray[2] << 16) | (hashArray[3] << 24)
}
```

### Weighted Load Balancing

```typescript
interface ShardWeight {
  id: string
  weight: number
  healthy: boolean
}

class WeightedBalancer {
  private shards: ShardWeight[] = []
  private totalWeight = 0

  constructor(shards: ShardWeight[]) {
    this.shards = shards.filter(s => s.healthy)
    this.totalWeight = this.shards.reduce((sum, s) => sum + s.weight, 0)
  }

  select(): string {
    let random = Math.random() * this.totalWeight

    for (const shard of this.shards) {
      random -= shard.weight
      if (random <= 0) {
        return shard.id
      }
    }

    return this.shards[0].id
  }
}

// Usage in worker
export default {
  async fetch(request: Request, env: Env): Promise<Response> {
    const health = await env.HEALTH_DO.get(
      env.HEALTH_DO.idFromName('health')
    ).fetch('/status')

    const shardHealth = await health.json() as ShardWeight[]
    const balancer = new WeightedBalancer(shardHealth)

    const targetShard = balancer.select()
    const id = env.DO.idFromName(targetShard)

    return env.DO.get(id).fetch(request)
  }
}
```

## Auto-Scaling Patterns

### Dynamic Shard Creation

```typescript
class AutoScalingDO extends DO {
  async handleRequest(request: Request): Promise<Response> {
    const stats = await this.getStats()

    // Check if we need to scale
    if (stats.rowCount > 1_000_000 && !this.isSharded) {
      // Trigger background sharding
      this.ctx.waitUntil(this.autoShard())
    }

    return this.processRequest(request)
  }

  private async autoShard(): Promise<void> {
    await this.$.shard({
      key: 'id',
      count: 4,
      strategy: 'consistent',
    })

    // Notify monitoring
    await this.events.emit({
      verb: 'auto-sharded',
      source: this.ns,
      data: {
        shardCount: 4,
        reason: 'row_count_threshold',
      },
    })
  }
}
```

### Capacity-Based Routing

```typescript
class CapacityAwareDO extends DO {
  async getCapacity(): Promise<CapacityInfo> {
    const [stats] = await this.db
      .select({
        rowCount: sql<number>`(SELECT COUNT(*) FROM things)`,
        dbSize: sql<number>`(SELECT page_count * page_size FROM pragma_page_count(), pragma_page_size())`,
      })
      .from(sql`(SELECT 1)`)

    return {
      rowCount: stats.rowCount,
      dbSizeBytes: stats.dbSize,
      dbSizeGB: stats.dbSize / (1024 * 1024 * 1024),
      capacityPercent: (stats.dbSize / (10 * 1024 * 1024 * 1024)) * 100,
      acceptingWrites: stats.dbSize < 9 * 1024 * 1024 * 1024,  // 90% threshold
    }
  }
}

// Router that considers capacity
class CapacityRouter {
  async route(request: Request, env: Env): Promise<Response> {
    const candidates = ['shard-0', 'shard-1', 'shard-2', 'shard-3']

    // Get capacity from all shards
    const capacities = await Promise.all(
      candidates.map(async (shard) => {
        const stub = env.DO.get(env.DO.idFromName(shard))
        const response = await stub.fetch('/capacity')
        const capacity = await response.json() as CapacityInfo
        return { shard, ...capacity }
      })
    )

    // Select shard with most available capacity
    const available = capacities
      .filter(c => c.acceptingWrites)
      .sort((a, b) => a.capacityPercent - b.capacityPercent)

    if (available.length === 0) {
      return new Response('All shards at capacity', { status: 503 })
    }

    const target = available[0].shard
    return env.DO.get(env.DO.idFromName(target)).fetch(request)
  }
}
```

## Scaling Limits Reference

### Per-Durable Object

| Resource | Limit |
|----------|-------|
| SQLite storage | 10 GB |
| Memory | 128 MB |
| CPU per request | 30s (paid), 10ms (free) |
| Subrequests per request | 1,000 |
| Concurrent WebSockets | 32,768 |

### Per-Account

| Resource | Limit |
|----------|-------|
| Total DOs | Unlimited |
| DO namespaces | 500 per script |
| Requests per second | 100,000+ (contact CF) |

### Per-Namespace

| Resource | Limit |
|----------|-------|
| Unique DOs | Unlimited |
| Storage across all DOs | Unlimited |

## Monitoring and Observability

### Scaling Metrics

```typescript
class MonitoredScalableDO extends DO {
  async recordMetrics(): Promise<void> {
    const capacity = await this.getCapacity()
    const performance = await this.getPerformanceMetrics()

    await this.env.ANALYTICS.writeDataPoint({
      blobs: [this.ns, 'capacity'],
      doubles: [
        capacity.dbSizeGB,
        capacity.capacityPercent,
        performance.avgQueryTimeMs,
        performance.requestsPerSecond,
      ],
      indexes: [capacity.acceptingWrites ? 'healthy' : 'at_capacity'],
    })
  }

  private async getPerformanceMetrics(): Promise<PerformanceMetrics> {
    const [metrics] = await this.db
      .select({
        avgQueryTime: sql<number>`AVG(duration_ms)`,
        requestCount: sql<number>`COUNT(*)`,
      })
      .from(requestLog)
      .where(gt(requestLog.timestamp, sql`datetime('now', '-1 minute')`))

    return {
      avgQueryTimeMs: metrics.avgQueryTime ?? 0,
      requestsPerSecond: (metrics.requestCount ?? 0) / 60,
    }
  }
}
```

### Alerting Thresholds

```typescript
const SCALING_ALERTS = {
  capacity: {
    warning: 70,   // % of 10GB
    critical: 90,
  },
  queryLatency: {
    warning: 50,   // ms
    critical: 200,
  },
  skewRatio: {
    warning: 1.5,
    critical: 2.5,
  },
}

async function checkScalingHealth(env: Env): Promise<HealthReport> {
  const shards = await getShardStats(env)
  const alerts: Alert[] = []

  for (const shard of shards) {
    if (shard.capacityPercent > SCALING_ALERTS.capacity.critical) {
      alerts.push({
        severity: 'critical',
        shard: shard.id,
        message: `Shard at ${shard.capacityPercent}% capacity`,
      })
    }

    if (shard.avgQueryTimeMs > SCALING_ALERTS.queryLatency.critical) {
      alerts.push({
        severity: 'critical',
        shard: shard.id,
        message: `Query latency ${shard.avgQueryTimeMs}ms`,
      })
    }
  }

  // Check overall skew
  const skew = Math.max(...shards.map(s => s.rowCount)) / Math.min(...shards.map(s => s.rowCount))
  if (skew > SCALING_ALERTS.skewRatio.critical) {
    alerts.push({
      severity: 'warning',
      message: `Shard skew ratio: ${skew.toFixed(2)}`,
    })
  }

  return { healthy: alerts.length === 0, alerts }
}
```

## Related

<Cards>
  <Card title="Durable Objects Deep Dive" href="/docs/architecture/durable-objects">
    DO lifecycle, state management, and WebSocket handling.
  </Card>
  <Card title="Edge Computing" href="/docs/architecture/edge-computing">
    Global distribution and latency optimization.
  </Card>
  <Card title="Sharding" href="/docs/deployment/sharding">
    Detailed sharding configuration and strategies.
  </Card>
  <Card title="Geo-Replication" href="/docs/deployment/geo-replication">
    Multi-region deployment with failover.
  </Card>
</Cards>
