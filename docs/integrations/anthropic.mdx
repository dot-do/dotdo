---
title: Anthropic (Claude AI)
description: Drop-in replacement for @anthropic-ai/sdk with edge compatibility, Messages API, streaming, and tool use support
---

# Anthropic

Drop-in replacement for the Anthropic SDK. Your existing `@anthropic-ai/sdk` code works unchanged - just swap the import.

```typescript
// Before: Anthropic SDK
import Anthropic from '@anthropic-ai/sdk'

// After: dotdo compat layer
import { Anthropic } from 'compat/anthropic'

// Code stays the same
const client = new Anthropic({ apiKey: 'sk-ant-xxx' })

const message = await client.messages.create({
  model: 'claude-sonnet-4-20250514',
  max_tokens: 1024,
  messages: [{ role: 'user', content: 'Hello!' }],
})
```

## Why @dotdo/anthropic?

| Anthropic SDK | dotdo compat |
|---------------|--------------|
| Node.js runtime only | Edge-compatible (Cloudflare Workers, Deno, Bun) |
| No built-in retry logic | Automatic retries with backoff |
| Manual timeout handling | Configurable timeout (default 10min) |
| Separate from your DO code | Native integration with Durable Objects |

**This is a compatibility wrapper.** Requests are forwarded to Anthropic's API, but with edge compatibility and enhanced error handling. The wrapper is designed to work in Cloudflare Workers, Deno, Bun, and other edge runtimes.

## Features

| Feature | Status |
|---------|--------|
| Messages API | Supported |
| Streaming | Supported |
| Tool use (function calling) | Supported |
| System prompts | Supported |
| Multi-turn conversations | Supported |
| Vision (image input) | Supported |
| All Claude models | Supported |
| Automatic retries | Supported |
| Timeout handling | Supported |
| Custom headers | Supported |
| Beta features | Supported |

## Quick Start

### Import

```typescript
// Import from the compat layer
import { Anthropic } from 'compat/anthropic'
```

### Basic Message

```typescript
import { Anthropic } from 'compat/anthropic'

const client = new Anthropic({
  apiKey: process.env.ANTHROPIC_API_KEY,
})

const message = await client.messages.create({
  model: 'claude-sonnet-4-20250514',
  max_tokens: 1024,
  messages: [
    { role: 'user', content: 'What is the capital of France?' }
  ],
})

console.log(message.content[0].text)
// "The capital of France is Paris."
```

### With System Prompt

```typescript
const message = await client.messages.create({
  model: 'claude-sonnet-4-20250514',
  max_tokens: 1024,
  system: 'You are a helpful assistant that responds in JSON format.',
  messages: [
    { role: 'user', content: 'List three colors' }
  ],
})
```

### Multi-Turn Conversation

```typescript
const message = await client.messages.create({
  model: 'claude-sonnet-4-20250514',
  max_tokens: 1024,
  messages: [
    { role: 'user', content: 'My name is Alice.' },
    { role: 'assistant', content: 'Hello Alice! Nice to meet you.' },
    { role: 'user', content: 'What is my name?' },
  ],
})

console.log(message.content[0].text)
// "Your name is Alice."
```

## Streaming

Stream responses for real-time output:

```typescript
const stream = await client.messages.create({
  model: 'claude-sonnet-4-20250514',
  max_tokens: 1024,
  messages: [{ role: 'user', content: 'Write a haiku about coding' }],
  stream: true,
})

// Iterate over stream events
for await (const event of stream) {
  if (event.type === 'content_block_delta') {
    if (event.delta.type === 'text_delta') {
      process.stdout.write(event.delta.text)
    }
  }
}

// Get accumulated text after streaming
const fullText = stream.getText()
console.log('\nFull response:', fullText)

// Get the final message object
const finalMessage = stream.getFinalMessage()
console.log('Stop reason:', finalMessage.stop_reason)
console.log('Usage:', finalMessage.usage)
```

### Stream Event Types

```typescript
for await (const event of stream) {
  switch (event.type) {
    case 'message_start':
      // Message metadata (id, model, usage)
      console.log('Message ID:', event.message.id)
      break

    case 'content_block_start':
      // New content block starting
      console.log('Block type:', event.content_block.type)
      break

    case 'content_block_delta':
      // Incremental content
      if (event.delta.type === 'text_delta') {
        process.stdout.write(event.delta.text)
      }
      break

    case 'content_block_stop':
      // Content block finished
      break

    case 'message_delta':
      // Message metadata update (stop_reason, usage)
      console.log('Stop reason:', event.delta.stop_reason)
      break

    case 'message_stop':
      // Stream complete
      break
  }
}
```

## Tool Use

Define tools for Claude to call:

```typescript
const message = await client.messages.create({
  model: 'claude-sonnet-4-20250514',
  max_tokens: 1024,
  tools: [
    {
      name: 'get_weather',
      description: 'Get the current weather in a location',
      input_schema: {
        type: 'object',
        properties: {
          location: {
            type: 'string',
            description: 'The city and state, e.g. San Francisco, CA',
          },
          unit: {
            type: 'string',
            enum: ['celsius', 'fahrenheit'],
            description: 'Temperature unit',
          },
        },
        required: ['location'],
      },
    },
  ],
  messages: [
    { role: 'user', content: 'What is the weather in San Francisco?' }
  ],
})

// Check if model wants to use a tool
if (message.stop_reason === 'tool_use') {
  const toolUse = message.content.find(block => block.type === 'tool_use')
  console.log('Tool:', toolUse.name)
  console.log('Input:', toolUse.input)
  // { location: "San Francisco, CA" }
}
```

### Tool Use Flow

Complete tool use conversation:

```typescript
// Step 1: Initial request with tools
const response1 = await client.messages.create({
  model: 'claude-sonnet-4-20250514',
  max_tokens: 1024,
  tools: [weatherTool],
  messages: [
    { role: 'user', content: 'What is the weather in NYC?' }
  ],
})

// Step 2: Execute the tool and send result back
if (response1.stop_reason === 'tool_use') {
  const toolUse = response1.content.find(b => b.type === 'tool_use')

  // Execute your function
  const weatherResult = await getWeather(toolUse.input.location)

  // Step 3: Continue conversation with tool result
  const response2 = await client.messages.create({
    model: 'claude-sonnet-4-20250514',
    max_tokens: 1024,
    tools: [weatherTool],
    messages: [
      { role: 'user', content: 'What is the weather in NYC?' },
      { role: 'assistant', content: response1.content },
      {
        role: 'user',
        content: [
          {
            type: 'tool_result',
            tool_use_id: toolUse.id,
            content: JSON.stringify(weatherResult),
          },
        ],
      },
    ],
  })

  console.log(response2.content[0].text)
  // "The weather in New York City is 72F and sunny."
}
```

### Tool Choice

Control when Claude uses tools:

```typescript
// Let Claude decide (default)
tool_choice: { type: 'auto' }

// Force Claude to use a tool
tool_choice: { type: 'any' }

// Force a specific tool
tool_choice: { type: 'tool', name: 'get_weather' }
```

### Streaming with Tools

```typescript
const stream = await client.messages.create({
  model: 'claude-sonnet-4-20250514',
  max_tokens: 1024,
  tools: [weatherTool],
  messages: [{ role: 'user', content: 'What is the weather?' }],
  stream: true,
})

let toolInput = ''
for await (const event of stream) {
  if (event.type === 'content_block_delta') {
    if (event.delta.type === 'input_json_delta') {
      // Accumulate tool input JSON
      toolInput += event.delta.partial_json
    }
  }
}

// Parse accumulated JSON
const input = JSON.parse(toolInput)
```

## Direct Anthropic API Access

The compat layer connects directly to Anthropic's API with edge compatibility:

```typescript
import { Anthropic } from 'compat/anthropic'

// Direct to Anthropic API (default)
const client = new Anthropic({
  apiKey: process.env.ANTHROPIC_API_KEY,
  // Uses https://api.anthropic.com by default
})

// Custom configuration
const client = new Anthropic({
  apiKey: process.env.ANTHROPIC_API_KEY,
  timeout: 120000, // 2 minute timeout
  maxRetries: 3,   // Retry failed requests
  defaultHeaders: {
    'anthropic-beta': 'max-tokens-3-5-sonnet-2024-07-15',
  },
})
```

## Named Agent Integration

The named agents in dotdo use Claude (via `@anthropic-ai/sdk`) by default when `ANTHROPIC_API_KEY` is set:

```typescript
import { priya, ralph, tom } from 'agents/named'

// Named agents automatically use Claude when ANTHROPIC_API_KEY is set
const spec = await priya`define the MVP for ${hypothesis}`
let app = await ralph`build ${spec}`

do {
  app = await ralph`improve ${app} per ${tom}`
} while (!await tom.approve(app))
```

### Agent Configuration

Named agents can be configured with specific models:

```typescript
import { ralph } from 'agents/named'

// Configure with a specific model
const customRalph = ralph.withConfig({
  model: 'claude-sonnet-4-20250514',
  maxTokens: 8192,
  temperature: 0.7,
})

const code = await customRalph`implement a REST API for user management`
```

### Combining Named Agents

```typescript
import { priya, ralph, tom, mark, sally, quinn } from 'agents/named'

// Product development workflow
const spec = await priya`define MVP for AI-powered todo app`
const code = await ralph`implement ${spec}`
const review = await tom`review ${code}`

// If approved, launch
if ((await tom.approve(code)).approved) {
  const announcement = await mark`write launch announcement for ${spec}`
  const pitch = await sally`create sales pitch for ${spec}`
  await quinn`create test plan for ${spec}`
}
```

## Model Selection

All Claude models are supported. The model string is passed directly to the API:

```typescript
// Claude 4 (latest generation)
model: 'claude-sonnet-4-20250514'
model: 'claude-opus-4-5-20251101'

// Claude 3.5
model: 'claude-3-5-sonnet-20241022'
model: 'claude-3-5-haiku-20241022'

// Claude 3
model: 'claude-3-opus-20240229'
model: 'claude-3-sonnet-20240229'
model: 'claude-3-haiku-20240307'
```

The compat layer is a passthrough - any model ID that Anthropic's API accepts will work.

## Configuration Options

```typescript
import { Anthropic, type AnthropicConfig } from 'compat/anthropic'

const client = new Anthropic({
  // Required
  apiKey: 'sk-ant-xxx',

  // Optional
  baseURL: 'https://api.anthropic.com', // API endpoint (default)
  timeout: 600000,                       // Request timeout in ms (default: 10 minutes)
  maxRetries: 2,                         // Retry count (default: 2)
  apiVersion: '2023-06-01',              // API version (default)

  // Custom headers for all requests
  defaultHeaders: {
    'anthropic-beta': 'max-tokens-3-5-sonnet-2024-07-15',
  },

  // Custom fetch implementation (for testing)
  fetch: customFetch,
})
```

## Error Handling

```typescript
import { Anthropic, AnthropicError } from '@dotdo/anthropic'

try {
  const message = await client.messages.create({
    model: 'claude-3-5-sonnet-20241022',
    max_tokens: 1024,
    messages: [{ role: 'user', content: 'Hello' }],
  })
} catch (error) {
  if (error instanceof AnthropicError) {
    console.error('Type:', error.type)
    console.error('Message:', error.message)
    console.error('Status:', error.status)
    console.error('Request ID:', error.requestId)

    switch (error.type) {
      case 'authentication_error':
        // Invalid API key
        break
      case 'rate_limit_error':
        // Rate limited, retry later
        break
      case 'invalid_request_error':
        // Bad request parameters
        break
      case 'overloaded_error':
        // API overloaded
        break
    }
  }
}
```

### Error Types

| Type | Status | Description |
|------|--------|-------------|
| `authentication_error` | 401 | Invalid API key |
| `permission_error` | 403 | Insufficient permissions |
| `not_found_error` | 404 | Resource not found |
| `rate_limit_error` | 429 | Rate limit exceeded |
| `invalid_request_error` | 400 | Invalid request parameters |
| `overloaded_error` | 529 | API temporarily overloaded |
| `api_error` | 500 | Internal server error |

## TypeScript Types

Full TypeScript support with exported types:

```typescript
import type {
  // Config
  AnthropicConfig,

  // Messages
  Message,
  MessageParam,
  MessageCreateParams,
  Usage,
  StopReason,

  // Content blocks
  ContentBlock,
  TextBlock,
  ToolUseBlock,
  ToolResultBlock,
  ImageBlock,

  // Tools
  Tool,
  ToolInputSchema,
  ToolChoice,

  // Streaming
  MessageStream,
  MessageStreamEvent,
  TextDelta,
  InputJsonDelta,

  // Errors
  AnthropicErrorType,
} from '@dotdo/anthropic'
```

## Vision (Image Input)

Send images to Claude for analysis:

```typescript
const message = await client.messages.create({
  model: 'claude-3-5-sonnet-20241022',
  max_tokens: 1024,
  messages: [
    {
      role: 'user',
      content: [
        {
          type: 'image',
          source: {
            type: 'base64',
            media_type: 'image/png',
            data: imageBase64,
          },
        },
        {
          type: 'text',
          text: 'What is in this image?',
        },
      ],
    },
  ],
})
```

## Durable Object Integration

Use Anthropic within Durable Objects for persistent AI state:

```typescript
import { DO } from 'dotdo'
import Anthropic from '@dotdo/anthropic'

export class ChatDO extends DO {
  private client: Anthropic
  private history: MessageParam[] = []

  constructor(state: DurableObjectState, env: Env) {
    super(state, env)
    this.client = new Anthropic({ apiKey: env.ANTHROPIC_API_KEY })
  }

  async chat(userMessage: string): Promise<string> {
    // Add user message to history
    this.history.push({ role: 'user', content: userMessage })

    // Get response
    const response = await this.client.messages.create({
      model: 'claude-3-5-sonnet-20241022',
      max_tokens: 1024,
      system: 'You are a helpful assistant.',
      messages: this.history,
    })

    // Extract and store assistant response
    const assistantMessage = response.content[0].text
    this.history.push({ role: 'assistant', content: assistantMessage })

    // Persist history
    await this.state.storage.put('history', this.history)

    return assistantMessage
  }
}
```

## Migration from @anthropic-ai/sdk

### Package Change

```bash
# Remove
npm uninstall @anthropic-ai/sdk

# Install
npm install @dotdo/anthropic
```

### Import Change

```typescript
// Before
import Anthropic from '@anthropic-ai/sdk'

// After
import Anthropic from '@dotdo/anthropic'

// All your existing code works unchanged
const client = new Anthropic({ apiKey: process.env.ANTHROPIC_API_KEY })

const message = await client.messages.create({
  model: 'claude-3-5-sonnet-20241022',
  max_tokens: 1024,
  messages: [{ role: 'user', content: 'Hello!' }],
})
```

### Streaming Migration

Streaming works identically:

```typescript
// Before: @anthropic-ai/sdk
const stream = await client.messages.create({
  model: 'claude-3-5-sonnet-20241022',
  max_tokens: 1024,
  messages: [{ role: 'user', content: 'Hello!' }],
  stream: true,
})

for await (const event of stream) {
  // Handle events...
}

// After: @dotdo/anthropic
// Identical API - no changes needed
const stream = await client.messages.create({
  model: 'claude-3-5-sonnet-20241022',
  max_tokens: 1024,
  messages: [{ role: 'user', content: 'Hello!' }],
  stream: true,
})

for await (const event of stream) {
  // Same event types and structure
}
```

### Tool Use Migration

Tool definitions and tool use flow are identical:

```typescript
// Works with both @anthropic-ai/sdk and @dotdo/anthropic
const message = await client.messages.create({
  model: 'claude-3-5-sonnet-20241022',
  max_tokens: 1024,
  tools: [{
    name: 'get_weather',
    description: 'Get weather for a location',
    input_schema: {
      type: 'object',
      properties: {
        location: { type: 'string' },
      },
      required: ['location'],
    },
  }],
  messages: [{ role: 'user', content: 'What is the weather in NYC?' }],
})

// Same response structure
if (message.stop_reason === 'tool_use') {
  const toolUse = message.content.find(b => b.type === 'tool_use')
  console.log(toolUse.name, toolUse.input)
}
```

### Edge Runtime Benefits

After migration, your code works in edge runtimes:

```typescript
// Cloudflare Workers - works with @dotdo/anthropic
export default {
  async fetch(request: Request, env: Env) {
    const client = new Anthropic({ apiKey: env.ANTHROPIC_API_KEY })

    const message = await client.messages.create({
      model: 'claude-3-5-sonnet-20241022',
      max_tokens: 1024,
      messages: [{ role: 'user', content: 'Hello from the edge!' }],
    })

    return Response.json(message)
  },
}
```

## Related

- [OpenAI](/docs/integrations/openai) - OpenAI API compatibility
- [Named Agents](/docs/agents/named-agents) - Priya, Ralph, Tom, Mark, Sally, Quinn
- [Agents Overview](/docs/agents) - Multi-provider agent system
