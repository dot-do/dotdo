---
title: Apache Flink
description: Apache Flink DataStream API compatibility layer for stateful stream processing on Durable Objects.
---

# Apache Flink

Flink DataStream API compatibility layer for building stateful stream processing applications. Provides the familiar Flink API for windowing, state management, and event-time processing - all running on Cloudflare Workers with Durable Objects for state.

```typescript
import { StreamExecutionEnvironment, Time, TumblingEventTimeWindows } from '@dotdo/flink'

const env = StreamExecutionEnvironment.getExecutionEnvironment()

const stream = env.fromElements(
  { userId: 'u1', value: 1, timestamp: 1000 },
  { userId: 'u1', value: 2, timestamp: 2000 },
  { userId: 'u2', value: 3, timestamp: 3000 },
)

const result = stream
  .filter((e) => e.value > 0)
  .keyBy((e) => e.userId)
  .window(TumblingEventTimeWindows.of(Time.seconds(5)))
  .reduce((a, b) => ({ ...a, value: a.value + b.value }))

await env.execute('My Job')
```

## Why @dotdo/flink?

| Apache Flink Cluster | @dotdo/flink |
|----------------------|--------------|
| JVM-based infrastructure | Edge-native TypeScript |
| Cluster management overhead | Serverless, auto-scaling |
| Separate deployment | Integrated with your app |
| Complex state backends | Durable Object storage |

## Features

### DataStream API

- `map`, `filter`, `flatMap` transformations
- `keyBy` for keyed streams
- `union`, `connect` for stream merging
- `process` with ProcessFunction

### Windowing

- **Tumbling windows** - Fixed-size non-overlapping
- **Sliding windows** - Fixed-size with overlap
- **Session windows** - Gap-based dynamic
- **Global windows** - Unbounded

### State Management

- `ValueState` - Single value per key
- `ListState` - List of values per key
- `MapState` - Key-value pairs per key
- `ReducingState` - Aggregated values
- `AggregatingState` - Custom aggregations

### Time & Watermarks

- Event-time processing
- Processing-time processing
- Watermark strategies
- Allowed lateness

## Quick Start

### Install

```bash
npm install @dotdo/flink
```

### Basic Stream Processing

```typescript
import {
  StreamExecutionEnvironment,
  Time,
  TumblingEventTimeWindows,
  WatermarkStrategy,
} from '@dotdo/flink'

const env = StreamExecutionEnvironment.getExecutionEnvironment()

// Create stream from elements
const events = env.fromCollection([
  { userId: 'u1', event: 'click', value: 1, timestamp: 1000 },
  { userId: 'u1', event: 'click', value: 2, timestamp: 2000 },
  { userId: 'u2', event: 'click', value: 3, timestamp: 3000 },
])

// Assign timestamps and watermarks
const timedStream = events.assignTimestampsAndWatermarks(
  WatermarkStrategy.forBoundedOutOfOrderness<typeof events[0]>(Time.seconds(5))
    .withTimestampAssigner((e) => e.timestamp)
)

// Transform and aggregate
const result = timedStream
  .filter((e) => e.event === 'click')
  .keyBy((e) => e.userId)
  .window(TumblingEventTimeWindows.of(Time.seconds(10)))
  .reduce((a, b) => ({ ...a, value: a.value + b.value }))

// Print results
result.print()

// Execute
await env.execute('Click Counter')
```

## Transformations

### Map

```typescript
const mapped = stream.map((x) => ({ ...x, processed: true }))

// With MapFunction class
class MyMapper implements MapFunction<Input, Output> {
  map(value: Input): Output {
    return { ...value, processed: true }
  }
}
stream.map(new MyMapper())
```

### Filter

```typescript
const filtered = stream.filter((x) => x.value > 0)

// With FilterFunction class
class MyFilter implements FilterFunction<Event> {
  filter(value: Event): boolean {
    return value.value > 0
  }
}
stream.filter(new MyFilter())
```

### FlatMap

```typescript
const flatMapped = stream.flatMap((x, out) => {
  for (const item of x.items) {
    out.collect({ ...x, item })
  }
})
```

### KeyBy

```typescript
// By field name
const keyed = stream.keyBy('userId')

// By function
const keyed = stream.keyBy((e) => e.userId)

// Keyed stream enables stateful operations
keyed.reduce((a, b) => ({ ...a, count: a.count + b.count }))
```

## Windows

### Tumbling Windows

Non-overlapping, fixed-size windows:

```typescript
import { TumblingEventTimeWindows, TumblingProcessingTimeWindows, Time } from '@dotdo/flink'

// Event-time tumbling window
stream
  .keyBy((e) => e.userId)
  .window(TumblingEventTimeWindows.of(Time.minutes(5)))
  .reduce((a, b) => ({ ...a, count: a.count + b.count }))

// Processing-time tumbling window
stream
  .keyBy((e) => e.userId)
  .window(TumblingProcessingTimeWindows.of(Time.minutes(5)))
  .reduce((a, b) => ({ ...a, count: a.count + b.count }))

// With offset
stream
  .keyBy((e) => e.userId)
  .window(TumblingEventTimeWindows.of(Time.hours(1), Time.minutes(15)))
  .reduce((a, b) => ({ ...a, count: a.count + b.count }))
```

### Sliding Windows

Overlapping windows:

```typescript
import { SlidingEventTimeWindows, Time } from '@dotdo/flink'

// 10-minute windows that slide every 5 minutes
stream
  .keyBy((e) => e.userId)
  .window(SlidingEventTimeWindows.of(Time.minutes(10), Time.minutes(5)))
  .reduce((a, b) => ({ ...a, count: a.count + b.count }))
```

### Session Windows

Gap-based windows:

```typescript
import { SessionWindows, Time } from '@dotdo/flink'

// Sessions with 30-minute gap
stream
  .keyBy((e) => e.userId)
  .window(SessionWindows.withGap(Time.minutes(30)))
  .reduce((a, b) => ({ ...a, count: a.count + b.count }))

// Dynamic gap based on element
stream
  .keyBy((e) => e.userId)
  .window(SessionWindows.withDynamicGap({
    extract: (e) => e.sessionTimeout ?? 30 * 60 * 1000,
  }))
  .reduce((a, b) => ({ ...a, count: a.count + b.count }))
```

### Window Functions

```typescript
// Reduce
windowed.reduce((a, b) => ({ ...a, value: a.value + b.value }))

// Aggregate
windowed.aggregate({
  createAccumulator: () => ({ sum: 0, count: 0 }),
  add: (value, acc) => ({ sum: acc.sum + value.amount, count: acc.count + 1 }),
  getResult: (acc) => ({ average: acc.sum / acc.count }),
  merge: (a, b) => ({ sum: a.sum + b.sum, count: a.count + b.count }),
})

// Apply (WindowFunction)
windowed.apply({
  apply: (key, window, elements, out) => {
    const total = [...elements].reduce((sum, e) => sum + e.value, 0)
    out.collect({ key, windowStart: window.getStart(), total })
  },
})

// Process (ProcessWindowFunction)
windowed.process({
  process: (key, context, elements, out) => {
    const window = context.window()
    out.collect({
      key,
      start: window.getStart(),
      end: window.getEnd(),
      count: [...elements].length,
    })
  },
})
```

## Keyed State

Maintain state per key:

```typescript
import {
  KeyedProcessFunction,
  ValueState,
  ValueStateDescriptor,
  ListState,
  ListStateDescriptor,
  MapState,
  MapStateDescriptor,
  RuntimeContext,
  Context,
  Collector,
} from '@dotdo/flink'

class CountingFunction extends KeyedProcessFunction<string, Event, Result> {
  private count!: ValueState<number>
  private history!: ListState<Event>
  private metadata!: MapState<string, string>

  open(ctx: RuntimeContext) {
    this.count = ctx.getState(new ValueStateDescriptor('count', 0))
    this.history = ctx.getListState(new ListStateDescriptor('history'))
    this.metadata = ctx.getMapState(new MapStateDescriptor('metadata'))
  }

  processElement(event: Event, ctx: Context, out: Collector<Result>) {
    // ValueState operations
    const current = (this.count.value() ?? 0) + 1
    this.count.update(current)

    // ListState operations
    this.history.add(event)

    // MapState operations
    this.metadata.put('lastUpdate', new Date().toISOString())

    out.collect({ userId: event.userId, count: current })
  }
}

const result = stream
  .keyBy((e) => e.userId)
  .process(new CountingFunction())
```

### State TTL

Configure time-to-live for state:

```typescript
import { ValueStateDescriptor, StateTtlConfig, Time } from '@dotdo/flink'

const descriptor = new ValueStateDescriptor('count', 0)

const ttlConfig = StateTtlConfig.newBuilder(Time.hours(1))
  .setUpdateType(StateTtlConfig.UpdateType.OnCreateAndWrite)
  .setStateVisibility(StateTtlConfig.StateVisibility.NeverReturnExpired)
  .build()

descriptor.enableTimeToLive(ttlConfig)
```

## Timers

Register and fire timers in ProcessFunction:

```typescript
class TimeoutFunction extends KeyedProcessFunction<string, Event, Alert> {
  private lastEventTime!: ValueState<number>

  open(ctx: RuntimeContext) {
    this.lastEventTime = ctx.getState(new ValueStateDescriptor('lastEvent', 0))
  }

  processElement(event: Event, ctx: Context, out: Collector<Alert>) {
    // Register timer for 1 hour after event
    const timerTime = (ctx.timestamp() ?? Date.now()) + 60 * 60 * 1000
    ctx.timerService().registerEventTimeTimer(timerTime)

    this.lastEventTime.update(ctx.timestamp() ?? Date.now())
  }

  onTimer(timestamp: number, ctx: OnTimerContext, out: Collector<Alert>) {
    // Timer fired - check if we should alert
    const lastEvent = this.lastEventTime.value() ?? 0
    if (timestamp - lastEvent >= 60 * 60 * 1000) {
      out.collect({ type: 'inactivity', key: ctx.getCurrentKey() })
    }
  }
}
```

## Watermarks

Handle event-time processing:

```typescript
import {
  WatermarkStrategy,
  BoundedOutOfOrdernessWatermarks,
  AscendingTimestampsWatermarks,
  Time,
} from '@dotdo/flink'

// Bounded out-of-orderness (most common)
stream.assignTimestampsAndWatermarks(
  WatermarkStrategy.forBoundedOutOfOrderness<Event>(Time.seconds(5))
    .withTimestampAssigner((e) => e.timestamp)
)

// Monotonous timestamps (in-order events)
stream.assignTimestampsAndWatermarks(
  WatermarkStrategy.forMonotonousTimestamps<Event>()
    .withTimestampAssigner((e) => e.timestamp)
)

// No watermarks (processing-time only)
stream.assignTimestampsAndWatermarks(
  WatermarkStrategy.noWatermarks<Event>()
)

// Custom watermark generator
stream.assignTimestampsAndWatermarks(
  WatermarkStrategy.forGenerator(() => new MyWatermarkGenerator())
    .withTimestampAssigner((e) => e.timestamp)
    .withIdleness(Time.minutes(5))
)
```

## Triggers

Control when windows fire:

```typescript
import {
  EventTimeTrigger,
  ProcessingTimeTrigger,
  CountTrigger,
  ContinuousEventTimeTrigger,
  PurgingTrigger,
  Time,
} from '@dotdo/flink'

// Event time trigger (default for event-time windows)
windowed.trigger(EventTimeTrigger.create())

// Processing time trigger
windowed.trigger(ProcessingTimeTrigger.create())

// Count trigger - fire every N elements
windowed.trigger(CountTrigger.of(100))

// Continuous event time - fire every interval
windowed.trigger(ContinuousEventTimeTrigger.of(Time.minutes(1)))

// Purging trigger wrapper - clear after firing
windowed.trigger(PurgingTrigger.of(EventTimeTrigger.create()))
```

## Evictors

Remove elements from windows:

```typescript
import { CountEvictor, TimeEvictor, DeltaEvictor, Time } from '@dotdo/flink'

// Keep only last N elements
windowed.evictor(CountEvictor.of(100))

// Remove elements older than duration
windowed.evictor(TimeEvictor.of(Time.minutes(5)))

// Remove based on delta function
windowed.evictor(
  DeltaEvictor.of(
    100,
    (a, b) => Math.abs(a.value - b.value)
  )
)
```

## Connected Streams

Join two streams:

```typescript
// Connect streams
const connected = stream1.connect(stream2)

// Process connected streams
const result = connected.process({
  processElement1: (value, ctx, out) => {
    out.collect({ source: 'stream1', ...value })
  },
  processElement2: (value, ctx, out) => {
    out.collect({ source: 'stream2', ...value })
  },
})

// Key connected streams
stream1
  .keyBy((e) => e.userId)
  .connect(stream2.keyBy((e) => e.userId))
  .process(new KeyedCoProcessFunction())
```

## Side Outputs

Emit to multiple outputs:

```typescript
import { OutputTag, ProcessFunction } from '@dotdo/flink'

const lateDataTag = new OutputTag<Event>('late-data')
const errorTag = new OutputTag<Error>('errors')

class MyProcessFunction extends ProcessFunction<Event, Result> {
  processElement(event: Event, ctx: Context, out: Collector<Result>) {
    if (event.isLate) {
      ctx.output(lateDataTag, event)
    } else if (event.error) {
      ctx.output(errorTag, event.error)
    } else {
      out.collect({ processed: true, ...event })
    }
  }
}

const mainStream = stream.process(new MyProcessFunction())
const lateStream = mainStream.getSideOutput(lateDataTag)
const errorStream = mainStream.getSideOutput(errorTag)
```

## Checkpointing

Configure checkpointing for fault tolerance:

```typescript
import { CheckpointingMode, CheckpointStorage } from '@dotdo/flink'

const env = StreamExecutionEnvironment.getExecutionEnvironment()

// Enable checkpointing every 5 minutes
env.enableCheckpointing(5 * 60 * 1000, CheckpointingMode.EXACTLY_ONCE)

// Configure checkpoint settings
const config = env.getCheckpointConfig()
config.setCheckpointTimeout(10 * 60 * 1000)
config.setMinPauseBetweenCheckpoints(60 * 1000)
config.setMaxConcurrentCheckpoints(1)
config.enableUnalignedCheckpoints()
```

## API Reference

### StreamExecutionEnvironment

```typescript
class StreamExecutionEnvironment {
  static getExecutionEnvironment(): StreamExecutionEnvironment
  static createLocalEnvironment(): LocalStreamEnvironment

  setParallelism(parallelism: number): StreamExecutionEnvironment
  enableCheckpointing(interval: number, mode?: CheckpointingMode): StreamExecutionEnvironment

  fromElements<T>(...elements: T[]): DataStream<T>
  fromCollection<T>(collection: T[]): DataStream<T>
  addSource<T>(source: SourceFunction<T>): DataStream<T>

  execute(jobName?: string): Promise<JobExecutionResult>
}
```

### DataStream

```typescript
class DataStream<T> {
  map<R>(mapper: (value: T) => R): DataStream<R>
  filter(predicate: (value: T) => boolean): DataStream<T>
  flatMap<R>(flatMapper: (value: T, out: Collector<R>) => void): DataStream<R>
  keyBy<K>(keySelector: (value: T) => K): KeyedStream<T, K>
  process<R>(processFunction: ProcessFunction<T, R>): DataStream<R>
  union(...streams: DataStream<T>[]): DataStream<T>
  connect<T2>(other: DataStream<T2>): ConnectedStreams<T, T2>
  assignTimestampsAndWatermarks(strategy: WatermarkStrategy<T>): DataStream<T>
  print(identifier?: string): void
  addSink(sink: SinkFunction<T>): void
}
```

### KeyedStream

```typescript
class KeyedStream<T, K> extends DataStream<T> {
  reduce(reducer: (a: T, b: T) => T): DataStream<T>
  sum(field: keyof T): DataStream<T>
  window<W extends TimeWindow>(assigner: WindowAssigner<T, W>): WindowedStream<T, K, W>
  process<R>(processFunction: KeyedProcessFunction<K, T, R>): DataStream<R>
}
```

## Types

```typescript
import type {
  // Stream types
  DataStream,
  KeyedStream,
  WindowedStream,
  ConnectedStreams,

  // Function types
  MapFunction,
  FilterFunction,
  FlatMapFunction,
  ReduceFunction,
  AggregateFunction,
  ProcessFunction,
  KeyedProcessFunction,
  WindowFunction,

  // Window types
  TimeWindow,
  WindowAssigner,
  Trigger,
  TriggerResult,
  Evictor,

  // State types
  ValueState,
  ListState,
  MapState,
  ReducingState,
  AggregatingState,
  StateDescriptor,

  // Time types
  Time,
  Duration,
  WatermarkStrategy,
  WatermarkGenerator,
  TimestampAssigner,

  // Context types
  RuntimeContext,
  Context,
  OnTimerContext,
  Collector,
} from '@dotdo/flink'
```

## Related

- [Kafka](/docs/integrations/kafka) - Kafka source/sink connectors
- [Workflows](/docs/workflows) - Workflow orchestration
- [Events](/docs/events) - Event handling patterns
