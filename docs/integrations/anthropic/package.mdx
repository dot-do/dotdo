---
title: "@dotdo/anthropic"
description: Drop-in replacement for @anthropic-ai/sdk with edge compatibility, automatic retries, and streaming support.
---

# @dotdo/anthropic

Drop-in replacement for the Anthropic SDK that runs in edge environments. Same API as `@anthropic-ai/sdk`, but compatible with Cloudflare Workers, Deno, and other edge runtimes.

```typescript
import { Anthropic } from '@dotdo/anthropic'

const client = new Anthropic({ apiKey: process.env.ANTHROPIC_API_KEY })

const message = await client.messages.create({
  model: 'claude-sonnet-4-20250514',
  max_tokens: 1024,
  messages: [{ role: 'user', content: 'Hello!' }],
})

console.log(message.content[0].text)
```

<Callout type="info">
Looking for managed Claude with caching and rate limiting? See [anthropic.do](/docs/integrations/anthropic/service) for a fully managed edge service.
</Callout>

## Why @dotdo/anthropic?

| Anthropic SDK | @dotdo/anthropic |
|---------------|------------------|
| Node.js runtime only | Edge-compatible (V8 isolates) |
| No built-in retry logic | Automatic retries with backoff |
| Manual timeout handling | Configurable timeout (default 10min) |
| Separate from DO code | Native integration with Durable Objects |

**This is a compatibility wrapper.** Requests are forwarded to Anthropic's API, but with edge compatibility and enhanced error handling. The wrapper is designed to work in Cloudflare Workers, Deno, Bun, and other edge runtimes.

## Installation

```bash
npm install @dotdo/anthropic
```

## Features

| Feature | Status |
|---------|--------|
| Messages API | Supported |
| Streaming | Supported |
| Tool use (function calling) | Supported |
| System prompts | Supported |
| Multi-turn conversations | Supported |
| Vision (image input) | Supported |
| All Claude models | Supported |
| Automatic retries | Supported |
| Timeout handling | Supported |
| Custom headers | Supported |
| Beta features | Supported |

## Quick Start

### Basic Message

```typescript
import { Anthropic } from '@dotdo/anthropic'

const client = new Anthropic({
  apiKey: process.env.ANTHROPIC_API_KEY,
})

const message = await client.messages.create({
  model: 'claude-sonnet-4-20250514',
  max_tokens: 1024,
  messages: [
    { role: 'user', content: 'What is the capital of France?' }
  ],
})

console.log(message.content[0].text)
// "The capital of France is Paris."
```

### With System Prompt

```typescript
const message = await client.messages.create({
  model: 'claude-sonnet-4-20250514',
  max_tokens: 1024,
  system: 'You are a helpful assistant that responds in JSON format.',
  messages: [
    { role: 'user', content: 'List three colors' }
  ],
})
```

### Multi-Turn Conversation

```typescript
const message = await client.messages.create({
  model: 'claude-sonnet-4-20250514',
  max_tokens: 1024,
  messages: [
    { role: 'user', content: 'My name is Alice.' },
    { role: 'assistant', content: 'Hello Alice! Nice to meet you.' },
    { role: 'user', content: 'What is my name?' },
  ],
})

console.log(message.content[0].text)
// "Your name is Alice."
```

## Streaming

Stream responses for real-time output:

```typescript
const stream = await client.messages.create({
  model: 'claude-sonnet-4-20250514',
  max_tokens: 1024,
  messages: [{ role: 'user', content: 'Write a haiku about coding' }],
  stream: true,
})

// Iterate over stream events
for await (const event of stream) {
  if (event.type === 'content_block_delta') {
    if (event.delta.type === 'text_delta') {
      process.stdout.write(event.delta.text)
    }
  }
}

// Get accumulated text after streaming
const fullText = stream.getText()
console.log('\nFull response:', fullText)

// Get the final message object
const finalMessage = stream.getFinalMessage()
console.log('Stop reason:', finalMessage.stop_reason)
console.log('Usage:', finalMessage.usage)
```

### Stream Event Types

```typescript
for await (const event of stream) {
  switch (event.type) {
    case 'message_start':
      // Message metadata (id, model, usage)
      console.log('Message ID:', event.message.id)
      break

    case 'content_block_start':
      // New content block starting
      console.log('Block type:', event.content_block.type)
      break

    case 'content_block_delta':
      // Incremental content
      if (event.delta.type === 'text_delta') {
        process.stdout.write(event.delta.text)
      }
      break

    case 'content_block_stop':
      // Content block finished
      break

    case 'message_delta':
      // Message metadata update (stop_reason, usage)
      console.log('Stop reason:', event.delta.stop_reason)
      break

    case 'message_stop':
      // Stream complete
      break
  }
}
```

## Tool Use

Define tools for Claude to call:

```typescript
const message = await client.messages.create({
  model: 'claude-sonnet-4-20250514',
  max_tokens: 1024,
  tools: [
    {
      name: 'get_weather',
      description: 'Get the current weather in a location',
      input_schema: {
        type: 'object',
        properties: {
          location: {
            type: 'string',
            description: 'The city and state, e.g. San Francisco, CA',
          },
          unit: {
            type: 'string',
            enum: ['celsius', 'fahrenheit'],
            description: 'Temperature unit',
          },
        },
        required: ['location'],
      },
    },
  ],
  messages: [
    { role: 'user', content: 'What is the weather in San Francisco?' }
  ],
})

// Check if model wants to use a tool
if (message.stop_reason === 'tool_use') {
  const toolUse = message.content.find(block => block.type === 'tool_use')
  console.log('Tool:', toolUse.name)
  console.log('Input:', toolUse.input)
  // { location: "San Francisco, CA" }
}
```

### Tool Use Flow

Complete tool use conversation:

```typescript
// Step 1: Initial request with tools
const response1 = await client.messages.create({
  model: 'claude-sonnet-4-20250514',
  max_tokens: 1024,
  tools: [weatherTool],
  messages: [
    { role: 'user', content: 'What is the weather in NYC?' }
  ],
})

// Step 2: Execute the tool and send result back
if (response1.stop_reason === 'tool_use') {
  const toolUse = response1.content.find(b => b.type === 'tool_use')

  // Execute your function
  const weatherResult = await getWeather(toolUse.input.location)

  // Step 3: Continue conversation with tool result
  const response2 = await client.messages.create({
    model: 'claude-sonnet-4-20250514',
    max_tokens: 1024,
    tools: [weatherTool],
    messages: [
      { role: 'user', content: 'What is the weather in NYC?' },
      { role: 'assistant', content: response1.content },
      {
        role: 'user',
        content: [
          {
            type: 'tool_result',
            tool_use_id: toolUse.id,
            content: JSON.stringify(weatherResult),
          },
        ],
      },
    ],
  })

  console.log(response2.content[0].text)
  // "The weather in New York City is 72F and sunny."
}
```

### Tool Choice

Control when Claude uses tools:

```typescript
// Let Claude decide (default)
tool_choice: { type: 'auto' }

// Force Claude to use a tool
tool_choice: { type: 'any' }

// Force a specific tool
tool_choice: { type: 'tool', name: 'get_weather' }
```

### Streaming with Tools

```typescript
const stream = await client.messages.create({
  model: 'claude-sonnet-4-20250514',
  max_tokens: 1024,
  tools: [weatherTool],
  messages: [{ role: 'user', content: 'What is the weather?' }],
  stream: true,
})

let toolInput = ''
for await (const event of stream) {
  if (event.type === 'content_block_delta') {
    if (event.delta.type === 'input_json_delta') {
      // Accumulate tool input JSON
      toolInput += event.delta.partial_json
    }
  }
}

// Parse accumulated JSON
const input = JSON.parse(toolInput)
```

## Vision (Image Input)

Send images to Claude for analysis:

```typescript
const message = await client.messages.create({
  model: 'claude-sonnet-4-20250514',
  max_tokens: 1024,
  messages: [
    {
      role: 'user',
      content: [
        {
          type: 'image',
          source: {
            type: 'base64',
            media_type: 'image/png',
            data: imageBase64,
          },
        },
        {
          type: 'text',
          text: 'What is in this image?',
        },
      ],
    },
  ],
})
```

## Model Selection

All Claude models are supported. The model string is passed directly to the API:

```typescript
// Claude 4 (latest generation)
model: 'claude-sonnet-4-20250514'
model: 'claude-opus-4-5-20251101'

// Claude 3.5
model: 'claude-3-5-sonnet-20241022'
model: 'claude-3-5-haiku-20241022'

// Claude 3
model: 'claude-3-opus-20240229'
model: 'claude-3-sonnet-20240229'
model: 'claude-3-haiku-20240307'
```

The compat layer is a passthrough - any model ID that Anthropic's API accepts will work.

## Configuration Options

```typescript
import { Anthropic, type AnthropicConfig } from '@dotdo/anthropic'

const client = new Anthropic({
  // Required
  apiKey: 'sk-ant-xxx',

  // Optional
  baseURL: 'https://api.anthropic.com', // API endpoint (default)
  timeout: 600000,                       // Request timeout in ms (default: 10 minutes)
  maxRetries: 2,                         // Retry count (default: 2)
  apiVersion: '2023-06-01',              // API version (default)

  // Custom headers for all requests
  defaultHeaders: {
    'anthropic-beta': 'max-tokens-3-5-sonnet-2024-07-15',
  },

  // Custom fetch implementation (for testing)
  fetch: customFetch,
})
```

## Error Handling

```typescript
import { Anthropic, AnthropicError } from '@dotdo/anthropic'

try {
  const message = await client.messages.create({
    model: 'claude-sonnet-4-20250514',
    max_tokens: 1024,
    messages: [{ role: 'user', content: 'Hello' }],
  })
} catch (error) {
  if (error instanceof AnthropicError) {
    console.error('Type:', error.type)
    console.error('Message:', error.message)
    console.error('Status:', error.status)
    console.error('Request ID:', error.requestId)

    switch (error.type) {
      case 'authentication_error':
        // Invalid API key
        break
      case 'rate_limit_error':
        // Rate limited, retry later
        break
      case 'invalid_request_error':
        // Bad request parameters
        break
      case 'overloaded_error':
        // API overloaded
        break
    }
  }
}
```

### Error Types

| Type | Status | Description |
|------|--------|-------------|
| `authentication_error` | 401 | Invalid API key |
| `permission_error` | 403 | Insufficient permissions |
| `not_found_error` | 404 | Resource not found |
| `rate_limit_error` | 429 | Rate limit exceeded |
| `invalid_request_error` | 400 | Invalid request parameters |
| `overloaded_error` | 529 | API temporarily overloaded |
| `api_error` | 500 | Internal server error |

## TypeScript Types

Full TypeScript support with exported types:

```typescript
import type {
  // Config
  AnthropicConfig,

  // Messages
  Message,
  MessageParam,
  MessageCreateParams,
  Usage,
  StopReason,

  // Content blocks
  ContentBlock,
  TextBlock,
  ToolUseBlock,
  ToolResultBlock,
  ImageBlock,

  // Tools
  Tool,
  ToolInputSchema,
  ToolChoice,

  // Streaming
  MessageStream,
  MessageStreamEvent,
  TextDelta,
  InputJsonDelta,

  // Errors
  AnthropicErrorType,
} from '@dotdo/anthropic'
```

## Edge Compatibility

Works in Cloudflare Workers without Node.js dependencies:

```typescript
// worker.ts
import { Anthropic } from '@dotdo/anthropic'

export default {
  async fetch(request: Request, env: Env): Promise<Response> {
    const client = new Anthropic({ apiKey: env.ANTHROPIC_API_KEY })

    const message = await client.messages.create({
      model: 'claude-sonnet-4-20250514',
      max_tokens: 1024,
      messages: [{ role: 'user', content: 'Hello from the edge!' }],
    })

    return Response.json(message)
  },
}
```

## Durable Object Integration

Use Anthropic within Durable Objects for persistent AI state:

```typescript
import { DO } from 'dotdo'
import { Anthropic } from '@dotdo/anthropic'

export class ChatDO extends DO {
  private client: Anthropic
  private history: MessageParam[] = []

  constructor(state: DurableObjectState, env: Env) {
    super(state, env)
    this.client = new Anthropic({ apiKey: env.ANTHROPIC_API_KEY })
  }

  async chat(userMessage: string): Promise<string> {
    // Add user message to history
    this.history.push({ role: 'user', content: userMessage })

    // Get response
    const response = await this.client.messages.create({
      model: 'claude-sonnet-4-20250514',
      max_tokens: 1024,
      system: 'You are a helpful assistant.',
      messages: this.history,
    })

    // Extract and store assistant response
    const assistantMessage = response.content[0].text
    this.history.push({ role: 'assistant', content: assistantMessage })

    // Persist history
    await this.state.storage.put('history', this.history)

    return assistantMessage
  }
}
```

## Named Agent Integration

The named agents in dotdo use Claude (via `@anthropic-ai/sdk`) by default when `ANTHROPIC_API_KEY` is set:

```typescript
import { priya, ralph, tom } from 'agents/named'

// Named agents automatically use Claude when ANTHROPIC_API_KEY is set
const spec = await priya`define the MVP for ${hypothesis}`
let app = await ralph`build ${spec}`

do {
  app = await ralph`improve ${app} per ${tom}`
} while (!await tom.approve(app))
```

### Agent Configuration

Named agents can be configured with specific models:

```typescript
import { ralph } from 'agents/named'

// Configure with a specific model
const customRalph = ralph.withConfig({
  model: 'claude-sonnet-4-20250514',
  maxTokens: 8192,
  temperature: 0.7,
})

const code = await customRalph`implement a REST API for user management`
```

## Testing with @dotdo/anthropic

The package is ideal for testing - use custom fetch for mocking:

```typescript
import { Anthropic } from '@dotdo/anthropic'

describe('AI Features', () => {
  it('should handle chat messages', async () => {
    const mockFetch = vi.fn().mockResolvedValue(
      new Response(JSON.stringify({
        id: 'msg_123',
        content: [{ type: 'text', text: 'Hello!' }],
        stop_reason: 'end_turn',
        usage: { input_tokens: 10, output_tokens: 5 },
      }))
    )

    const client = new Anthropic({
      apiKey: 'test-key',
      fetch: mockFetch,
    })

    const message = await client.messages.create({
      model: 'claude-sonnet-4-20250514',
      max_tokens: 1024,
      messages: [{ role: 'user', content: 'Hello' }],
    })

    expect(message.content[0].text).toBe('Hello!')
  })
})
```

## Migration from @anthropic-ai/sdk

### Package Change

```bash
# Remove
npm uninstall @anthropic-ai/sdk

# Install
npm install @dotdo/anthropic
```

### Import Change

```typescript
// Before
import Anthropic from '@anthropic-ai/sdk'

// After
import { Anthropic } from '@dotdo/anthropic'

// All your existing code works unchanged
const client = new Anthropic({ apiKey: process.env.ANTHROPIC_API_KEY })

const message = await client.messages.create({
  model: 'claude-sonnet-4-20250514',
  max_tokens: 1024,
  messages: [{ role: 'user', content: 'Hello!' }],
})
```

## Related

- [anthropic.do](/docs/integrations/anthropic/service) - Managed Claude on the edge
- [OpenAI Integration](/docs/integrations/openai) - OpenAI API compatibility
- [Named Agents](/docs/agents/named-agents) - Priya, Ralph, Tom, Mark, Sally, Quinn
