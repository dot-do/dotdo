---
title: DuckDB
description: Drop-in replacement for DuckDB with edge-native WASM execution, Parquet support, and analytical query capabilities.
---

# DuckDB

Drop-in replacement for the DuckDB JavaScript SDK. Your existing `duckdb` code works unchanged - just swap the import.

```typescript
// Before: DuckDB Node.js
import duckdb from 'duckdb'

// After: dotdo
import { Database, open } from '@dotdo/duckdb'

// Code stays the same
const db = new Database(':memory:')

db.run('CREATE TABLE users (id INTEGER, name VARCHAR, age INTEGER)')
db.run('INSERT INTO users VALUES (?, ?, ?)', [1, 'Alice', 30])

const users = db.all('SELECT * FROM users WHERE age > ?', [25])
console.log(users) // [{ id: 1, name: 'Alice', age: 30 }]
```

## Why duckdb.do?

| DuckDB Node.js | @dotdo/duckdb |
|----------------|---------------|
| Node.js runtime required | Edge-compatible (Cloudflare Workers) |
| Requires native binaries | Pure WASM execution |
| ~50MB binary size | WASM loaded from CDN |
| Single-machine analytics | Analytics at the edge |
| Local filesystem only | R2/S3 Parquet integration |
| No vector search | VSS extension for embeddings |
| No full-text search | FTS extension with BM25 |

**This is a compatibility layer with two modes:**
1. **Inbound Mode** - DuckDB WASM runs directly in Workers for edge analytics
2. **Outbound Mode** - Connect to external DuckDB instances or file-based databases

## Features

### Implemented (Core APIs)

**Database Management**
- `new Database()` - Create in-memory or file-based database
- `open()` - Async factory for database creation
- `connect()` - Create connections for async operations
- `close()` - Close database and release resources

**Query Execution**
- `run()` - Execute DDL/DML statements (CREATE, INSERT, UPDATE, DELETE)
- `all()` - Execute SELECT queries returning all rows
- `get()` - Execute SELECT returning single row
- `each()` - Row-by-row iteration with callbacks
- `exec()` - Execute multiple statements

**Prepared Statements**
- `prepare()` - Create reusable prepared statement
- `bind()` - Bind parameters to statement
- `Statement.all()`, `Statement.get()`, `Statement.run()` - Execute prepared statement
- `finalize()` - Release statement resources

**Aggregate Functions**
- `COUNT()`, `SUM()`, `AVG()`, `MIN()`, `MAX()`
- `GROUP BY`, `HAVING`, `ORDER BY`
- Window functions

**DuckDB WASM Extensions**
- Full-Text Search (FTS) with BM25 ranking
- Vector Similarity Search (VSS) with HNSW indexes
- Iceberg table support with R2 integration
- Parquet file scanning from R2/S3

### Data Types Supported

| Type | Description |
|------|-------------|
| `INTEGER` | 32-bit signed integer |
| `BIGINT` | 64-bit signed integer |
| `DOUBLE` | 64-bit floating point |
| `VARCHAR` | Variable-length string |
| `BOOLEAN` | True/false |
| `DATE` | Calendar date |
| `TIMESTAMP` | Date and time |
| `BLOB` | Binary data |
| `FLOAT[]` | Vector arrays (for VSS) |

## Quick Start

### Install

```bash
npm install @dotdo/duckdb
```

### Basic Usage

```typescript
import { Database } from '@dotdo/duckdb'

const db = new Database(':memory:')

// Create table
db.run(`
  CREATE TABLE events (
    id INTEGER PRIMARY KEY,
    event_type VARCHAR,
    user_id INTEGER,
    timestamp TIMESTAMP,
    properties VARCHAR
  )
`)

// Insert data
db.run('INSERT INTO events VALUES (?, ?, ?, ?, ?)', [
  1, 'page_view', 42, '2024-01-15 10:30:00', '{"page": "/home"}'
])

// Analytical query
const results = db.all(`
  SELECT
    event_type,
    COUNT(*) as count,
    COUNT(DISTINCT user_id) as unique_users
  FROM events
  WHERE timestamp >= '2024-01-01'
  GROUP BY event_type
  ORDER BY count DESC
`)

console.log(results)
db.close()
```

### Async API

```typescript
import { open } from '@dotdo/duckdb'

const db = await open(':memory:')
const conn = await db.connect()

await conn.run('CREATE TABLE users (id INTEGER, name VARCHAR)')
await conn.run('INSERT INTO users VALUES (?, ?)', [1, 'Alice'])

const users = await conn.all('SELECT * FROM users')
console.log(users)

await conn.close()
await db.close()
```

### Prepared Statements

```typescript
import { Database } from '@dotdo/duckdb'

const db = new Database(':memory:')
db.run('CREATE TABLE logs (id INTEGER, message VARCHAR, level VARCHAR)')

// Prepare reusable insert statement
const insertStmt = db.prepare('INSERT INTO logs VALUES (?, ?, ?)')
insertStmt.run(1, 'Starting up', 'INFO')
insertStmt.run(2, 'Warning!', 'WARN')
insertStmt.run(3, 'Error occurred', 'ERROR')
insertStmt.finalize()

// Prepare reusable select statement
const selectStmt = db.prepare('SELECT * FROM logs WHERE level = ?')
const warnings = selectStmt.all('WARN')
const errors = selectStmt.all('ERROR')
selectStmt.finalize()

db.close()
```

## Inbound Mode - DuckDB WASM at the Edge

Run DuckDB directly in Cloudflare Workers using WebAssembly.

### Basic WASM Usage

```typescript
import { createDuckDB } from '@dotdo/duckdb-wasm'

export default {
  async fetch(request: Request, env: Env): Promise<Response> {
    const db = await createDuckDB()

    // Create and query tables
    await db.query('CREATE TABLE metrics (name VARCHAR, value DOUBLE)')
    await db.query("INSERT INTO metrics VALUES ('cpu', 45.5)")

    const result = await db.query('SELECT * FROM metrics')
    await db.close()

    return Response.json(result.rows)
  }
}
```

### Querying Parquet from R2

Load Parquet files from R2 and query with SQL:

```typescript
import { createDuckDB, registerBuffer } from '@dotdo/duckdb-wasm'

export default {
  async fetch(request: Request, env: Env): Promise<Response> {
    const db = await createDuckDB()

    // Fetch Parquet file from R2
    const object = await env.R2_BUCKET.get('analytics/sales-2024.parquet')
    const buffer = await object.arrayBuffer()

    // Register the buffer as a virtual file
    await db.registerBuffer('sales.parquet', buffer)

    // Query the Parquet data
    const result = await db.query(`
      SELECT
        region,
        SUM(revenue) as total_revenue,
        COUNT(*) as transactions
      FROM parquet_scan('sales.parquet')
      GROUP BY region
      ORDER BY total_revenue DESC
    `)

    await db.close()
    return Response.json(result.rows)
  }
}
```

### Full-Text Search (FTS)

BM25-ranked full-text search using the FTS extension:

```typescript
import { createDuckDB } from '@dotdo/duckdb-wasm'
import { createFTSIndex, search, rebuildIndex } from '@dotdo/duckdb-wasm/fts'

const db = await createDuckDB()

// Create table with text content
await db.query(`
  CREATE TABLE articles (
    id INTEGER PRIMARY KEY,
    title VARCHAR,
    body VARCHAR
  )
`)

await db.query(`INSERT INTO articles VALUES (1, 'Introduction to DuckDB', 'DuckDB is an analytical database...')`)
await db.query(`INSERT INTO articles VALUES (2, 'Vector Search Guide', 'Learn how to search embeddings...')`)

// Create FTS index
await createFTSIndex(db, {
  table: 'articles',
  columns: ['title', 'body'],
  stemmer: 'english',
})

// Search with BM25 ranking
const results = await search(db, 'articles', 'analytical database', {
  limit: 10,
  minScore: 0.5,
})

console.log(results)
// { results: [{ docId: 1, score: 2.5, document: {...} }], totalCount: 1, ... }

// After data changes, rebuild index
await db.query("INSERT INTO articles VALUES (3, 'New Article', '...')")
await rebuildIndex(db, 'articles')
```

### Vector Similarity Search (VSS)

HNSW-based vector search for embeddings:

```typescript
import { createDuckDB } from '@dotdo/duckdb-wasm'
import { loadVSS, createVectorIndex, search, estimateMemory } from '@dotdo/duckdb-wasm/vss'

const db = await createDuckDB()
await loadVSS(db)

// Create table with vector column
await db.query(`
  CREATE TABLE items (
    id INTEGER PRIMARY KEY,
    name VARCHAR,
    category VARCHAR,
    embedding FLOAT[768]
  )
`)

// Insert embeddings (from your embedding model)
await db.query(`INSERT INTO items VALUES (1, 'Red Sneakers', 'shoes', [0.1, 0.2, ...])`)

// Create HNSW index
await createVectorIndex(db, 'items', 'embedding', {
  dimensions: 768,
  metric: 'cosine',  // or 'l2', 'l2sq', 'ip'
  M: 16,
  efConstruction: 200,
})

// Search for similar vectors
const queryVector = [0.15, 0.22, ...] // Your query embedding
const results = await search(db, 'items', 'embedding', queryVector, {
  k: 10,
  filter: "category = 'shoes'",
  select: ['name', 'category'],
})

console.log(results)
// [{ id: 1, distance: 0.05, data: { name: 'Red Sneakers', category: 'shoes' } }]

// Estimate memory requirements
const estimate = estimateMemory({
  vectorCount: 1_000_000,
  dimensions: 768,
})
console.log(estimate.humanReadable) // "3.42 GB"
```

### Iceberg Table Integration

Query Iceberg tables stored in R2:

```typescript
import { createDuckDB } from '@dotdo/duckdb-wasm'
import { createDataSource, registerIcebergTable, scanIcebergTable } from '@dotdo/duckdb-wasm/iceberg'

// Create data source for R2 catalog
const dataSource = createDataSource({
  catalogConfig: {
    accountId: 'abc123',
    accessKeyId: env.R2_ACCESS_KEY,
    secretAccessKey: env.R2_SECRET_KEY,
    endpoint: 'https://abc123.r2.cloudflarestorage.com',
    bucketName: 'iceberg-data',
  },
  r2Bucket: env.R2_BUCKET,
  cacheTtlMs: 60000,
})

// Get table metadata
const table = await dataSource.getTable('analytics', 'events')

// Scan with partition pruning
const scanResult = await scanIcebergTable({
  namespace: 'analytics',
  tableName: 'events',
  predicate: { column: 'event_date', op: '>=', value: '2024-01-01' },
  metadata: table.metadata,
  fetchParquet: async (path) => {
    const obj = await env.R2_BUCKET.get(path)
    return obj?.arrayBuffer() ?? new ArrayBuffer(0)
  },
})

console.log(`Pruned ${scanResult.prunedPartitions} partitions`)
console.log(`Scanned ${scanResult.scannedFiles} files (${scanResult.scannedBytes} bytes)`)
```

## Outbound Mode - Connecting to DuckDB

For development and testing, use the Node.js-compatible API:

```typescript
import { Database } from '@dotdo/duckdb'

// In-memory database
const memDb = new Database(':memory:')

// File-based database
const fileDb = new Database('/path/to/database.duckdb')

// With configuration
const configDb = new Database(':memory:', {
  access_mode: 'read_write',
  threads: 4,
  max_memory: '512MB',
})
```

### Configuration Options

```typescript
interface DatabaseConfig {
  access_mode?: 'read_only' | 'read_write'
  threads?: number
  max_memory?: string
  default_null_order?: 'nulls_first' | 'nulls_last'
  default_order?: 'asc' | 'desc'
  enable_external_access?: boolean
}
```

## API Reference

### Database

```typescript
class Database {
  // Properties
  readonly path: string
  readonly open: boolean

  // Constructor
  constructor(path?: string, config?: DatabaseConfig, callback?: DatabaseCallback)

  // Query methods
  run(sql: string, params?: unknown[], callback?: RunCallback): QueryResult
  all<T>(sql: string, params?: unknown[], callback?: AllCallback<T>): T[]
  get<T>(sql: string, params?: unknown[], callback?: GetCallback<T>): T | undefined
  each<T>(sql: string, callback: EachRowCallback<T>, complete?: EachCompleteCallback): void
  exec(sql: string, callback?: (err: Error | null) => void): this

  // Prepared statements
  prepare(sql: string): Statement

  // Async API
  connect(): Promise<Connection>
  close(callback?: CloseCallback): void
}
```

### Statement

```typescript
class Statement {
  readonly sql: string

  bind(...params: unknown[]): this
  run(...params: unknown[]): QueryResult
  all<T>(...params: unknown[]): T[]
  get<T>(...params: unknown[]): T | undefined
  finalize(callback?: FinalizeCallback): void
}
```

### Connection (Async)

```typescript
interface Connection {
  run(sql: string, params?: unknown[]): Promise<QueryResult>
  all<T>(sql: string, params?: unknown[]): Promise<T[]>
  get<T>(sql: string, params?: unknown[]): Promise<T | undefined>
  prepare(sql: string): Promise<Statement>
  close(): Promise<void>
}
```

### DuckDB WASM Instance

```typescript
interface DuckDBInstance {
  readonly path: string
  readonly open: boolean

  query<T>(sql: string, params?: unknown[], options?: QueryOptions): Promise<QueryResult<T>>
  registerBuffer(name: string, buffer: ArrayBuffer | Uint8Array, options?: BufferRegistrationOptions): Promise<BufferRegistrationResult>
  dropBuffer(name: string): Promise<void>
  close(): Promise<void>
}

interface QueryResult<T> {
  rows: T[]
  columns: ColumnInfo[]
  rowsAffected?: number
}

interface BufferRegistrationResult {
  name: string
  sizeBytes: number
  overwritten: boolean
}
```

### FTS Functions

```typescript
import {
  createFTSIndex,
  dropFTSIndex,
  search,
  rebuildIndex,
  listIndexes,
} from '@dotdo/duckdb-wasm/fts'

// Create full-text search index
createFTSIndex(db: DuckDBInstance, config: {
  table: string
  columns: string | string[]
  indexName?: string
  stemmer?: StemmerLanguage  // 'english', 'porter', etc. Default: 'porter'
  docIdColumn?: string       // Default: 'rowid'
  ignoreCase?: boolean       // Default: true
  stripAccents?: boolean     // Default: true
  overwrite?: boolean        // Default: false
}): Promise<FTSCreateResult>

// Drop an FTS index
dropFTSIndex(db: DuckDBInstance, table: string): Promise<FTSDropResult>

// Search with BM25 ranking
search<T>(db: DuckDBInstance, table: string, query: string, options?: {
  limit?: number      // Default: 10
  offset?: number     // Default: 0
  minScore?: number   // Default: 0
  select?: string[] | '*'
  where?: string
}): Promise<FTSSearchResults<T>>

// Rebuild index after data changes
rebuildIndex(db: DuckDBInstance, table: string): Promise<FTSRebuildResult>

// List all FTS indexes
listIndexes(db: DuckDBInstance): Promise<FTSIndexInfo[]>
```

### VSS Functions

```typescript
import {
  loadVSS,
  createVectorIndex,
  dropVectorIndex,
  getIndexStats,
  search,
  estimateMemory,
} from '@dotdo/duckdb-wasm/vss'

// Load VSS extension
loadVSS(db: DuckDBInstance): Promise<VSSExtensionState>

// Create HNSW vector index
createVectorIndex(db: DuckDBInstance, table: string, column: string, options: {
  dimensions: number
  metric?: 'l2' | 'l2sq' | 'cosine' | 'ip'  // Default: 'l2sq'
  M?: number                 // HNSW parameter (default: 16)
  efConstruction?: number    // HNSW parameter (default: 200)
  efSearch?: number          // HNSW parameter (default: 64)
  indexName?: string         // Auto-generated if not provided
  failIfExists?: boolean     // Default: false (uses IF NOT EXISTS)
}): Promise<void>

// Drop a vector index
dropVectorIndex(db: DuckDBInstance, table: string, column: string, indexName?: string): Promise<void>

// Get index statistics
getIndexStats(db: DuckDBInstance, table: string, column: string, indexName?: string): Promise<IndexStats>

// k-NN vector search
search<T>(db: DuckDBInstance, table: string, column: string, queryVector: number[], options?: {
  k?: number           // Default: 10
  efSearch?: number    // Override index default
  filter?: string      // SQL WHERE clause
  select?: string[]    // Additional columns to return
  idColumn?: string    // Default: 'id'
}): Promise<SearchResult<T>[]>

// Estimate memory requirements
estimateMemory(params: {
  vectorCount: number
  dimensions: number
  M?: number           // Default: 16
}): MemoryEstimation
```

## Error Handling

```typescript
import { Database, DuckDBError } from '@dotdo/duckdb'

const db = new Database(':memory:')

try {
  db.all('SELECT * FROM nonexistent_table')
} catch (error) {
  if (error instanceof DuckDBError) {
    console.log('Code:', error.code)      // 'CATALOG_ERROR'
    console.log('Message:', error.message) // 'Table not found...'
    console.log('SQL:', error.sql)         // Original query
  }
}
```

### Error Codes

| Code | Description |
|------|-------------|
| `PARSER_ERROR` | SQL syntax error |
| `CATALOG_ERROR` | Table/column not found |
| `CONSTRAINT_ERROR` | Unique/NOT NULL violation |
| `INTERNAL_ERROR` | Internal database error |

## Types

### DuckDB Node.js API Types

```typescript
import type {
  // Configuration
  DatabaseConfig,
  AccessMode,
  ExtendedDuckDBConfig,

  // Results
  QueryResult,
  ColumnInfo,

  // Callbacks
  DatabaseCallback,
  CloseCallback,
  RunCallback,
  AllCallback,
  GetCallback,
  EachRowCallback,
  EachCompleteCallback,
  FinalizeCallback,

  // Interfaces
  IDatabase,
  IConnection,
  IStatement,
} from '@dotdo/duckdb'

// Error class
import { DuckDBError } from '@dotdo/duckdb'
```

### DuckDB WASM Types

```typescript
import type {
  // Configuration
  DuckDBConfig,
  InstantiateOptions,

  // Instance
  DuckDBInstance,

  // Results
  QueryResult,
  QueryOptions,
  ColumnInfo,

  // Metrics
  InstantiationResult,
  InstantiationMetrics,

  // Buffer registration
  BufferRegistrationOptions,
  BufferRegistrationResult,
} from '@dotdo/duckdb-wasm'
```

### FTS Types

```typescript
import type {
  FTSIndexConfig,
  FTSIndexInfo,
  FTSSearchOptions,
  FTSSearchResult,
  FTSSearchResults,
  FTSCreateResult,
  FTSDropResult,
  FTSRebuildResult,
  StemmerLanguage,
} from '@dotdo/duckdb-wasm/fts'

import { FTSError, FTSErrorCode } from '@dotdo/duckdb-wasm/fts'
```

### VSS Types

```typescript
import type {
  VectorIndexConfig,
  CreateVectorIndexOptions,
  SearchOptions,
  SearchResult,
  IndexStats,
  DistanceMetric,
  MemoryEstimationParams,
  MemoryEstimation,
  VSSExtensionState,
} from '@dotdo/duckdb-wasm/vss'
```

## Performance Tips

### Memory Management

```typescript
// DuckDB WASM memory is limited in Workers (~128MB)
// Use pagination for large result sets
const pageSize = 1000
let offset = 0

while (true) {
  const rows = await db.query(`
    SELECT * FROM large_table
    ORDER BY id
    LIMIT ${pageSize}
    OFFSET ${offset}
  `)

  if (rows.rows.length === 0) break
  // Process rows...
  offset += pageSize
}
```

### WASM Module Caching

```typescript
import { createDuckDB, isCached, clearCache, getHeapUsage } from '@dotdo/duckdb-wasm'

// First call loads WASM from CDN (~500ms cold start)
const db1 = await createDuckDB()

// Subsequent calls use cached module (~50ms warm start)
console.log(isCached()) // true

// Check estimated heap usage
console.log(getHeapUsage()) // e.g., 39321600 (bytes)

// Clear cache if needed
clearCache()
```

### Index Usage

```typescript
// For large tables, always create indexes on filter columns
await db.query('CREATE INDEX idx_events_user ON events(user_id)')
await db.query('CREATE INDEX idx_events_timestamp ON events(timestamp)')

// DuckDB will use indexes automatically
const result = await db.query(`
  SELECT * FROM events
  WHERE user_id = 42 AND timestamp > '2024-01-01'
`)
```

## Architecture

```
+-------------------------------------------------------------+
|                    Your Application                          |
|                                                             |
|  const db = new Database()  // or createDuckDB()            |
|  db.all('SELECT ...')                                       |
+-------------------------------------------------------------+
                              |
              +---------------+---------------+
              |                               |
              v                               v
+-------------------------+     +-------------------------+
|   Node.js Mode          |     |     WASM Mode           |
|   (Database)            |     |     (createDuckDB)      |
+-------------------------+     +-------------------------+
|                         |     |                         |
|  -> Shared SQL Engine   |     |  -> DuckDB WASM Binary  |
|  -> In-memory storage   |     |  -> Runs in Workers     |
|  -> API compatibility   |     |  -> R2/Parquet support  |
|  -> Local development   |     |  -> FTS/VSS extensions  |
|                         |     |                         |
+-------------------------+     +-------------------------+
```

## Common Patterns

### Analytics Dashboard

```typescript
import { createDuckDB, registerBuffer } from '@dotdo/duckdb-wasm'

export async function analyzeMetrics(env: Env, dateRange: { start: string; end: string }) {
  const db = await createDuckDB()

  // Load metrics Parquet from R2
  const metricsFile = await env.R2_BUCKET.get('metrics/daily.parquet')
  await db.registerBuffer('metrics.parquet', await metricsFile.arrayBuffer())

  // Aggregate metrics
  const result = await db.query(`
    SELECT
      metric_name,
      date_trunc('day', timestamp) as day,
      AVG(value) as avg_value,
      MAX(value) as max_value,
      MIN(value) as min_value,
      COUNT(*) as samples
    FROM parquet_scan('metrics.parquet')
    WHERE timestamp BETWEEN '${dateRange.start}' AND '${dateRange.end}'
    GROUP BY metric_name, day
    ORDER BY day DESC
  `)

  await db.close()
  return result.rows
}
```

### Semantic Search

```typescript
import { createDuckDB } from '@dotdo/duckdb-wasm'
import { loadVSS, createVectorIndex, search } from '@dotdo/duckdb-wasm/vss'

export async function semanticSearch(
  env: Env,
  query: string,
  options: { limit?: number; category?: string }
) {
  const db = await createDuckDB()
  await loadVSS(db)

  // Load product embeddings from R2
  const embeddings = await env.R2_BUCKET.get('products/embeddings.parquet')
  await db.registerBuffer('embeddings.parquet', await embeddings.arrayBuffer())

  // Create table from Parquet
  await db.query(`
    CREATE TABLE products AS
    SELECT * FROM parquet_scan('embeddings.parquet')
  `)

  // Create vector index
  await createVectorIndex(db, 'products', 'embedding', {
    dimensions: 768,
    metric: 'cosine',
  })

  // Generate query embedding (call your embedding API)
  const queryEmbedding = await generateEmbedding(env, query)

  // Search
  const filter = options.category ? `category = '${options.category}'` : undefined
  const results = await search(db, 'products', 'embedding', queryEmbedding, {
    k: options.limit ?? 10,
    filter,
    select: ['name', 'description', 'price'],
  })

  await db.close()
  return results
}
```

### Log Analysis

```typescript
import { createDuckDB } from '@dotdo/duckdb-wasm'
import { createFTSIndex, search } from '@dotdo/duckdb-wasm/fts'

export async function searchLogs(env: Env, query: string, options: { limit?: number }) {
  const db = await createDuckDB()

  // Load logs from R2
  const logs = await env.R2_BUCKET.get('logs/application.parquet')
  await db.registerBuffer('logs.parquet', await logs.arrayBuffer())

  // Create table
  await db.query(`
    CREATE TABLE logs AS
    SELECT * FROM parquet_scan('logs.parquet')
  `)

  // Create FTS index
  await createFTSIndex(db, {
    table: 'logs',
    columns: ['message', 'stack_trace'],
    stemmer: 'english',
  })

  // Search logs
  const results = await search(db, 'logs', query, {
    limit: options.limit ?? 100,
    select: ['timestamp', 'level', 'message'],
  })

  await db.close()
  return results
}
```

## Related

- [Postgres Integration](/docs/integrations/postgres) - PostgreSQL compatibility layer
- [S3/R2 Integration](/docs/integrations/s3) - Object storage for Parquet files
- [Algolia Integration](/docs/integrations/algolia) - Alternative search solution
- [Compat SDKs](/docs/compat) - All API-compatible SDKs
