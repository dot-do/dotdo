---
title: s3.do
description: S3 on the Edge — A fully managed S3-compatible object storage service running on Cloudflare R2 with zero egress fees.
---

# s3.do

**S3 on the Edge** — A fully managed S3-compatible object storage service built on Cloudflare R2, with multi-tenant support, edge-generated presigned URLs, and seamless Durable Object integration.

```typescript
import { S3 } from 's3.do'

const storage = new S3('https://your-worker.workers.dev')

// Upload a file
await storage.put('my-bucket', 'hello.txt', 'Hello, World!')

// Download a file
const content = await storage.get('my-bucket', 'hello.txt')
```

<Callout type="info">
Looking for AWS SDK compatibility? See [@dotdo/s3](/docs/integrations/s3/package) for a drop-in @aws-sdk/client-s3 replacement.
</Callout>

## Why s3.do?

Traditional object storage requires infrastructure management, regional planning, and egress cost optimization. s3.do eliminates all of that by running directly on Cloudflare's edge network:

- **Zero Infrastructure** — No buckets to provision, no regions to choose, no egress fees
- **Global by Default** — Data lives at the edge, close to your users
- **S3 Compatible** — Works with existing S3 tools and libraries
- **Multi-Tenant Native** — Built-in tenant isolation with standardized path conventions
- **Serverless Economics** — Pay only for storage, zero egress fees

## Features

### Core Storage

| Feature | Description |
|---------|-------------|
| **Object Operations** | `put`, `get`, `delete`, `head`, `list` with full streaming support |
| **Multipart Uploads** | Large file uploads with resumability and parallel parts |
| **Presigned URLs** | Edge-generated signed URLs for direct client uploads/downloads |
| **Range Requests** | Partial content retrieval with byte-range support |
| **Metadata** | Custom metadata and HTTP headers on objects |

### Multi-Tenant Storage

| Feature | Description |
|---------|-------------|
| **Path Conventions** | Standardized `{tenant}/{type}/{id}` paths |
| **Tenant Isolation** | Each tenant's data is logically separated |
| **Scoped Operations** | `putForTenant`, `getForTenant`, `listForTenant` |
| **Audit Paths** | Timestamped paths for compliance |

### R2 Integration

| Feature | Description |
|---------|-------------|
| **Zero Egress** | No data transfer fees (Cloudflare R2) |
| **Automatic Tiering** | Cold data automatically moved to cheaper storage |
| **S3 API** | Compatible with AWS S3 tools and SDKs |
| **Custom Domains** | Serve files from your own domain |

## Installation

```bash
npm install s3.do
```

## Quick Start

### Deploy to Cloudflare Workers

```typescript
// src/index.ts
import { S3Entrypoint, S3Storage } from 's3.do'

export { S3Storage }
export default S3Entrypoint
```

```jsonc
// wrangler.jsonc
{
  "name": "my-s3.do",
  "main": "src/index.ts",
  "compatibility_date": "2025-01-01",
  "r2_buckets": [
    { "binding": "R2_BUCKET", "bucket_name": "my-storage" }
  ],
  "durable_objects": {
    "bindings": [{ "name": "S3_STORAGE", "class_name": "S3Storage" }]
  }
}
```

```bash
npx wrangler deploy
```

### Direct R2 Access

For maximum performance in Workers, use R2 bindings directly with the R2Store utility:

```typescript
import { createR2Store } from 's3.do/r2'

export default {
  async fetch(request: Request, env: Env) {
    const store = createR2Store(env.R2_BUCKET, {
      tenant: 'acme-corp',
      publicUrl: 'https://files.example.com',
    })

    // Put with auto content-type detection
    await store.put('reports/q4.pdf', pdfData)

    // Get with streaming
    const stream = await store.getStream('reports/q4.pdf')

    // List with pagination
    for await (const object of store.listAll({ prefix: 'reports/' })) {
      console.log(object.key, object.size)
    }
  }
}
```

## Examples

### File Upload API

```typescript
import { S3 } from 's3.do'

export default {
  async fetch(request: Request, env: Env) {
    const storage = new S3(env)
    const url = new URL(request.url)

    if (url.pathname === '/api/upload-url' && request.method === 'POST') {
      const { filename, contentType } = await request.json()
      const key = `uploads/${crypto.randomUUID()}/${filename}`

      const uploadUrl = await storage.getSignedPutUrl('uploads', key, {
        contentType,
        expiresIn: 300, // 5 minutes
      })

      return Response.json({ uploadUrl, key })
    }

    if (url.pathname.startsWith('/files/')) {
      const key = url.pathname.replace('/files/', '')
      const response = await storage.getAsResponse('uploads', key)
      return response
    }

    return new Response('Not found', { status: 404 })
  }
}
```

### Multi-Tenant Document Storage

```typescript
import { createR2Store } from 's3.do/r2'

export class DocumentStore extends DO {
  private store: R2Store

  constructor(state: DurableObjectState, env: Env) {
    super(state, env)
    this.store = createR2Store(env.DOCUMENTS, {
      tenant: this.id,
    })
  }

  async saveDocument(id: string, content: string) {
    await this.store.putForTenant({
      type: 'docs',
      id,
      data: content,
      contentType: 'text/markdown',
    })
  }

  async getDocument(id: string) {
    const obj = await this.store.getForTenant({
      type: 'docs',
      id,
    })
    return obj?.text()
  }

  async listDocuments() {
    const docs = []
    for await (const obj of this.store.listAllForTenant({ type: 'docs' })) {
      docs.push({
        id: obj.key.split('/').pop(),
        size: obj.size,
        modified: obj.uploaded,
      })
    }
    return docs
  }
}
```

### Image Processing Pipeline

```typescript
import { S3 } from 's3.do'

async function processImage(storage: S3, bucket: string, key: string) {
  // Get original
  const original = await storage.get(bucket, key)

  // Process with Cloudflare Images
  const processed = await processWithCloudflareImages(original)

  // Store processed versions in parallel
  await Promise.all([
    storage.put(bucket, key.replace('.', '-thumb.'), processed.thumbnail, {
      contentType: 'image/webp',
    }),
    storage.put(bucket, key.replace('.', '-medium.'), processed.medium, {
      contentType: 'image/webp',
    }),
  ])
}
```

### Backup and Restore

```typescript
import { S3 } from 's3.do'

async function backupDatabase(storage: S3, data: string) {
  const timestamp = new Date().toISOString().replace(/[:.]/g, '-')

  await storage.put('backups', `database/${timestamp}.json`, data, {
    contentType: 'application/json',
    metadata: {
      'backup-type': 'daily',
      'created-at': new Date().toISOString(),
    },
  })
}

async function restoreLatestBackup(storage: S3) {
  // List backups
  const backups = await storage.list('backups', {
    prefix: 'database/',
  })

  // Get latest (sorted by key which includes timestamp)
  const latest = backups.objects
    .sort((a, b) => b.key.localeCompare(a.key))[0]

  if (!latest) throw new Error('No backups found')

  return storage.get('backups', latest.key)
}
```

### Presigned URLs for Direct Upload

```typescript
import { S3 } from 's3.do'

// Backend: Generate presigned URL
async function createUploadUrl(storage: S3, userId: string, filename: string) {
  const key = `uploads/${userId}/${crypto.randomUUID()}/${filename}`

  const url = await storage.getSignedPutUrl('user-uploads', key, {
    expiresIn: 300, // 5 minutes
    contentType: 'application/octet-stream',
  })

  return { url, key }
}

// Frontend: Direct upload to R2
async function uploadFile(file: File) {
  const { url } = await fetch('/api/upload-url', {
    method: 'POST',
    body: JSON.stringify({ filename: file.name }),
  }).then(r => r.json())

  await fetch(url, {
    method: 'PUT',
    body: file,
    headers: { 'Content-Type': file.type },
  })
}
```

## Path Conventions

s3.do uses standardized paths for multi-tenant storage:

```
{tenant}/{type}/{id}[/{timestamp}][/{filename}]
```

Examples:
- `acme/documents/doc-123` - Simple document
- `acme/backups/db-1/2024-01-15T10:30:00Z` - Timestamped backup
- `acme/uploads/user-1/photo.jpg` - User upload with filename

```typescript
import { buildPath, parsePath } from 's3.do/r2'

// Build path
const path = buildPath({
  tenant: 'acme',
  type: 'documents',
  id: 'doc-123',
  filename: 'report.pdf',
})
// Returns: 'acme/documents/doc-123/report.pdf'

// Parse path
const components = parsePath('acme/backups/db-1/2024-01-15T10:30:00Z')
// Returns: { tenant: 'acme', type: 'backups', id: 'db-1', timestamp: '2024-01-15T10:30:00Z' }
```

## Configuration

### Basic R2 Setup

```toml
# wrangler.toml

# Single bucket
[[r2_buckets]]
binding = "BUCKET"
bucket_name = "my-app-storage"

# Multiple buckets
[[r2_buckets]]
binding = "UPLOADS"
bucket_name = "my-app-uploads"

[[r2_buckets]]
binding = "BACKUPS"
bucket_name = "my-app-backups"

# With custom domain (configure in Cloudflare dashboard)
[[r2_buckets]]
binding = "PUBLIC"
bucket_name = "my-app-public"
```

### With Durable Objects

```jsonc
// wrangler.jsonc
{
  "durable_objects": {
    "bindings": [
      { "name": "S3_STORAGE", "class_name": "S3Storage" }
    ]
  },
  "migrations": [
    { "tag": "v1", "new_sqlite_classes": ["S3Storage"] }
  ]
}
```

## Architecture

```
┌─────────────────────────────────────────────────────────────────────────┐
│                           Client Applications                           │
├─────────────────┬─────────────────┬─────────────────┬───────────────────┤
│   Presigned     │   HTTP API      │   Service       │   Direct R2       │
│   URLs          │   JSON-RPC      │   Bindings      │   Binding         │
├─────────────────┴─────────────────┴─────────────────┴───────────────────┤
│                         s3.do Worker (Edge)                             │
├─────────────────────────────────────────────────────────────────────────┤
│  Request Router  │  Path Builder  │  Tenant Manager  │  URL Signer      │
├─────────────────────────────────────────────────────────────────────────┤
│                         Cloudflare R2 (Storage)                         │
├──────────────────────────┬──────────────────────────────────────────────┤
│     Automatic Tiering    │              Custom Domains                  │
│  (Hot → Cold Storage)    │          (CDN Integration)                   │
└──────────────────────────┴──────────────────────────────────────────────┘
```

s3.do provides:

1. **Edge Request Handling** — All requests processed at the edge, closest to users
2. **Multi-Tenant Isolation** — Logical separation of tenant data with path conventions
3. **Presigned URL Generation** — Generate signed URLs at the edge with zero latency
4. **R2 Integration** — Direct access to Cloudflare R2 with zero egress fees

## API Reference

### S3 Client

```typescript
const storage = new S3(envOrUrl)

// Object operations
await storage.put(bucket, key, data, options?)
await storage.get(bucket, key, options?)
await storage.delete(bucket, key)
await storage.head(bucket, key)
await storage.list(bucket, options?)

// Presigned URLs
await storage.getSignedGetUrl(bucket, key, options?)
await storage.getSignedPutUrl(bucket, key, options?)
await storage.getSignedDeleteUrl(bucket, key, options?)

// Response helpers
await storage.getAsResponse(bucket, key) // Returns Response object
await storage.getStream(bucket, key)     // Returns ReadableStream
```

### R2Store

```typescript
const store = createR2Store(r2Binding, config?)

// Basic operations
await store.put(key, data, options?)
await store.get(key)
await store.delete(key)
await store.head(key)
await store.list(options?)

// Streaming
await store.getStream(key)
await store.putStream(key, stream, options?)

// Iteration
for await (const obj of store.listAll(options?)) { ... }

// Tenant-scoped operations
await store.putForTenant({ type, id, data, ... })
await store.getForTenant({ type, id })
await store.listForTenant({ type, prefix? })
for await (const obj of store.listAllForTenant({ type })) { ... }
```

## Types

```typescript
import type {
  // Client
  S3,
  S3Config,

  // R2 Store
  R2Store,
  R2StoreConfig,
  R2Object,
  R2ObjectMetadata,
  R2HTTPMetadata,

  // Operations
  PutOptions,
  GetOptions,
  ListOptions,
  ListResult,

  // Presigned URLs
  PresignedUrlOptions,

  // Path utilities
  PathComponents,
  TenantPathOptions,
} from 's3.do'
```

## Comparison with AWS S3

| Feature | AWS S3 | s3.do |
|---------|--------|-------|
| Egress fees | $0.09/GB | **Free** |
| Cold start | Lambda latency | 0ms (V8 isolates) |
| Regional | Single region | Global edge |
| Pricing | Per-request + storage | Storage only |
| Multi-tenant | Manual | Built-in |
| Presigned URLs | SDK required | Edge-native |

## Related

- [@dotdo/s3](/docs/integrations/s3/package) - AWS SDK-compatible package for migration
- [Storage Overview](/docs/storage) - All storage options
- [Hot Tier Storage](/docs/storage/hot-tier) - High-performance storage with Durable Objects
- [Warm Tier Storage](/docs/storage/warm-tier) - R2 object storage
- [Durable Objects](/docs/architecture/durable-objects) - DO-backed storage
